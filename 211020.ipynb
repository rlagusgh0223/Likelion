{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "211020",
      "provenance": [],
      "authorship_tag": "ABX9TyO8JfxwxxyRZ/vg+ai3sn4T"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvq_Uo9yeWDG"
      },
      "source": [
        "학습의 자동 중단\n",
        "- iris.csv를 사용해서 학습의 자동 중단 추가하기\n",
        "- 아이리스 데이터에서 자동 중단이 일어나는 시점 확인해보기\n",
        "- Epoch : 3500\n",
        "- batch_size : 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R3ez7k0AeLaT",
        "outputId": "3698f65a-76b6-4821-e96e-90a9848e7896"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "#import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#seed값 설정\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "#데이터 입력\n",
        "df_pre = pd.read_csv(\"/iris.csv\", header=None)\n",
        "\n",
        "#데이터 섞어주기\n",
        "df = df_pre.sample(frac=1)\n",
        "\n",
        "#데이터 분류\n",
        "dataset = df.values\n",
        "X = dataset[:, 0:4].astype(float)\n",
        "Y_obj = dataset[:, 4]\n",
        "\n",
        "#문자열을 숫자로 변환\n",
        "e = LabelEncoder()\n",
        "e.fit(Y_obj)\n",
        "Y = e.transform(Y_obj)\n",
        "Y_encoded = tf.keras.utils.to_categorical(Y)\n",
        "\n",
        "#모델의 설정\n",
        "model = Sequential()\n",
        "model.add(Dense(16, input_dim=4, activation = 'relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "#모델 컴파일\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "#자동 중단 설정\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)\n",
        "#patience=10 : 10번동안 나빠지면 중단\n",
        "#EarlyStopping : 학습된걸 보면서 강제로 정지(검증용셀의 loss(val_loss를 본다)\n",
        "\n",
        "#모델 저장 조건 설정\n",
        "modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "#ModelCheckpoint : val_loss값이 좋아질때만 modelpath에 저장\n",
        "\n",
        "#모델 실행\n",
        "history = model.fit(X, Y_encoded, validation_split=0.33, epochs=3500, batch_size=50, callbacks=[early_stopping_callback, checkpointer])\n",
        "\n",
        "#결과 출력\n",
        "#print(\"\\nAccuracy : %.2f%%\" % (model.evaluate(X, Y_encoded)[1]*100))\n",
        "\n",
        "#val값에 테스트셋으로 실험 결과의 오차 값을 저장\n",
        "y_vacc = history.history['val_accuracy']\n",
        "y_vloss = history.history['val_loss']\n",
        "\n",
        "#원래 값에 학습셋으로 측정한 정확도의 값을 저장\n",
        "y_acc = history.history['accuracy']\n",
        "y_loss = history.history['loss']\n",
        "\n",
        "#x값을 지정하고 정확도를 파란색으로, 오차를 빨간색으로 표시\n",
        "x_len = np.arange(len(y_acc))\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.plot(x_len, y_vacc, \"o\", c=\"red\", markersize=3, label='val_acccuracy')\n",
        "plt.plot(x_len, y_acc, \"o\", c=\"blue\", markersize=3, label='acccuracy')\n",
        "plt.plot(x_len, y_vloss, \"o\", c=\"violet\", markersize=3, label='val_loss')\n",
        "plt.plot(x_len, y_loss, \"o\", c=\"springgreen\", markersize=3, label='loss')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3500\n",
            "2/2 [==============================] - 1s 152ms/step - loss: 2.6070 - accuracy: 0.3600 - val_loss: 2.7158 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.71583, saving model to ./model/01-2.7158.hdf5\n",
            "Epoch 2/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 2.5462 - accuracy: 0.3600 - val_loss: 2.6508 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.71583 to 2.65082, saving model to ./model/02-2.6508.hdf5\n",
            "Epoch 3/3500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.4883 - accuracy: 0.3600 - val_loss: 2.5860 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.65082 to 2.58601, saving model to ./model/03-2.5860.hdf5\n",
            "Epoch 4/3500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.4293 - accuracy: 0.3600 - val_loss: 2.5213 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00004: val_loss improved from 2.58601 to 2.52129, saving model to ./model/04-2.5213.hdf5\n",
            "Epoch 5/3500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.3704 - accuracy: 0.3600 - val_loss: 2.4570 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00005: val_loss improved from 2.52129 to 2.45697, saving model to ./model/05-2.4570.hdf5\n",
            "Epoch 6/3500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.3097 - accuracy: 0.3600 - val_loss: 2.3929 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00006: val_loss improved from 2.45697 to 2.39293, saving model to ./model/06-2.3929.hdf5\n",
            "Epoch 7/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 2.2487 - accuracy: 0.3600 - val_loss: 2.3294 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00007: val_loss improved from 2.39293 to 2.32937, saving model to ./model/07-2.3294.hdf5\n",
            "Epoch 8/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 2.1914 - accuracy: 0.3600 - val_loss: 2.2653 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00008: val_loss improved from 2.32937 to 2.26526, saving model to ./model/08-2.2653.hdf5\n",
            "Epoch 9/3500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 2.1251 - accuracy: 0.3600 - val_loss: 2.1993 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00009: val_loss improved from 2.26526 to 2.19934, saving model to ./model/09-2.1993.hdf5\n",
            "Epoch 10/3500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 2.0644 - accuracy: 0.3600 - val_loss: 2.1319 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00010: val_loss improved from 2.19934 to 2.13195, saving model to ./model/10-2.1319.hdf5\n",
            "Epoch 11/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 2.0014 - accuracy: 0.3600 - val_loss: 2.0646 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00011: val_loss improved from 2.13195 to 2.06458, saving model to ./model/11-2.0646.hdf5\n",
            "Epoch 12/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 1.9368 - accuracy: 0.3600 - val_loss: 1.9973 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00012: val_loss improved from 2.06458 to 1.99731, saving model to ./model/12-1.9973.hdf5\n",
            "Epoch 13/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.8745 - accuracy: 0.3600 - val_loss: 1.9299 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.99731 to 1.92988, saving model to ./model/13-1.9299.hdf5\n",
            "Epoch 14/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.8130 - accuracy: 0.3700 - val_loss: 1.8631 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.92988 to 1.86310, saving model to ./model/14-1.8631.hdf5\n",
            "Epoch 15/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.7489 - accuracy: 0.3700 - val_loss: 1.7975 - val_accuracy: 0.2800\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.86310 to 1.79750, saving model to ./model/15-1.7975.hdf5\n",
            "Epoch 16/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 1.6917 - accuracy: 0.3700 - val_loss: 1.7323 - val_accuracy: 0.3000\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.79750 to 1.73228, saving model to ./model/16-1.7323.hdf5\n",
            "Epoch 17/3500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.6271 - accuracy: 0.3700 - val_loss: 1.6687 - val_accuracy: 0.3400\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.73228 to 1.66868, saving model to ./model/17-1.6687.hdf5\n",
            "Epoch 18/3500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.5673 - accuracy: 0.4000 - val_loss: 1.6061 - val_accuracy: 0.4000\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.66868 to 1.60606, saving model to ./model/18-1.6061.hdf5\n",
            "Epoch 19/3500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.5082 - accuracy: 0.4400 - val_loss: 1.5446 - val_accuracy: 0.4800\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.60606 to 1.54455, saving model to ./model/19-1.5446.hdf5\n",
            "Epoch 20/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 1.4487 - accuracy: 0.5000 - val_loss: 1.4845 - val_accuracy: 0.5800\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.54455 to 1.48450, saving model to ./model/20-1.4845.hdf5\n",
            "Epoch 21/3500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 1.3961 - accuracy: 0.5600 - val_loss: 1.4251 - val_accuracy: 0.5800\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.48450 to 1.42509, saving model to ./model/21-1.4251.hdf5\n",
            "Epoch 22/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 1.3393 - accuracy: 0.6100 - val_loss: 1.3673 - val_accuracy: 0.6400\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.42509 to 1.36733, saving model to ./model/22-1.3673.hdf5\n",
            "Epoch 23/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.2854 - accuracy: 0.6500 - val_loss: 1.3110 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.36733 to 1.31099, saving model to ./model/23-1.3110.hdf5\n",
            "Epoch 24/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.2350 - accuracy: 0.6700 - val_loss: 1.2559 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00024: val_loss improved from 1.31099 to 1.25587, saving model to ./model/24-1.2559.hdf5\n",
            "Epoch 25/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 1.1828 - accuracy: 0.6700 - val_loss: 1.2027 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.25587 to 1.20272, saving model to ./model/25-1.2027.hdf5\n",
            "Epoch 26/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.1349 - accuracy: 0.6700 - val_loss: 1.1512 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00026: val_loss improved from 1.20272 to 1.15119, saving model to ./model/26-1.1512.hdf5\n",
            "Epoch 27/3500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 1.0873 - accuracy: 0.6700 - val_loss: 1.1018 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00027: val_loss improved from 1.15119 to 1.10185, saving model to ./model/27-1.1018.hdf5\n",
            "Epoch 28/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 1.0414 - accuracy: 0.6700 - val_loss: 1.0548 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00028: val_loss improved from 1.10185 to 1.05476, saving model to ./model/28-1.0548.hdf5\n",
            "Epoch 29/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 1.0006 - accuracy: 0.6700 - val_loss: 1.0099 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00029: val_loss improved from 1.05476 to 1.00990, saving model to ./model/29-1.0099.hdf5\n",
            "Epoch 30/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.9591 - accuracy: 0.6700 - val_loss: 0.9678 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00030: val_loss improved from 1.00990 to 0.96775, saving model to ./model/30-0.9678.hdf5\n",
            "Epoch 31/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.9241 - accuracy: 0.6700 - val_loss: 0.9281 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.96775 to 0.92814, saving model to ./model/31-0.9281.hdf5\n",
            "Epoch 32/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.8883 - accuracy: 0.6700 - val_loss: 0.8919 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.92814 to 0.89187, saving model to ./model/32-0.8919.hdf5\n",
            "Epoch 33/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.8572 - accuracy: 0.6700 - val_loss: 0.8588 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.89187 to 0.85877, saving model to ./model/33-0.8588.hdf5\n",
            "Epoch 34/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.8304 - accuracy: 0.6700 - val_loss: 0.8289 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.85877 to 0.82890, saving model to ./model/34-0.8289.hdf5\n",
            "Epoch 35/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.8062 - accuracy: 0.6700 - val_loss: 0.8027 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.82890 to 0.80269, saving model to ./model/35-0.8027.hdf5\n",
            "Epoch 36/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.7836 - accuracy: 0.6700 - val_loss: 0.7800 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.80269 to 0.78002, saving model to ./model/36-0.7800.hdf5\n",
            "Epoch 37/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.7670 - accuracy: 0.6700 - val_loss: 0.7602 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.78002 to 0.76023, saving model to ./model/37-0.7602.hdf5\n",
            "Epoch 38/3500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7533 - accuracy: 0.6700 - val_loss: 0.7431 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.76023 to 0.74306, saving model to ./model/38-0.7431.hdf5\n",
            "Epoch 39/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.7406 - accuracy: 0.6700 - val_loss: 0.7283 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.74306 to 0.72829, saving model to ./model/39-0.7283.hdf5\n",
            "Epoch 40/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.7304 - accuracy: 0.6700 - val_loss: 0.7157 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.72829 to 0.71572, saving model to ./model/40-0.7157.hdf5\n",
            "Epoch 41/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.7213 - accuracy: 0.6700 - val_loss: 0.7052 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00041: val_loss improved from 0.71572 to 0.70518, saving model to ./model/41-0.7052.hdf5\n",
            "Epoch 42/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.7153 - accuracy: 0.6800 - val_loss: 0.6962 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.70518 to 0.69618, saving model to ./model/42-0.6962.hdf5\n",
            "Epoch 43/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.7081 - accuracy: 0.6800 - val_loss: 0.6885 - val_accuracy: 0.6600\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.69618 to 0.68846, saving model to ./model/43-0.6885.hdf5\n",
            "Epoch 44/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.7035 - accuracy: 0.6900 - val_loss: 0.6816 - val_accuracy: 0.6800\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.68846 to 0.68162, saving model to ./model/44-0.6816.hdf5\n",
            "Epoch 45/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.6993 - accuracy: 0.7100 - val_loss: 0.6754 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.68162 to 0.67538, saving model to ./model/45-0.6754.hdf5\n",
            "Epoch 46/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6951 - accuracy: 0.7200 - val_loss: 0.6696 - val_accuracy: 0.7200\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.67538 to 0.66960, saving model to ./model/46-0.6696.hdf5\n",
            "Epoch 47/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.6906 - accuracy: 0.7200 - val_loss: 0.6644 - val_accuracy: 0.7400\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.66960 to 0.66436, saving model to ./model/47-0.6644.hdf5\n",
            "Epoch 48/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6869 - accuracy: 0.7200 - val_loss: 0.6594 - val_accuracy: 0.7600\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.66436 to 0.65943, saving model to ./model/48-0.6594.hdf5\n",
            "Epoch 49/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.6828 - accuracy: 0.7300 - val_loss: 0.6548 - val_accuracy: 0.7600\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.65943 to 0.65483, saving model to ./model/49-0.6548.hdf5\n",
            "Epoch 50/3500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.6790 - accuracy: 0.7300 - val_loss: 0.6504 - val_accuracy: 0.7800\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.65483 to 0.65044, saving model to ./model/50-0.6504.hdf5\n",
            "Epoch 51/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6749 - accuracy: 0.7300 - val_loss: 0.6464 - val_accuracy: 0.7600\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.65044 to 0.64642, saving model to ./model/51-0.6464.hdf5\n",
            "Epoch 52/3500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6710 - accuracy: 0.7200 - val_loss: 0.6426 - val_accuracy: 0.7400\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.64642 to 0.64259, saving model to ./model/52-0.6426.hdf5\n",
            "Epoch 53/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6673 - accuracy: 0.7300 - val_loss: 0.6389 - val_accuracy: 0.7200\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.64259 to 0.63892, saving model to ./model/53-0.6389.hdf5\n",
            "Epoch 54/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.6633 - accuracy: 0.7300 - val_loss: 0.6355 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.63892 to 0.63548, saving model to ./model/54-0.6355.hdf5\n",
            "Epoch 55/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6599 - accuracy: 0.7300 - val_loss: 0.6322 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.63548 to 0.63223, saving model to ./model/55-0.6322.hdf5\n",
            "Epoch 56/3500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6562 - accuracy: 0.7200 - val_loss: 0.6291 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00056: val_loss improved from 0.63223 to 0.62907, saving model to ./model/56-0.6291.hdf5\n",
            "Epoch 57/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6531 - accuracy: 0.7100 - val_loss: 0.6261 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00057: val_loss improved from 0.62907 to 0.62610, saving model to ./model/57-0.6261.hdf5\n",
            "Epoch 58/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6499 - accuracy: 0.7100 - val_loss: 0.6232 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00058: val_loss improved from 0.62610 to 0.62322, saving model to ./model/58-0.6232.hdf5\n",
            "Epoch 59/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.6468 - accuracy: 0.7100 - val_loss: 0.6204 - val_accuracy: 0.6800\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.62322 to 0.62038, saving model to ./model/59-0.6204.hdf5\n",
            "Epoch 60/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6439 - accuracy: 0.7000 - val_loss: 0.6176 - val_accuracy: 0.6800\n",
            "\n",
            "Epoch 00060: val_loss improved from 0.62038 to 0.61762, saving model to ./model/60-0.6176.hdf5\n",
            "Epoch 61/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6411 - accuracy: 0.7000 - val_loss: 0.6149 - val_accuracy: 0.6800\n",
            "\n",
            "Epoch 00061: val_loss improved from 0.61762 to 0.61490, saving model to ./model/61-0.6149.hdf5\n",
            "Epoch 62/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.6385 - accuracy: 0.7000 - val_loss: 0.6124 - val_accuracy: 0.6800\n",
            "\n",
            "Epoch 00062: val_loss improved from 0.61490 to 0.61239, saving model to ./model/62-0.6124.hdf5\n",
            "Epoch 63/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6357 - accuracy: 0.7000 - val_loss: 0.6098 - val_accuracy: 0.6800\n",
            "\n",
            "Epoch 00063: val_loss improved from 0.61239 to 0.60981, saving model to ./model/63-0.6098.hdf5\n",
            "Epoch 64/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6333 - accuracy: 0.6900 - val_loss: 0.6074 - val_accuracy: 0.6800\n",
            "\n",
            "Epoch 00064: val_loss improved from 0.60981 to 0.60735, saving model to ./model/64-0.6074.hdf5\n",
            "Epoch 65/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6307 - accuracy: 0.7000 - val_loss: 0.6046 - val_accuracy: 0.6800\n",
            "\n",
            "Epoch 00065: val_loss improved from 0.60735 to 0.60456, saving model to ./model/65-0.6046.hdf5\n",
            "Epoch 66/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6280 - accuracy: 0.6900 - val_loss: 0.6020 - val_accuracy: 0.6800\n",
            "\n",
            "Epoch 00066: val_loss improved from 0.60456 to 0.60196, saving model to ./model/66-0.6020.hdf5\n",
            "Epoch 67/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6255 - accuracy: 0.7000 - val_loss: 0.5993 - val_accuracy: 0.6800\n",
            "\n",
            "Epoch 00067: val_loss improved from 0.60196 to 0.59930, saving model to ./model/67-0.5993.hdf5\n",
            "Epoch 68/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.6232 - accuracy: 0.6900 - val_loss: 0.5968 - val_accuracy: 0.6800\n",
            "\n",
            "Epoch 00068: val_loss improved from 0.59930 to 0.59682, saving model to ./model/68-0.5968.hdf5\n",
            "Epoch 69/3500\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 0.6207 - accuracy: 0.7000 - val_loss: 0.5943 - val_accuracy: 0.6800\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.59682 to 0.59428, saving model to ./model/69-0.5943.hdf5\n",
            "Epoch 70/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.6182 - accuracy: 0.7000 - val_loss: 0.5917 - val_accuracy: 0.6800\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.59428 to 0.59173, saving model to ./model/70-0.5917.hdf5\n",
            "Epoch 71/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.6160 - accuracy: 0.7000 - val_loss: 0.5892 - val_accuracy: 0.6800\n",
            "\n",
            "Epoch 00071: val_loss improved from 0.59173 to 0.58923, saving model to ./model/71-0.5892.hdf5\n",
            "Epoch 72/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6135 - accuracy: 0.7000 - val_loss: 0.5866 - val_accuracy: 0.6800\n",
            "\n",
            "Epoch 00072: val_loss improved from 0.58923 to 0.58661, saving model to ./model/72-0.5866.hdf5\n",
            "Epoch 73/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.6112 - accuracy: 0.7000 - val_loss: 0.5840 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00073: val_loss improved from 0.58661 to 0.58402, saving model to ./model/73-0.5840.hdf5\n",
            "Epoch 74/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.6089 - accuracy: 0.7000 - val_loss: 0.5814 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00074: val_loss improved from 0.58402 to 0.58144, saving model to ./model/74-0.5814.hdf5\n",
            "Epoch 75/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.6066 - accuracy: 0.7000 - val_loss: 0.5789 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00075: val_loss improved from 0.58144 to 0.57892, saving model to ./model/75-0.5789.hdf5\n",
            "Epoch 76/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.6044 - accuracy: 0.7000 - val_loss: 0.5765 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00076: val_loss improved from 0.57892 to 0.57651, saving model to ./model/76-0.5765.hdf5\n",
            "Epoch 77/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.6022 - accuracy: 0.7000 - val_loss: 0.5740 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00077: val_loss improved from 0.57651 to 0.57405, saving model to ./model/77-0.5740.hdf5\n",
            "Epoch 78/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.6000 - accuracy: 0.7000 - val_loss: 0.5716 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00078: val_loss improved from 0.57405 to 0.57161, saving model to ./model/78-0.5716.hdf5\n",
            "Epoch 79/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5979 - accuracy: 0.7000 - val_loss: 0.5692 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00079: val_loss improved from 0.57161 to 0.56923, saving model to ./model/79-0.5692.hdf5\n",
            "Epoch 80/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5957 - accuracy: 0.7000 - val_loss: 0.5669 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00080: val_loss improved from 0.56923 to 0.56692, saving model to ./model/80-0.5669.hdf5\n",
            "Epoch 81/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5937 - accuracy: 0.7000 - val_loss: 0.5645 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00081: val_loss improved from 0.56692 to 0.56448, saving model to ./model/81-0.5645.hdf5\n",
            "Epoch 82/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5916 - accuracy: 0.7000 - val_loss: 0.5623 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00082: val_loss improved from 0.56448 to 0.56227, saving model to ./model/82-0.5623.hdf5\n",
            "Epoch 83/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.5894 - accuracy: 0.7000 - val_loss: 0.5600 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.56227 to 0.56002, saving model to ./model/83-0.5600.hdf5\n",
            "Epoch 84/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5875 - accuracy: 0.7000 - val_loss: 0.5579 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00084: val_loss improved from 0.56002 to 0.55788, saving model to ./model/84-0.5579.hdf5\n",
            "Epoch 85/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.5853 - accuracy: 0.7000 - val_loss: 0.5557 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00085: val_loss improved from 0.55788 to 0.55565, saving model to ./model/85-0.5557.hdf5\n",
            "Epoch 86/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5833 - accuracy: 0.7000 - val_loss: 0.5534 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00086: val_loss improved from 0.55565 to 0.55341, saving model to ./model/86-0.5534.hdf5\n",
            "Epoch 87/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.5814 - accuracy: 0.7000 - val_loss: 0.5511 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00087: val_loss improved from 0.55341 to 0.55110, saving model to ./model/87-0.5511.hdf5\n",
            "Epoch 88/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.5793 - accuracy: 0.7000 - val_loss: 0.5490 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00088: val_loss improved from 0.55110 to 0.54898, saving model to ./model/88-0.5490.hdf5\n",
            "Epoch 89/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5773 - accuracy: 0.7000 - val_loss: 0.5469 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00089: val_loss improved from 0.54898 to 0.54687, saving model to ./model/89-0.5469.hdf5\n",
            "Epoch 90/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5754 - accuracy: 0.7000 - val_loss: 0.5447 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00090: val_loss improved from 0.54687 to 0.54470, saving model to ./model/90-0.5447.hdf5\n",
            "Epoch 91/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5734 - accuracy: 0.7000 - val_loss: 0.5426 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00091: val_loss improved from 0.54470 to 0.54259, saving model to ./model/91-0.5426.hdf5\n",
            "Epoch 92/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5715 - accuracy: 0.7100 - val_loss: 0.5405 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00092: val_loss improved from 0.54259 to 0.54046, saving model to ./model/92-0.5405.hdf5\n",
            "Epoch 93/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5696 - accuracy: 0.7100 - val_loss: 0.5385 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00093: val_loss improved from 0.54046 to 0.53854, saving model to ./model/93-0.5385.hdf5\n",
            "Epoch 94/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.5676 - accuracy: 0.7100 - val_loss: 0.5365 - val_accuracy: 0.7000\n",
            "\n",
            "Epoch 00094: val_loss improved from 0.53854 to 0.53654, saving model to ./model/94-0.5365.hdf5\n",
            "Epoch 95/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5658 - accuracy: 0.7200 - val_loss: 0.5345 - val_accuracy: 0.7400\n",
            "\n",
            "Epoch 00095: val_loss improved from 0.53654 to 0.53454, saving model to ./model/95-0.5345.hdf5\n",
            "Epoch 96/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.5639 - accuracy: 0.7200 - val_loss: 0.5325 - val_accuracy: 0.7400\n",
            "\n",
            "Epoch 00096: val_loss improved from 0.53454 to 0.53252, saving model to ./model/96-0.5325.hdf5\n",
            "Epoch 97/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.5621 - accuracy: 0.7200 - val_loss: 0.5304 - val_accuracy: 0.7400\n",
            "\n",
            "Epoch 00097: val_loss improved from 0.53252 to 0.53042, saving model to ./model/97-0.5304.hdf5\n",
            "Epoch 98/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.5601 - accuracy: 0.7200 - val_loss: 0.5285 - val_accuracy: 0.7400\n",
            "\n",
            "Epoch 00098: val_loss improved from 0.53042 to 0.52850, saving model to ./model/98-0.5285.hdf5\n",
            "Epoch 99/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.5584 - accuracy: 0.7300 - val_loss: 0.5265 - val_accuracy: 0.7400\n",
            "\n",
            "Epoch 00099: val_loss improved from 0.52850 to 0.52649, saving model to ./model/99-0.5265.hdf5\n",
            "Epoch 100/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.5565 - accuracy: 0.7300 - val_loss: 0.5246 - val_accuracy: 0.7400\n",
            "\n",
            "Epoch 00100: val_loss improved from 0.52649 to 0.52463, saving model to ./model/100-0.5246.hdf5\n",
            "Epoch 101/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.5549 - accuracy: 0.7400 - val_loss: 0.5226 - val_accuracy: 0.7400\n",
            "\n",
            "Epoch 00101: val_loss improved from 0.52463 to 0.52256, saving model to ./model/101-0.5226.hdf5\n",
            "Epoch 102/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.5530 - accuracy: 0.7300 - val_loss: 0.5209 - val_accuracy: 0.7400\n",
            "\n",
            "Epoch 00102: val_loss improved from 0.52256 to 0.52086, saving model to ./model/102-0.5209.hdf5\n",
            "Epoch 103/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5511 - accuracy: 0.7300 - val_loss: 0.5191 - val_accuracy: 0.7400\n",
            "\n",
            "Epoch 00103: val_loss improved from 0.52086 to 0.51906, saving model to ./model/103-0.5191.hdf5\n",
            "Epoch 104/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5493 - accuracy: 0.7300 - val_loss: 0.5172 - val_accuracy: 0.7600\n",
            "\n",
            "Epoch 00104: val_loss improved from 0.51906 to 0.51721, saving model to ./model/104-0.5172.hdf5\n",
            "Epoch 105/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.5476 - accuracy: 0.7400 - val_loss: 0.5153 - val_accuracy: 0.7600\n",
            "\n",
            "Epoch 00105: val_loss improved from 0.51721 to 0.51531, saving model to ./model/105-0.5153.hdf5\n",
            "Epoch 106/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5458 - accuracy: 0.7400 - val_loss: 0.5134 - val_accuracy: 0.7600\n",
            "\n",
            "Epoch 00106: val_loss improved from 0.51531 to 0.51339, saving model to ./model/106-0.5134.hdf5\n",
            "Epoch 107/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5442 - accuracy: 0.7400 - val_loss: 0.5116 - val_accuracy: 0.7600\n",
            "\n",
            "Epoch 00107: val_loss improved from 0.51339 to 0.51160, saving model to ./model/107-0.5116.hdf5\n",
            "Epoch 108/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.5427 - accuracy: 0.7400 - val_loss: 0.5095 - val_accuracy: 0.7600\n",
            "\n",
            "Epoch 00108: val_loss improved from 0.51160 to 0.50955, saving model to ./model/108-0.5095.hdf5\n",
            "Epoch 109/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.5407 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7600\n",
            "\n",
            "Epoch 00109: val_loss improved from 0.50955 to 0.50777, saving model to ./model/109-0.5078.hdf5\n",
            "Epoch 110/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.5391 - accuracy: 0.7500 - val_loss: 0.5059 - val_accuracy: 0.7800\n",
            "\n",
            "Epoch 00110: val_loss improved from 0.50777 to 0.50590, saving model to ./model/110-0.5059.hdf5\n",
            "Epoch 111/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5374 - accuracy: 0.7500 - val_loss: 0.5042 - val_accuracy: 0.7800\n",
            "\n",
            "Epoch 00111: val_loss improved from 0.50590 to 0.50420, saving model to ./model/111-0.5042.hdf5\n",
            "Epoch 112/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5357 - accuracy: 0.7500 - val_loss: 0.5025 - val_accuracy: 0.7800\n",
            "\n",
            "Epoch 00112: val_loss improved from 0.50420 to 0.50253, saving model to ./model/112-0.5025.hdf5\n",
            "Epoch 113/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.5341 - accuracy: 0.7500 - val_loss: 0.5008 - val_accuracy: 0.7800\n",
            "\n",
            "Epoch 00113: val_loss improved from 0.50253 to 0.50077, saving model to ./model/113-0.5008.hdf5\n",
            "Epoch 114/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.5325 - accuracy: 0.7500 - val_loss: 0.4991 - val_accuracy: 0.7800\n",
            "\n",
            "Epoch 00114: val_loss improved from 0.50077 to 0.49913, saving model to ./model/114-0.4991.hdf5\n",
            "Epoch 115/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.5308 - accuracy: 0.7500 - val_loss: 0.4973 - val_accuracy: 0.8000\n",
            "\n",
            "Epoch 00115: val_loss improved from 0.49913 to 0.49733, saving model to ./model/115-0.4973.hdf5\n",
            "Epoch 116/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.5292 - accuracy: 0.7500 - val_loss: 0.4955 - val_accuracy: 0.8000\n",
            "\n",
            "Epoch 00116: val_loss improved from 0.49733 to 0.49548, saving model to ./model/116-0.4955.hdf5\n",
            "Epoch 117/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.5276 - accuracy: 0.7600 - val_loss: 0.4938 - val_accuracy: 0.8000\n",
            "\n",
            "Epoch 00117: val_loss improved from 0.49548 to 0.49382, saving model to ./model/117-0.4938.hdf5\n",
            "Epoch 118/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5260 - accuracy: 0.7900 - val_loss: 0.4921 - val_accuracy: 0.8000\n",
            "\n",
            "Epoch 00118: val_loss improved from 0.49382 to 0.49210, saving model to ./model/118-0.4921.hdf5\n",
            "Epoch 119/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.5244 - accuracy: 0.8000 - val_loss: 0.4904 - val_accuracy: 0.8200\n",
            "\n",
            "Epoch 00119: val_loss improved from 0.49210 to 0.49042, saving model to ./model/119-0.4904.hdf5\n",
            "Epoch 120/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5229 - accuracy: 0.8000 - val_loss: 0.4887 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00120: val_loss improved from 0.49042 to 0.48874, saving model to ./model/120-0.4887.hdf5\n",
            "Epoch 121/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.5213 - accuracy: 0.8000 - val_loss: 0.4871 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00121: val_loss improved from 0.48874 to 0.48709, saving model to ./model/121-0.4871.hdf5\n",
            "Epoch 122/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.5197 - accuracy: 0.8000 - val_loss: 0.4854 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00122: val_loss improved from 0.48709 to 0.48538, saving model to ./model/122-0.4854.hdf5\n",
            "Epoch 123/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.5182 - accuracy: 0.8100 - val_loss: 0.4838 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00123: val_loss improved from 0.48538 to 0.48376, saving model to ./model/123-0.4838.hdf5\n",
            "Epoch 124/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.5166 - accuracy: 0.8100 - val_loss: 0.4821 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00124: val_loss improved from 0.48376 to 0.48208, saving model to ./model/124-0.4821.hdf5\n",
            "Epoch 125/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.5152 - accuracy: 0.8200 - val_loss: 0.4803 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00125: val_loss improved from 0.48208 to 0.48030, saving model to ./model/125-0.4803.hdf5\n",
            "Epoch 126/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.5136 - accuracy: 0.8200 - val_loss: 0.4787 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00126: val_loss improved from 0.48030 to 0.47870, saving model to ./model/126-0.4787.hdf5\n",
            "Epoch 127/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5121 - accuracy: 0.8200 - val_loss: 0.4771 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00127: val_loss improved from 0.47870 to 0.47707, saving model to ./model/127-0.4771.hdf5\n",
            "Epoch 128/3500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.5109 - accuracy: 0.8200 - val_loss: 0.4753 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00128: val_loss improved from 0.47707 to 0.47526, saving model to ./model/128-0.4753.hdf5\n",
            "Epoch 129/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.5092 - accuracy: 0.8300 - val_loss: 0.4737 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00129: val_loss improved from 0.47526 to 0.47368, saving model to ./model/129-0.4737.hdf5\n",
            "Epoch 130/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.5078 - accuracy: 0.8300 - val_loss: 0.4720 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00130: val_loss improved from 0.47368 to 0.47203, saving model to ./model/130-0.4720.hdf5\n",
            "Epoch 131/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5062 - accuracy: 0.8300 - val_loss: 0.4706 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00131: val_loss improved from 0.47203 to 0.47059, saving model to ./model/131-0.4706.hdf5\n",
            "Epoch 132/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.5047 - accuracy: 0.8300 - val_loss: 0.4691 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00132: val_loss improved from 0.47059 to 0.46908, saving model to ./model/132-0.4691.hdf5\n",
            "Epoch 133/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.5033 - accuracy: 0.8300 - val_loss: 0.4677 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00133: val_loss improved from 0.46908 to 0.46766, saving model to ./model/133-0.4677.hdf5\n",
            "Epoch 134/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.5021 - accuracy: 0.8300 - val_loss: 0.4664 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00134: val_loss improved from 0.46766 to 0.46641, saving model to ./model/134-0.4664.hdf5\n",
            "Epoch 135/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.5004 - accuracy: 0.8300 - val_loss: 0.4650 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00135: val_loss improved from 0.46641 to 0.46500, saving model to ./model/135-0.4650.hdf5\n",
            "Epoch 136/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.4990 - accuracy: 0.8300 - val_loss: 0.4635 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00136: val_loss improved from 0.46500 to 0.46352, saving model to ./model/136-0.4635.hdf5\n",
            "Epoch 137/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.4977 - accuracy: 0.8300 - val_loss: 0.4619 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00137: val_loss improved from 0.46352 to 0.46191, saving model to ./model/137-0.4619.hdf5\n",
            "Epoch 138/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.4963 - accuracy: 0.8300 - val_loss: 0.4604 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00138: val_loss improved from 0.46191 to 0.46041, saving model to ./model/138-0.4604.hdf5\n",
            "Epoch 139/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4949 - accuracy: 0.8300 - val_loss: 0.4589 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00139: val_loss improved from 0.46041 to 0.45893, saving model to ./model/139-0.4589.hdf5\n",
            "Epoch 140/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.4936 - accuracy: 0.8300 - val_loss: 0.4575 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00140: val_loss improved from 0.45893 to 0.45745, saving model to ./model/140-0.4575.hdf5\n",
            "Epoch 141/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4923 - accuracy: 0.8300 - val_loss: 0.4561 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00141: val_loss improved from 0.45745 to 0.45612, saving model to ./model/141-0.4561.hdf5\n",
            "Epoch 142/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.4910 - accuracy: 0.8300 - val_loss: 0.4546 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00142: val_loss improved from 0.45612 to 0.45462, saving model to ./model/142-0.4546.hdf5\n",
            "Epoch 143/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.4896 - accuracy: 0.8300 - val_loss: 0.4532 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00143: val_loss improved from 0.45462 to 0.45323, saving model to ./model/143-0.4532.hdf5\n",
            "Epoch 144/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.4884 - accuracy: 0.8300 - val_loss: 0.4520 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00144: val_loss improved from 0.45323 to 0.45199, saving model to ./model/144-0.4520.hdf5\n",
            "Epoch 145/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.4870 - accuracy: 0.8300 - val_loss: 0.4505 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00145: val_loss improved from 0.45199 to 0.45051, saving model to ./model/145-0.4505.hdf5\n",
            "Epoch 146/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4857 - accuracy: 0.8300 - val_loss: 0.4492 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00146: val_loss improved from 0.45051 to 0.44916, saving model to ./model/146-0.4492.hdf5\n",
            "Epoch 147/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.4843 - accuracy: 0.8400 - val_loss: 0.4477 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00147: val_loss improved from 0.44916 to 0.44766, saving model to ./model/147-0.4477.hdf5\n",
            "Epoch 148/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4830 - accuracy: 0.8500 - val_loss: 0.4462 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00148: val_loss improved from 0.44766 to 0.44616, saving model to ./model/148-0.4462.hdf5\n",
            "Epoch 149/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.4816 - accuracy: 0.8500 - val_loss: 0.4447 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00149: val_loss improved from 0.44616 to 0.44471, saving model to ./model/149-0.4447.hdf5\n",
            "Epoch 150/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.4803 - accuracy: 0.8500 - val_loss: 0.4433 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00150: val_loss improved from 0.44471 to 0.44331, saving model to ./model/150-0.4433.hdf5\n",
            "Epoch 151/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.4789 - accuracy: 0.8500 - val_loss: 0.4418 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00151: val_loss improved from 0.44331 to 0.44178, saving model to ./model/151-0.4418.hdf5\n",
            "Epoch 152/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4776 - accuracy: 0.8600 - val_loss: 0.4401 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 00152: val_loss improved from 0.44178 to 0.44010, saving model to ./model/152-0.4401.hdf5\n",
            "Epoch 153/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.4761 - accuracy: 0.8700 - val_loss: 0.4384 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00153: val_loss improved from 0.44010 to 0.43842, saving model to ./model/153-0.4384.hdf5\n",
            "Epoch 154/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.4748 - accuracy: 0.8800 - val_loss: 0.4367 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00154: val_loss improved from 0.43842 to 0.43667, saving model to ./model/154-0.4367.hdf5\n",
            "Epoch 155/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4732 - accuracy: 0.8800 - val_loss: 0.4350 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00155: val_loss improved from 0.43667 to 0.43501, saving model to ./model/155-0.4350.hdf5\n",
            "Epoch 156/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4717 - accuracy: 0.8800 - val_loss: 0.4333 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00156: val_loss improved from 0.43501 to 0.43331, saving model to ./model/156-0.4333.hdf5\n",
            "Epoch 157/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.4702 - accuracy: 0.8800 - val_loss: 0.4315 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00157: val_loss improved from 0.43331 to 0.43152, saving model to ./model/157-0.4315.hdf5\n",
            "Epoch 158/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4686 - accuracy: 0.8800 - val_loss: 0.4296 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00158: val_loss improved from 0.43152 to 0.42964, saving model to ./model/158-0.4296.hdf5\n",
            "Epoch 159/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.4670 - accuracy: 0.8800 - val_loss: 0.4280 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00159: val_loss improved from 0.42964 to 0.42803, saving model to ./model/159-0.4280.hdf5\n",
            "Epoch 160/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.4652 - accuracy: 0.8800 - val_loss: 0.4261 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00160: val_loss improved from 0.42803 to 0.42612, saving model to ./model/160-0.4261.hdf5\n",
            "Epoch 161/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.4635 - accuracy: 0.8800 - val_loss: 0.4243 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00161: val_loss improved from 0.42612 to 0.42433, saving model to ./model/161-0.4243.hdf5\n",
            "Epoch 162/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4620 - accuracy: 0.8800 - val_loss: 0.4226 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00162: val_loss improved from 0.42433 to 0.42262, saving model to ./model/162-0.4226.hdf5\n",
            "Epoch 163/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4601 - accuracy: 0.8800 - val_loss: 0.4205 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00163: val_loss improved from 0.42262 to 0.42055, saving model to ./model/163-0.4205.hdf5\n",
            "Epoch 164/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.4583 - accuracy: 0.8800 - val_loss: 0.4186 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00164: val_loss improved from 0.42055 to 0.41856, saving model to ./model/164-0.4186.hdf5\n",
            "Epoch 165/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.4565 - accuracy: 0.8800 - val_loss: 0.4165 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00165: val_loss improved from 0.41856 to 0.41653, saving model to ./model/165-0.4165.hdf5\n",
            "Epoch 166/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.4547 - accuracy: 0.8800 - val_loss: 0.4144 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00166: val_loss improved from 0.41653 to 0.41441, saving model to ./model/166-0.4144.hdf5\n",
            "Epoch 167/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.4529 - accuracy: 0.8900 - val_loss: 0.4123 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00167: val_loss improved from 0.41441 to 0.41228, saving model to ./model/167-0.4123.hdf5\n",
            "Epoch 168/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.4511 - accuracy: 0.8900 - val_loss: 0.4101 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00168: val_loss improved from 0.41228 to 0.41009, saving model to ./model/168-0.4101.hdf5\n",
            "Epoch 169/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.4493 - accuracy: 0.8900 - val_loss: 0.4082 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00169: val_loss improved from 0.41009 to 0.40818, saving model to ./model/169-0.4082.hdf5\n",
            "Epoch 170/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.4474 - accuracy: 0.8900 - val_loss: 0.4060 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00170: val_loss improved from 0.40818 to 0.40604, saving model to ./model/170-0.4060.hdf5\n",
            "Epoch 171/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.4456 - accuracy: 0.8900 - val_loss: 0.4042 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00171: val_loss improved from 0.40604 to 0.40420, saving model to ./model/171-0.4042.hdf5\n",
            "Epoch 172/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.4441 - accuracy: 0.8900 - val_loss: 0.4023 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00172: val_loss improved from 0.40420 to 0.40227, saving model to ./model/172-0.4023.hdf5\n",
            "Epoch 173/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.4426 - accuracy: 0.8900 - val_loss: 0.4004 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00173: val_loss improved from 0.40227 to 0.40043, saving model to ./model/173-0.4004.hdf5\n",
            "Epoch 174/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.4415 - accuracy: 0.9000 - val_loss: 0.3987 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00174: val_loss improved from 0.40043 to 0.39872, saving model to ./model/174-0.3987.hdf5\n",
            "Epoch 175/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.4401 - accuracy: 0.9200 - val_loss: 0.3970 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00175: val_loss improved from 0.39872 to 0.39698, saving model to ./model/175-0.3970.hdf5\n",
            "Epoch 176/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4383 - accuracy: 0.9200 - val_loss: 0.3953 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00176: val_loss improved from 0.39698 to 0.39527, saving model to ./model/176-0.3953.hdf5\n",
            "Epoch 177/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4369 - accuracy: 0.9200 - val_loss: 0.3939 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00177: val_loss improved from 0.39527 to 0.39387, saving model to ./model/177-0.3939.hdf5\n",
            "Epoch 178/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.4353 - accuracy: 0.9200 - val_loss: 0.3923 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00178: val_loss improved from 0.39387 to 0.39228, saving model to ./model/178-0.3923.hdf5\n",
            "Epoch 179/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4338 - accuracy: 0.9200 - val_loss: 0.3909 - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00179: val_loss improved from 0.39228 to 0.39094, saving model to ./model/179-0.3909.hdf5\n",
            "Epoch 180/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4322 - accuracy: 0.9200 - val_loss: 0.3896 - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00180: val_loss improved from 0.39094 to 0.38961, saving model to ./model/180-0.3896.hdf5\n",
            "Epoch 181/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.4310 - accuracy: 0.9200 - val_loss: 0.3885 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00181: val_loss improved from 0.38961 to 0.38849, saving model to ./model/181-0.3885.hdf5\n",
            "Epoch 182/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.4294 - accuracy: 0.9200 - val_loss: 0.3871 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00182: val_loss improved from 0.38849 to 0.38709, saving model to ./model/182-0.3871.hdf5\n",
            "Epoch 183/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.4280 - accuracy: 0.9300 - val_loss: 0.3856 - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00183: val_loss improved from 0.38709 to 0.38560, saving model to ./model/183-0.3856.hdf5\n",
            "Epoch 184/3500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.4267 - accuracy: 0.9300 - val_loss: 0.3844 - val_accuracy: 0.8800\n",
            "\n",
            "Epoch 00184: val_loss improved from 0.38560 to 0.38440, saving model to ./model/184-0.3844.hdf5\n",
            "Epoch 185/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.4252 - accuracy: 0.9300 - val_loss: 0.3829 - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00185: val_loss improved from 0.38440 to 0.38288, saving model to ./model/185-0.3829.hdf5\n",
            "Epoch 186/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.4238 - accuracy: 0.9300 - val_loss: 0.3815 - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00186: val_loss improved from 0.38288 to 0.38148, saving model to ./model/186-0.3815.hdf5\n",
            "Epoch 187/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.4224 - accuracy: 0.9300 - val_loss: 0.3801 - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00187: val_loss improved from 0.38148 to 0.38007, saving model to ./model/187-0.3801.hdf5\n",
            "Epoch 188/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.4210 - accuracy: 0.9300 - val_loss: 0.3786 - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00188: val_loss improved from 0.38007 to 0.37865, saving model to ./model/188-0.3786.hdf5\n",
            "Epoch 189/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.4196 - accuracy: 0.9300 - val_loss: 0.3771 - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00189: val_loss improved from 0.37865 to 0.37709, saving model to ./model/189-0.3771.hdf5\n",
            "Epoch 190/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.4184 - accuracy: 0.9300 - val_loss: 0.3758 - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 00190: val_loss improved from 0.37709 to 0.37580, saving model to ./model/190-0.3758.hdf5\n",
            "Epoch 191/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.4169 - accuracy: 0.9300 - val_loss: 0.3742 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00191: val_loss improved from 0.37580 to 0.37418, saving model to ./model/191-0.3742.hdf5\n",
            "Epoch 192/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.4156 - accuracy: 0.9300 - val_loss: 0.3726 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00192: val_loss improved from 0.37418 to 0.37258, saving model to ./model/192-0.3726.hdf5\n",
            "Epoch 193/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4142 - accuracy: 0.9300 - val_loss: 0.3713 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00193: val_loss improved from 0.37258 to 0.37132, saving model to ./model/193-0.3713.hdf5\n",
            "Epoch 194/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4128 - accuracy: 0.9300 - val_loss: 0.3698 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00194: val_loss improved from 0.37132 to 0.36977, saving model to ./model/194-0.3698.hdf5\n",
            "Epoch 195/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.4115 - accuracy: 0.9400 - val_loss: 0.3683 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00195: val_loss improved from 0.36977 to 0.36825, saving model to ./model/195-0.3683.hdf5\n",
            "Epoch 196/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.4102 - accuracy: 0.9500 - val_loss: 0.3667 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00196: val_loss improved from 0.36825 to 0.36673, saving model to ./model/196-0.3667.hdf5\n",
            "Epoch 197/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.4087 - accuracy: 0.9500 - val_loss: 0.3654 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00197: val_loss improved from 0.36673 to 0.36540, saving model to ./model/197-0.3654.hdf5\n",
            "Epoch 198/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.4076 - accuracy: 0.9600 - val_loss: 0.3640 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00198: val_loss improved from 0.36540 to 0.36404, saving model to ./model/198-0.3640.hdf5\n",
            "Epoch 199/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4062 - accuracy: 0.9500 - val_loss: 0.3629 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00199: val_loss improved from 0.36404 to 0.36291, saving model to ./model/199-0.3629.hdf5\n",
            "Epoch 200/3500\n",
            "2/2 [==============================] - 0s 17ms/step - loss: 0.4048 - accuracy: 0.9500 - val_loss: 0.3617 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00200: val_loss improved from 0.36291 to 0.36170, saving model to ./model/200-0.3617.hdf5\n",
            "Epoch 201/3500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.4035 - accuracy: 0.9500 - val_loss: 0.3604 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00201: val_loss improved from 0.36170 to 0.36037, saving model to ./model/201-0.3604.hdf5\n",
            "Epoch 202/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.4022 - accuracy: 0.9500 - val_loss: 0.3591 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00202: val_loss improved from 0.36037 to 0.35909, saving model to ./model/202-0.3591.hdf5\n",
            "Epoch 203/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.4009 - accuracy: 0.9500 - val_loss: 0.3577 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00203: val_loss improved from 0.35909 to 0.35772, saving model to ./model/203-0.3577.hdf5\n",
            "Epoch 204/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.3998 - accuracy: 0.9600 - val_loss: 0.3562 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00204: val_loss improved from 0.35772 to 0.35620, saving model to ./model/204-0.3562.hdf5\n",
            "Epoch 205/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.3984 - accuracy: 0.9700 - val_loss: 0.3549 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00205: val_loss improved from 0.35620 to 0.35494, saving model to ./model/205-0.3549.hdf5\n",
            "Epoch 206/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3971 - accuracy: 0.9700 - val_loss: 0.3537 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00206: val_loss improved from 0.35494 to 0.35374, saving model to ./model/206-0.3537.hdf5\n",
            "Epoch 207/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.3959 - accuracy: 0.9700 - val_loss: 0.3525 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00207: val_loss improved from 0.35374 to 0.35251, saving model to ./model/207-0.3525.hdf5\n",
            "Epoch 208/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3945 - accuracy: 0.9700 - val_loss: 0.3512 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00208: val_loss improved from 0.35251 to 0.35120, saving model to ./model/208-0.3512.hdf5\n",
            "Epoch 209/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3933 - accuracy: 0.9700 - val_loss: 0.3499 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00209: val_loss improved from 0.35120 to 0.34994, saving model to ./model/209-0.3499.hdf5\n",
            "Epoch 210/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3921 - accuracy: 0.9800 - val_loss: 0.3485 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00210: val_loss improved from 0.34994 to 0.34853, saving model to ./model/210-0.3485.hdf5\n",
            "Epoch 211/3500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.3907 - accuracy: 0.9800 - val_loss: 0.3471 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00211: val_loss improved from 0.34853 to 0.34710, saving model to ./model/211-0.3471.hdf5\n",
            "Epoch 212/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3895 - accuracy: 0.9800 - val_loss: 0.3458 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00212: val_loss improved from 0.34710 to 0.34578, saving model to ./model/212-0.3458.hdf5\n",
            "Epoch 213/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3883 - accuracy: 0.9800 - val_loss: 0.3445 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00213: val_loss improved from 0.34578 to 0.34454, saving model to ./model/213-0.3445.hdf5\n",
            "Epoch 214/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3870 - accuracy: 0.9800 - val_loss: 0.3432 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00214: val_loss improved from 0.34454 to 0.34318, saving model to ./model/214-0.3432.hdf5\n",
            "Epoch 215/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3858 - accuracy: 0.9800 - val_loss: 0.3418 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00215: val_loss improved from 0.34318 to 0.34184, saving model to ./model/215-0.3418.hdf5\n",
            "Epoch 216/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3847 - accuracy: 0.9800 - val_loss: 0.3403 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00216: val_loss improved from 0.34184 to 0.34031, saving model to ./model/216-0.3403.hdf5\n",
            "Epoch 217/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3833 - accuracy: 0.9800 - val_loss: 0.3391 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00217: val_loss improved from 0.34031 to 0.33912, saving model to ./model/217-0.3391.hdf5\n",
            "Epoch 218/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3821 - accuracy: 0.9800 - val_loss: 0.3378 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00218: val_loss improved from 0.33912 to 0.33784, saving model to ./model/218-0.3378.hdf5\n",
            "Epoch 219/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.3809 - accuracy: 0.9800 - val_loss: 0.3365 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00219: val_loss improved from 0.33784 to 0.33653, saving model to ./model/219-0.3365.hdf5\n",
            "Epoch 220/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3797 - accuracy: 0.9800 - val_loss: 0.3354 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00220: val_loss improved from 0.33653 to 0.33538, saving model to ./model/220-0.3354.hdf5\n",
            "Epoch 221/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3785 - accuracy: 0.9800 - val_loss: 0.3342 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00221: val_loss improved from 0.33538 to 0.33418, saving model to ./model/221-0.3342.hdf5\n",
            "Epoch 222/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.3773 - accuracy: 0.9800 - val_loss: 0.3328 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00222: val_loss improved from 0.33418 to 0.33279, saving model to ./model/222-0.3328.hdf5\n",
            "Epoch 223/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3761 - accuracy: 0.9800 - val_loss: 0.3316 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00223: val_loss improved from 0.33279 to 0.33162, saving model to ./model/223-0.3316.hdf5\n",
            "Epoch 224/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3749 - accuracy: 0.9800 - val_loss: 0.3305 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00224: val_loss improved from 0.33162 to 0.33052, saving model to ./model/224-0.3305.hdf5\n",
            "Epoch 225/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3738 - accuracy: 0.9800 - val_loss: 0.3291 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00225: val_loss improved from 0.33052 to 0.32914, saving model to ./model/225-0.3291.hdf5\n",
            "Epoch 226/3500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.3726 - accuracy: 0.9800 - val_loss: 0.3280 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00226: val_loss improved from 0.32914 to 0.32801, saving model to ./model/226-0.3280.hdf5\n",
            "Epoch 227/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3714 - accuracy: 0.9800 - val_loss: 0.3266 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00227: val_loss improved from 0.32801 to 0.32660, saving model to ./model/227-0.3266.hdf5\n",
            "Epoch 228/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3702 - accuracy: 0.9800 - val_loss: 0.3252 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00228: val_loss improved from 0.32660 to 0.32524, saving model to ./model/228-0.3252.hdf5\n",
            "Epoch 229/3500\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.3690 - accuracy: 0.9800 - val_loss: 0.3242 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00229: val_loss improved from 0.32524 to 0.32416, saving model to ./model/229-0.3242.hdf5\n",
            "Epoch 230/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3679 - accuracy: 0.9800 - val_loss: 0.3231 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00230: val_loss improved from 0.32416 to 0.32310, saving model to ./model/230-0.3231.hdf5\n",
            "Epoch 231/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.3668 - accuracy: 0.9800 - val_loss: 0.3217 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00231: val_loss improved from 0.32310 to 0.32165, saving model to ./model/231-0.3217.hdf5\n",
            "Epoch 232/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3655 - accuracy: 0.9800 - val_loss: 0.3204 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00232: val_loss improved from 0.32165 to 0.32042, saving model to ./model/232-0.3204.hdf5\n",
            "Epoch 233/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3644 - accuracy: 0.9800 - val_loss: 0.3193 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00233: val_loss improved from 0.32042 to 0.31932, saving model to ./model/233-0.3193.hdf5\n",
            "Epoch 234/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3632 - accuracy: 0.9800 - val_loss: 0.3181 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00234: val_loss improved from 0.31932 to 0.31813, saving model to ./model/234-0.3181.hdf5\n",
            "Epoch 235/3500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.3621 - accuracy: 0.9800 - val_loss: 0.3171 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00235: val_loss improved from 0.31813 to 0.31707, saving model to ./model/235-0.3171.hdf5\n",
            "Epoch 236/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3609 - accuracy: 0.9800 - val_loss: 0.3160 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00236: val_loss improved from 0.31707 to 0.31598, saving model to ./model/236-0.3160.hdf5\n",
            "Epoch 237/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3598 - accuracy: 0.9800 - val_loss: 0.3149 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00237: val_loss improved from 0.31598 to 0.31492, saving model to ./model/237-0.3149.hdf5\n",
            "Epoch 238/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3588 - accuracy: 0.9800 - val_loss: 0.3136 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00238: val_loss improved from 0.31492 to 0.31359, saving model to ./model/238-0.3136.hdf5\n",
            "Epoch 239/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3575 - accuracy: 0.9800 - val_loss: 0.3125 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00239: val_loss improved from 0.31359 to 0.31247, saving model to ./model/239-0.3125.hdf5\n",
            "Epoch 240/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.3564 - accuracy: 0.9800 - val_loss: 0.3113 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00240: val_loss improved from 0.31247 to 0.31128, saving model to ./model/240-0.3113.hdf5\n",
            "Epoch 241/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.3553 - accuracy: 0.9800 - val_loss: 0.3103 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00241: val_loss improved from 0.31128 to 0.31026, saving model to ./model/241-0.3103.hdf5\n",
            "Epoch 242/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.3542 - accuracy: 0.9800 - val_loss: 0.3093 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00242: val_loss improved from 0.31026 to 0.30928, saving model to ./model/242-0.3093.hdf5\n",
            "Epoch 243/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3531 - accuracy: 0.9800 - val_loss: 0.3082 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00243: val_loss improved from 0.30928 to 0.30822, saving model to ./model/243-0.3082.hdf5\n",
            "Epoch 244/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3520 - accuracy: 0.9800 - val_loss: 0.3071 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00244: val_loss improved from 0.30822 to 0.30709, saving model to ./model/244-0.3071.hdf5\n",
            "Epoch 245/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3509 - accuracy: 0.9800 - val_loss: 0.3057 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00245: val_loss improved from 0.30709 to 0.30573, saving model to ./model/245-0.3057.hdf5\n",
            "Epoch 246/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3499 - accuracy: 0.9800 - val_loss: 0.3045 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00246: val_loss improved from 0.30573 to 0.30446, saving model to ./model/246-0.3045.hdf5\n",
            "Epoch 247/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3487 - accuracy: 0.9800 - val_loss: 0.3034 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00247: val_loss improved from 0.30446 to 0.30341, saving model to ./model/247-0.3034.hdf5\n",
            "Epoch 248/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3476 - accuracy: 0.9800 - val_loss: 0.3022 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00248: val_loss improved from 0.30341 to 0.30224, saving model to ./model/248-0.3022.hdf5\n",
            "Epoch 249/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.3465 - accuracy: 0.9800 - val_loss: 0.3012 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00249: val_loss improved from 0.30224 to 0.30119, saving model to ./model/249-0.3012.hdf5\n",
            "Epoch 250/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3455 - accuracy: 0.9800 - val_loss: 0.3000 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00250: val_loss improved from 0.30119 to 0.30003, saving model to ./model/250-0.3000.hdf5\n",
            "Epoch 251/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.3443 - accuracy: 0.9800 - val_loss: 0.2990 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00251: val_loss improved from 0.30003 to 0.29897, saving model to ./model/251-0.2990.hdf5\n",
            "Epoch 252/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3438 - accuracy: 0.9800 - val_loss: 0.2976 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00252: val_loss improved from 0.29897 to 0.29762, saving model to ./model/252-0.2976.hdf5\n",
            "Epoch 253/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3423 - accuracy: 0.9800 - val_loss: 0.2968 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00253: val_loss improved from 0.29762 to 0.29679, saving model to ./model/253-0.2968.hdf5\n",
            "Epoch 254/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3415 - accuracy: 0.9800 - val_loss: 0.2955 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00254: val_loss improved from 0.29679 to 0.29553, saving model to ./model/254-0.2955.hdf5\n",
            "Epoch 255/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3401 - accuracy: 0.9800 - val_loss: 0.2946 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00255: val_loss improved from 0.29553 to 0.29459, saving model to ./model/255-0.2946.hdf5\n",
            "Epoch 256/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3391 - accuracy: 0.9800 - val_loss: 0.2938 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00256: val_loss improved from 0.29459 to 0.29377, saving model to ./model/256-0.2938.hdf5\n",
            "Epoch 257/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.3381 - accuracy: 0.9800 - val_loss: 0.2927 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00257: val_loss improved from 0.29377 to 0.29273, saving model to ./model/257-0.2927.hdf5\n",
            "Epoch 258/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3371 - accuracy: 0.9800 - val_loss: 0.2920 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00258: val_loss improved from 0.29273 to 0.29197, saving model to ./model/258-0.2920.hdf5\n",
            "Epoch 259/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.3359 - accuracy: 0.9800 - val_loss: 0.2910 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00259: val_loss improved from 0.29197 to 0.29095, saving model to ./model/259-0.2910.hdf5\n",
            "Epoch 260/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3350 - accuracy: 0.9800 - val_loss: 0.2902 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00260: val_loss improved from 0.29095 to 0.29016, saving model to ./model/260-0.2902.hdf5\n",
            "Epoch 261/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3339 - accuracy: 0.9800 - val_loss: 0.2892 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00261: val_loss improved from 0.29016 to 0.28923, saving model to ./model/261-0.2892.hdf5\n",
            "Epoch 262/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.3329 - accuracy: 0.9800 - val_loss: 0.2880 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00262: val_loss improved from 0.28923 to 0.28801, saving model to ./model/262-0.2880.hdf5\n",
            "Epoch 263/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.3319 - accuracy: 0.9800 - val_loss: 0.2868 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00263: val_loss improved from 0.28801 to 0.28684, saving model to ./model/263-0.2868.hdf5\n",
            "Epoch 264/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3308 - accuracy: 0.9800 - val_loss: 0.2858 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00264: val_loss improved from 0.28684 to 0.28581, saving model to ./model/264-0.2858.hdf5\n",
            "Epoch 265/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.3299 - accuracy: 0.9800 - val_loss: 0.2849 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00265: val_loss improved from 0.28581 to 0.28489, saving model to ./model/265-0.2849.hdf5\n",
            "Epoch 266/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3288 - accuracy: 0.9800 - val_loss: 0.2839 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00266: val_loss improved from 0.28489 to 0.28386, saving model to ./model/266-0.2839.hdf5\n",
            "Epoch 267/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.3278 - accuracy: 0.9800 - val_loss: 0.2827 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00267: val_loss improved from 0.28386 to 0.28273, saving model to ./model/267-0.2827.hdf5\n",
            "Epoch 268/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3268 - accuracy: 0.9800 - val_loss: 0.2817 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00268: val_loss improved from 0.28273 to 0.28166, saving model to ./model/268-0.2817.hdf5\n",
            "Epoch 269/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.3258 - accuracy: 0.9800 - val_loss: 0.2806 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00269: val_loss improved from 0.28166 to 0.28062, saving model to ./model/269-0.2806.hdf5\n",
            "Epoch 270/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.3248 - accuracy: 0.9800 - val_loss: 0.2796 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00270: val_loss improved from 0.28062 to 0.27959, saving model to ./model/270-0.2796.hdf5\n",
            "Epoch 271/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3238 - accuracy: 0.9800 - val_loss: 0.2787 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00271: val_loss improved from 0.27959 to 0.27871, saving model to ./model/271-0.2787.hdf5\n",
            "Epoch 272/3500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.3229 - accuracy: 0.9800 - val_loss: 0.2779 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00272: val_loss improved from 0.27871 to 0.27789, saving model to ./model/272-0.2779.hdf5\n",
            "Epoch 273/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3219 - accuracy: 0.9800 - val_loss: 0.2771 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00273: val_loss improved from 0.27789 to 0.27707, saving model to ./model/273-0.2771.hdf5\n",
            "Epoch 274/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.3208 - accuracy: 0.9800 - val_loss: 0.2761 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00274: val_loss improved from 0.27707 to 0.27606, saving model to ./model/274-0.2761.hdf5\n",
            "Epoch 275/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.3198 - accuracy: 0.9800 - val_loss: 0.2751 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00275: val_loss improved from 0.27606 to 0.27505, saving model to ./model/275-0.2751.hdf5\n",
            "Epoch 276/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3190 - accuracy: 0.9800 - val_loss: 0.2739 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00276: val_loss improved from 0.27505 to 0.27394, saving model to ./model/276-0.2739.hdf5\n",
            "Epoch 277/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3179 - accuracy: 0.9800 - val_loss: 0.2730 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00277: val_loss improved from 0.27394 to 0.27301, saving model to ./model/277-0.2730.hdf5\n",
            "Epoch 278/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.3170 - accuracy: 0.9800 - val_loss: 0.2721 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00278: val_loss improved from 0.27301 to 0.27208, saving model to ./model/278-0.2721.hdf5\n",
            "Epoch 279/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.3162 - accuracy: 0.9800 - val_loss: 0.2710 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00279: val_loss improved from 0.27208 to 0.27097, saving model to ./model/279-0.2710.hdf5\n",
            "Epoch 280/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3152 - accuracy: 0.9800 - val_loss: 0.2703 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00280: val_loss improved from 0.27097 to 0.27035, saving model to ./model/280-0.2703.hdf5\n",
            "Epoch 281/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.3148 - accuracy: 0.9800 - val_loss: 0.2700 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00281: val_loss improved from 0.27035 to 0.26995, saving model to ./model/281-0.2700.hdf5\n",
            "Epoch 282/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3131 - accuracy: 0.9800 - val_loss: 0.2690 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00282: val_loss improved from 0.26995 to 0.26895, saving model to ./model/282-0.2690.hdf5\n",
            "Epoch 283/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3122 - accuracy: 0.9800 - val_loss: 0.2679 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00283: val_loss improved from 0.26895 to 0.26785, saving model to ./model/283-0.2679.hdf5\n",
            "Epoch 284/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.3113 - accuracy: 0.9800 - val_loss: 0.2670 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00284: val_loss improved from 0.26785 to 0.26696, saving model to ./model/284-0.2670.hdf5\n",
            "Epoch 285/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.3104 - accuracy: 0.9800 - val_loss: 0.2658 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00285: val_loss improved from 0.26696 to 0.26582, saving model to ./model/285-0.2658.hdf5\n",
            "Epoch 286/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3094 - accuracy: 0.9800 - val_loss: 0.2648 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00286: val_loss improved from 0.26582 to 0.26478, saving model to ./model/286-0.2648.hdf5\n",
            "Epoch 287/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3086 - accuracy: 0.9800 - val_loss: 0.2636 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00287: val_loss improved from 0.26478 to 0.26363, saving model to ./model/287-0.2636.hdf5\n",
            "Epoch 288/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3077 - accuracy: 0.9800 - val_loss: 0.2630 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00288: val_loss improved from 0.26363 to 0.26298, saving model to ./model/288-0.2630.hdf5\n",
            "Epoch 289/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3066 - accuracy: 0.9800 - val_loss: 0.2622 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00289: val_loss improved from 0.26298 to 0.26218, saving model to ./model/289-0.2622.hdf5\n",
            "Epoch 290/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.3057 - accuracy: 0.9800 - val_loss: 0.2614 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00290: val_loss improved from 0.26218 to 0.26141, saving model to ./model/290-0.2614.hdf5\n",
            "Epoch 291/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.3048 - accuracy: 0.9800 - val_loss: 0.2605 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00291: val_loss improved from 0.26141 to 0.26048, saving model to ./model/291-0.2605.hdf5\n",
            "Epoch 292/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.3039 - accuracy: 0.9800 - val_loss: 0.2595 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00292: val_loss improved from 0.26048 to 0.25952, saving model to ./model/292-0.2595.hdf5\n",
            "Epoch 293/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.3029 - accuracy: 0.9800 - val_loss: 0.2586 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00293: val_loss improved from 0.25952 to 0.25862, saving model to ./model/293-0.2586.hdf5\n",
            "Epoch 294/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.3020 - accuracy: 0.9800 - val_loss: 0.2578 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00294: val_loss improved from 0.25862 to 0.25777, saving model to ./model/294-0.2578.hdf5\n",
            "Epoch 295/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.3013 - accuracy: 0.9800 - val_loss: 0.2568 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00295: val_loss improved from 0.25777 to 0.25675, saving model to ./model/295-0.2568.hdf5\n",
            "Epoch 296/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.3003 - accuracy: 0.9800 - val_loss: 0.2561 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00296: val_loss improved from 0.25675 to 0.25612, saving model to ./model/296-0.2561.hdf5\n",
            "Epoch 297/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2994 - accuracy: 0.9800 - val_loss: 0.2552 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00297: val_loss improved from 0.25612 to 0.25519, saving model to ./model/297-0.2552.hdf5\n",
            "Epoch 298/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2985 - accuracy: 0.9800 - val_loss: 0.2542 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00298: val_loss improved from 0.25519 to 0.25423, saving model to ./model/298-0.2542.hdf5\n",
            "Epoch 299/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.2976 - accuracy: 0.9800 - val_loss: 0.2536 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00299: val_loss improved from 0.25423 to 0.25360, saving model to ./model/299-0.2536.hdf5\n",
            "Epoch 300/3500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2966 - accuracy: 0.9800 - val_loss: 0.2529 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00300: val_loss improved from 0.25360 to 0.25285, saving model to ./model/300-0.2529.hdf5\n",
            "Epoch 301/3500\n",
            "2/2 [==============================] - 0s 18ms/step - loss: 0.2959 - accuracy: 0.9800 - val_loss: 0.2519 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00301: val_loss improved from 0.25285 to 0.25192, saving model to ./model/301-0.2519.hdf5\n",
            "Epoch 302/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2949 - accuracy: 0.9800 - val_loss: 0.2510 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00302: val_loss improved from 0.25192 to 0.25103, saving model to ./model/302-0.2510.hdf5\n",
            "Epoch 303/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.2940 - accuracy: 0.9800 - val_loss: 0.2503 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00303: val_loss improved from 0.25103 to 0.25032, saving model to ./model/303-0.2503.hdf5\n",
            "Epoch 304/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.2932 - accuracy: 0.9800 - val_loss: 0.2497 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00304: val_loss improved from 0.25032 to 0.24967, saving model to ./model/304-0.2497.hdf5\n",
            "Epoch 305/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2923 - accuracy: 0.9800 - val_loss: 0.2489 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00305: val_loss improved from 0.24967 to 0.24885, saving model to ./model/305-0.2489.hdf5\n",
            "Epoch 306/3500\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.2915 - accuracy: 0.9800 - val_loss: 0.2479 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00306: val_loss improved from 0.24885 to 0.24793, saving model to ./model/306-0.2479.hdf5\n",
            "Epoch 307/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.2905 - accuracy: 0.9800 - val_loss: 0.2472 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00307: val_loss improved from 0.24793 to 0.24718, saving model to ./model/307-0.2472.hdf5\n",
            "Epoch 308/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2900 - accuracy: 0.9800 - val_loss: 0.2461 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00308: val_loss improved from 0.24718 to 0.24608, saving model to ./model/308-0.2461.hdf5\n",
            "Epoch 309/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2888 - accuracy: 0.9800 - val_loss: 0.2454 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00309: val_loss improved from 0.24608 to 0.24538, saving model to ./model/309-0.2454.hdf5\n",
            "Epoch 310/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2886 - accuracy: 0.9800 - val_loss: 0.2442 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00310: val_loss improved from 0.24538 to 0.24420, saving model to ./model/310-0.2442.hdf5\n",
            "Epoch 311/3500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.2871 - accuracy: 0.9800 - val_loss: 0.2435 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00311: val_loss improved from 0.24420 to 0.24352, saving model to ./model/311-0.2435.hdf5\n",
            "Epoch 312/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.2863 - accuracy: 0.9800 - val_loss: 0.2430 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00312: val_loss improved from 0.24352 to 0.24300, saving model to ./model/312-0.2430.hdf5\n",
            "Epoch 313/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2855 - accuracy: 0.9800 - val_loss: 0.2425 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00313: val_loss improved from 0.24300 to 0.24246, saving model to ./model/313-0.2425.hdf5\n",
            "Epoch 314/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.2848 - accuracy: 0.9800 - val_loss: 0.2420 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00314: val_loss improved from 0.24246 to 0.24195, saving model to ./model/314-0.2420.hdf5\n",
            "Epoch 315/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.2838 - accuracy: 0.9800 - val_loss: 0.2413 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00315: val_loss improved from 0.24195 to 0.24126, saving model to ./model/315-0.2413.hdf5\n",
            "Epoch 316/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.2830 - accuracy: 0.9800 - val_loss: 0.2405 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00316: val_loss improved from 0.24126 to 0.24047, saving model to ./model/316-0.2405.hdf5\n",
            "Epoch 317/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2822 - accuracy: 0.9800 - val_loss: 0.2393 - val_accuracy: 0.9400\n",
            "\n",
            "Epoch 00317: val_loss improved from 0.24047 to 0.23935, saving model to ./model/317-0.2393.hdf5\n",
            "Epoch 318/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.2813 - accuracy: 0.9800 - val_loss: 0.2383 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00318: val_loss improved from 0.23935 to 0.23829, saving model to ./model/318-0.2383.hdf5\n",
            "Epoch 319/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.2804 - accuracy: 0.9800 - val_loss: 0.2373 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00319: val_loss improved from 0.23829 to 0.23732, saving model to ./model/319-0.2373.hdf5\n",
            "Epoch 320/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.2797 - accuracy: 0.9800 - val_loss: 0.2363 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00320: val_loss improved from 0.23732 to 0.23631, saving model to ./model/320-0.2363.hdf5\n",
            "Epoch 321/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.2788 - accuracy: 0.9800 - val_loss: 0.2355 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00321: val_loss improved from 0.23631 to 0.23547, saving model to ./model/321-0.2355.hdf5\n",
            "Epoch 322/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2780 - accuracy: 0.9800 - val_loss: 0.2349 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00322: val_loss improved from 0.23547 to 0.23485, saving model to ./model/322-0.2349.hdf5\n",
            "Epoch 323/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.2771 - accuracy: 0.9800 - val_loss: 0.2342 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00323: val_loss improved from 0.23485 to 0.23420, saving model to ./model/323-0.2342.hdf5\n",
            "Epoch 324/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2765 - accuracy: 0.9800 - val_loss: 0.2333 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00324: val_loss improved from 0.23420 to 0.23329, saving model to ./model/324-0.2333.hdf5\n",
            "Epoch 325/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2759 - accuracy: 0.9800 - val_loss: 0.2323 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00325: val_loss improved from 0.23329 to 0.23234, saving model to ./model/325-0.2323.hdf5\n",
            "Epoch 326/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.2749 - accuracy: 0.9800 - val_loss: 0.2320 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00326: val_loss improved from 0.23234 to 0.23202, saving model to ./model/326-0.2320.hdf5\n",
            "Epoch 327/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.2739 - accuracy: 0.9800 - val_loss: 0.2313 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00327: val_loss improved from 0.23202 to 0.23134, saving model to ./model/327-0.2313.hdf5\n",
            "Epoch 328/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.2731 - accuracy: 0.9800 - val_loss: 0.2307 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00328: val_loss improved from 0.23134 to 0.23066, saving model to ./model/328-0.2307.hdf5\n",
            "Epoch 329/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2723 - accuracy: 0.9800 - val_loss: 0.2301 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00329: val_loss improved from 0.23066 to 0.23015, saving model to ./model/329-0.2301.hdf5\n",
            "Epoch 330/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2715 - accuracy: 0.9800 - val_loss: 0.2294 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00330: val_loss improved from 0.23015 to 0.22939, saving model to ./model/330-0.2294.hdf5\n",
            "Epoch 331/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.2707 - accuracy: 0.9800 - val_loss: 0.2287 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00331: val_loss improved from 0.22939 to 0.22873, saving model to ./model/331-0.2287.hdf5\n",
            "Epoch 332/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.2699 - accuracy: 0.9800 - val_loss: 0.2280 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00332: val_loss improved from 0.22873 to 0.22801, saving model to ./model/332-0.2280.hdf5\n",
            "Epoch 333/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.2694 - accuracy: 0.9800 - val_loss: 0.2270 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00333: val_loss improved from 0.22801 to 0.22701, saving model to ./model/333-0.2270.hdf5\n",
            "Epoch 334/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.2683 - accuracy: 0.9800 - val_loss: 0.2263 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00334: val_loss improved from 0.22701 to 0.22629, saving model to ./model/334-0.2263.hdf5\n",
            "Epoch 335/3500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.2676 - accuracy: 0.9800 - val_loss: 0.2256 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00335: val_loss improved from 0.22629 to 0.22562, saving model to ./model/335-0.2256.hdf5\n",
            "Epoch 336/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2668 - accuracy: 0.9800 - val_loss: 0.2250 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00336: val_loss improved from 0.22562 to 0.22499, saving model to ./model/336-0.2250.hdf5\n",
            "Epoch 337/3500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.2660 - accuracy: 0.9800 - val_loss: 0.2243 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00337: val_loss improved from 0.22499 to 0.22429, saving model to ./model/337-0.2243.hdf5\n",
            "Epoch 338/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.2653 - accuracy: 0.9800 - val_loss: 0.2236 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00338: val_loss improved from 0.22429 to 0.22362, saving model to ./model/338-0.2236.hdf5\n",
            "Epoch 339/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.2645 - accuracy: 0.9800 - val_loss: 0.2229 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00339: val_loss improved from 0.22362 to 0.22294, saving model to ./model/339-0.2229.hdf5\n",
            "Epoch 340/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.2638 - accuracy: 0.9800 - val_loss: 0.2220 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00340: val_loss improved from 0.22294 to 0.22204, saving model to ./model/340-0.2220.hdf5\n",
            "Epoch 341/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2631 - accuracy: 0.9800 - val_loss: 0.2211 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00341: val_loss improved from 0.22204 to 0.22109, saving model to ./model/341-0.2211.hdf5\n",
            "Epoch 342/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.2622 - accuracy: 0.9800 - val_loss: 0.2205 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00342: val_loss improved from 0.22109 to 0.22051, saving model to ./model/342-0.2205.hdf5\n",
            "Epoch 343/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.2617 - accuracy: 0.9800 - val_loss: 0.2196 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00343: val_loss improved from 0.22051 to 0.21959, saving model to ./model/343-0.2196.hdf5\n",
            "Epoch 344/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2607 - accuracy: 0.9800 - val_loss: 0.2191 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00344: val_loss improved from 0.21959 to 0.21912, saving model to ./model/344-0.2191.hdf5\n",
            "Epoch 345/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.2599 - accuracy: 0.9800 - val_loss: 0.2186 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00345: val_loss improved from 0.21912 to 0.21857, saving model to ./model/345-0.2186.hdf5\n",
            "Epoch 346/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2598 - accuracy: 0.9800 - val_loss: 0.2184 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00346: val_loss improved from 0.21857 to 0.21836, saving model to ./model/346-0.2184.hdf5\n",
            "Epoch 347/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.2585 - accuracy: 0.9800 - val_loss: 0.2178 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00347: val_loss improved from 0.21836 to 0.21778, saving model to ./model/347-0.2178.hdf5\n",
            "Epoch 348/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.2577 - accuracy: 0.9800 - val_loss: 0.2168 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00348: val_loss improved from 0.21778 to 0.21684, saving model to ./model/348-0.2168.hdf5\n",
            "Epoch 349/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.2570 - accuracy: 0.9800 - val_loss: 0.2159 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00349: val_loss improved from 0.21684 to 0.21588, saving model to ./model/349-0.2159.hdf5\n",
            "Epoch 350/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.2566 - accuracy: 0.9800 - val_loss: 0.2148 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00350: val_loss improved from 0.21588 to 0.21479, saving model to ./model/350-0.2148.hdf5\n",
            "Epoch 351/3500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.2555 - accuracy: 0.9800 - val_loss: 0.2141 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00351: val_loss improved from 0.21479 to 0.21409, saving model to ./model/351-0.2141.hdf5\n",
            "Epoch 352/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.2551 - accuracy: 0.9800 - val_loss: 0.2138 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00352: val_loss improved from 0.21409 to 0.21378, saving model to ./model/352-0.2138.hdf5\n",
            "Epoch 353/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2540 - accuracy: 0.9800 - val_loss: 0.2130 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00353: val_loss improved from 0.21378 to 0.21297, saving model to ./model/353-0.2130.hdf5\n",
            "Epoch 354/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2535 - accuracy: 0.9800 - val_loss: 0.2121 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00354: val_loss improved from 0.21297 to 0.21207, saving model to ./model/354-0.2121.hdf5\n",
            "Epoch 355/3500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.2526 - accuracy: 0.9800 - val_loss: 0.2116 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00355: val_loss improved from 0.21207 to 0.21162, saving model to ./model/355-0.2116.hdf5\n",
            "Epoch 356/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2519 - accuracy: 0.9800 - val_loss: 0.2110 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00356: val_loss improved from 0.21162 to 0.21096, saving model to ./model/356-0.2110.hdf5\n",
            "Epoch 357/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2511 - accuracy: 0.9800 - val_loss: 0.2104 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00357: val_loss improved from 0.21096 to 0.21044, saving model to ./model/357-0.2104.hdf5\n",
            "Epoch 358/3500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.2506 - accuracy: 0.9800 - val_loss: 0.2101 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00358: val_loss improved from 0.21044 to 0.21009, saving model to ./model/358-0.2101.hdf5\n",
            "Epoch 359/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2497 - accuracy: 0.9800 - val_loss: 0.2094 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00359: val_loss improved from 0.21009 to 0.20943, saving model to ./model/359-0.2094.hdf5\n",
            "Epoch 360/3500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.2491 - accuracy: 0.9800 - val_loss: 0.2090 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00360: val_loss improved from 0.20943 to 0.20900, saving model to ./model/360-0.2090.hdf5\n",
            "Epoch 361/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.2483 - accuracy: 0.9800 - val_loss: 0.2082 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00361: val_loss improved from 0.20900 to 0.20821, saving model to ./model/361-0.2082.hdf5\n",
            "Epoch 362/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.2476 - accuracy: 0.9800 - val_loss: 0.2076 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00362: val_loss improved from 0.20821 to 0.20762, saving model to ./model/362-0.2076.hdf5\n",
            "Epoch 363/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.2470 - accuracy: 0.9800 - val_loss: 0.2071 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00363: val_loss improved from 0.20762 to 0.20707, saving model to ./model/363-0.2071.hdf5\n",
            "Epoch 364/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2462 - accuracy: 0.9800 - val_loss: 0.2062 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00364: val_loss improved from 0.20707 to 0.20624, saving model to ./model/364-0.2062.hdf5\n",
            "Epoch 365/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.2459 - accuracy: 0.9800 - val_loss: 0.2052 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00365: val_loss improved from 0.20624 to 0.20516, saving model to ./model/365-0.2052.hdf5\n",
            "Epoch 366/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.2448 - accuracy: 0.9800 - val_loss: 0.2045 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00366: val_loss improved from 0.20516 to 0.20448, saving model to ./model/366-0.2045.hdf5\n",
            "Epoch 367/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.2441 - accuracy: 0.9800 - val_loss: 0.2039 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00367: val_loss improved from 0.20448 to 0.20393, saving model to ./model/367-0.2039.hdf5\n",
            "Epoch 368/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.2434 - accuracy: 0.9800 - val_loss: 0.2033 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00368: val_loss improved from 0.20393 to 0.20332, saving model to ./model/368-0.2033.hdf5\n",
            "Epoch 369/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.2429 - accuracy: 0.9800 - val_loss: 0.2025 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00369: val_loss improved from 0.20332 to 0.20254, saving model to ./model/369-0.2025.hdf5\n",
            "Epoch 370/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2421 - accuracy: 0.9800 - val_loss: 0.2020 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00370: val_loss improved from 0.20254 to 0.20197, saving model to ./model/370-0.2020.hdf5\n",
            "Epoch 371/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2415 - accuracy: 0.9800 - val_loss: 0.2017 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00371: val_loss improved from 0.20197 to 0.20169, saving model to ./model/371-0.2017.hdf5\n",
            "Epoch 372/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.2407 - accuracy: 0.9800 - val_loss: 0.2011 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00372: val_loss improved from 0.20169 to 0.20106, saving model to ./model/372-0.2011.hdf5\n",
            "Epoch 373/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2400 - accuracy: 0.9800 - val_loss: 0.2006 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00373: val_loss improved from 0.20106 to 0.20057, saving model to ./model/373-0.2006.hdf5\n",
            "Epoch 374/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.2393 - accuracy: 0.9800 - val_loss: 0.2001 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00374: val_loss improved from 0.20057 to 0.20005, saving model to ./model/374-0.2001.hdf5\n",
            "Epoch 375/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.2386 - accuracy: 0.9800 - val_loss: 0.1995 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00375: val_loss improved from 0.20005 to 0.19953, saving model to ./model/375-0.1995.hdf5\n",
            "Epoch 376/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.2380 - accuracy: 0.9800 - val_loss: 0.1988 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00376: val_loss improved from 0.19953 to 0.19884, saving model to ./model/376-0.1988.hdf5\n",
            "Epoch 377/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.2374 - accuracy: 0.9800 - val_loss: 0.1981 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00377: val_loss improved from 0.19884 to 0.19814, saving model to ./model/377-0.1981.hdf5\n",
            "Epoch 378/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.2368 - accuracy: 0.9800 - val_loss: 0.1974 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00378: val_loss improved from 0.19814 to 0.19742, saving model to ./model/378-0.1974.hdf5\n",
            "Epoch 379/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2360 - accuracy: 0.9800 - val_loss: 0.1970 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00379: val_loss improved from 0.19742 to 0.19696, saving model to ./model/379-0.1970.hdf5\n",
            "Epoch 380/3500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.2353 - accuracy: 0.9800 - val_loss: 0.1964 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00380: val_loss improved from 0.19696 to 0.19641, saving model to ./model/380-0.1964.hdf5\n",
            "Epoch 381/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.2346 - accuracy: 0.9800 - val_loss: 0.1959 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00381: val_loss improved from 0.19641 to 0.19588, saving model to ./model/381-0.1959.hdf5\n",
            "Epoch 382/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.2340 - accuracy: 0.9800 - val_loss: 0.1954 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00382: val_loss improved from 0.19588 to 0.19544, saving model to ./model/382-0.1954.hdf5\n",
            "Epoch 383/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.2335 - accuracy: 0.9800 - val_loss: 0.1951 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00383: val_loss improved from 0.19544 to 0.19510, saving model to ./model/383-0.1951.hdf5\n",
            "Epoch 384/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2327 - accuracy: 0.9800 - val_loss: 0.1945 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00384: val_loss improved from 0.19510 to 0.19453, saving model to ./model/384-0.1945.hdf5\n",
            "Epoch 385/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.2321 - accuracy: 0.9800 - val_loss: 0.1940 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00385: val_loss improved from 0.19453 to 0.19399, saving model to ./model/385-0.1940.hdf5\n",
            "Epoch 386/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.2314 - accuracy: 0.9800 - val_loss: 0.1932 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00386: val_loss improved from 0.19399 to 0.19322, saving model to ./model/386-0.1932.hdf5\n",
            "Epoch 387/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.2314 - accuracy: 0.9800 - val_loss: 0.1929 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00387: val_loss improved from 0.19322 to 0.19294, saving model to ./model/387-0.1929.hdf5\n",
            "Epoch 388/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.2304 - accuracy: 0.9800 - val_loss: 0.1918 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00388: val_loss improved from 0.19294 to 0.19178, saving model to ./model/388-0.1918.hdf5\n",
            "Epoch 389/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.2295 - accuracy: 0.9800 - val_loss: 0.1910 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00389: val_loss improved from 0.19178 to 0.19099, saving model to ./model/389-0.1910.hdf5\n",
            "Epoch 390/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.2289 - accuracy: 0.9800 - val_loss: 0.1902 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00390: val_loss improved from 0.19099 to 0.19024, saving model to ./model/390-0.1902.hdf5\n",
            "Epoch 391/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.2282 - accuracy: 0.9800 - val_loss: 0.1897 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00391: val_loss improved from 0.19024 to 0.18967, saving model to ./model/391-0.1897.hdf5\n",
            "Epoch 392/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.2276 - accuracy: 0.9800 - val_loss: 0.1892 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00392: val_loss improved from 0.18967 to 0.18922, saving model to ./model/392-0.1892.hdf5\n",
            "Epoch 393/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.2272 - accuracy: 0.9800 - val_loss: 0.1884 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00393: val_loss improved from 0.18922 to 0.18843, saving model to ./model/393-0.1884.hdf5\n",
            "Epoch 394/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.2264 - accuracy: 0.9800 - val_loss: 0.1878 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00394: val_loss improved from 0.18843 to 0.18784, saving model to ./model/394-0.1878.hdf5\n",
            "Epoch 395/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.2258 - accuracy: 0.9800 - val_loss: 0.1876 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00395: val_loss improved from 0.18784 to 0.18756, saving model to ./model/395-0.1876.hdf5\n",
            "Epoch 396/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.2251 - accuracy: 0.9800 - val_loss: 0.1872 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00396: val_loss improved from 0.18756 to 0.18722, saving model to ./model/396-0.1872.hdf5\n",
            "Epoch 397/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2250 - accuracy: 0.9800 - val_loss: 0.1864 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00397: val_loss improved from 0.18722 to 0.18644, saving model to ./model/397-0.1864.hdf5\n",
            "Epoch 398/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.2239 - accuracy: 0.9800 - val_loss: 0.1860 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00398: val_loss improved from 0.18644 to 0.18604, saving model to ./model/398-0.1860.hdf5\n",
            "Epoch 399/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.2236 - accuracy: 0.9800 - val_loss: 0.1861 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00399: val_loss did not improve from 0.18604\n",
            "Epoch 400/3500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.2226 - accuracy: 0.9800 - val_loss: 0.1856 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00400: val_loss improved from 0.18604 to 0.18562, saving model to ./model/400-0.1856.hdf5\n",
            "Epoch 401/3500\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2220 - accuracy: 0.9800 - val_loss: 0.1852 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00401: val_loss improved from 0.18562 to 0.18525, saving model to ./model/401-0.1852.hdf5\n",
            "Epoch 402/3500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.2214 - accuracy: 0.9800 - val_loss: 0.1847 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00402: val_loss improved from 0.18525 to 0.18474, saving model to ./model/402-0.1847.hdf5\n",
            "Epoch 403/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.2209 - accuracy: 0.9800 - val_loss: 0.1841 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00403: val_loss improved from 0.18474 to 0.18407, saving model to ./model/403-0.1841.hdf5\n",
            "Epoch 404/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.2203 - accuracy: 0.9800 - val_loss: 0.1834 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00404: val_loss improved from 0.18407 to 0.18335, saving model to ./model/404-0.1834.hdf5\n",
            "Epoch 405/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.2196 - accuracy: 0.9800 - val_loss: 0.1827 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00405: val_loss improved from 0.18335 to 0.18272, saving model to ./model/405-0.1827.hdf5\n",
            "Epoch 406/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.2191 - accuracy: 0.9800 - val_loss: 0.1820 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00406: val_loss improved from 0.18272 to 0.18199, saving model to ./model/406-0.1820.hdf5\n",
            "Epoch 407/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.2184 - accuracy: 0.9800 - val_loss: 0.1815 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00407: val_loss improved from 0.18199 to 0.18149, saving model to ./model/407-0.1815.hdf5\n",
            "Epoch 408/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2178 - accuracy: 0.9800 - val_loss: 0.1809 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00408: val_loss improved from 0.18149 to 0.18092, saving model to ./model/408-0.1809.hdf5\n",
            "Epoch 409/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.2172 - accuracy: 0.9800 - val_loss: 0.1804 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00409: val_loss improved from 0.18092 to 0.18044, saving model to ./model/409-0.1804.hdf5\n",
            "Epoch 410/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2168 - accuracy: 0.9800 - val_loss: 0.1798 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00410: val_loss improved from 0.18044 to 0.17975, saving model to ./model/410-0.1798.hdf5\n",
            "Epoch 411/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2161 - accuracy: 0.9800 - val_loss: 0.1793 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00411: val_loss improved from 0.17975 to 0.17930, saving model to ./model/411-0.1793.hdf5\n",
            "Epoch 412/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.2155 - accuracy: 0.9800 - val_loss: 0.1789 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00412: val_loss improved from 0.17930 to 0.17890, saving model to ./model/412-0.1789.hdf5\n",
            "Epoch 413/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2151 - accuracy: 0.9800 - val_loss: 0.1782 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00413: val_loss improved from 0.17890 to 0.17822, saving model to ./model/413-0.1782.hdf5\n",
            "Epoch 414/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.2144 - accuracy: 0.9800 - val_loss: 0.1781 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00414: val_loss improved from 0.17822 to 0.17807, saving model to ./model/414-0.1781.hdf5\n",
            "Epoch 415/3500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.2138 - accuracy: 0.9800 - val_loss: 0.1776 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00415: val_loss improved from 0.17807 to 0.17763, saving model to ./model/415-0.1776.hdf5\n",
            "Epoch 416/3500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.2132 - accuracy: 0.9800 - val_loss: 0.1772 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00416: val_loss improved from 0.17763 to 0.17719, saving model to ./model/416-0.1772.hdf5\n",
            "Epoch 417/3500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.2126 - accuracy: 0.9800 - val_loss: 0.1767 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00417: val_loss improved from 0.17719 to 0.17666, saving model to ./model/417-0.1767.hdf5\n",
            "Epoch 418/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.2121 - accuracy: 0.9800 - val_loss: 0.1761 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00418: val_loss improved from 0.17666 to 0.17612, saving model to ./model/418-0.1761.hdf5\n",
            "Epoch 419/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.2115 - accuracy: 0.9800 - val_loss: 0.1758 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00419: val_loss improved from 0.17612 to 0.17578, saving model to ./model/419-0.1758.hdf5\n",
            "Epoch 420/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.2110 - accuracy: 0.9800 - val_loss: 0.1755 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00420: val_loss improved from 0.17578 to 0.17547, saving model to ./model/420-0.1755.hdf5\n",
            "Epoch 421/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.2103 - accuracy: 0.9800 - val_loss: 0.1749 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00421: val_loss improved from 0.17547 to 0.17490, saving model to ./model/421-0.1749.hdf5\n",
            "Epoch 422/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.2098 - accuracy: 0.9800 - val_loss: 0.1743 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00422: val_loss improved from 0.17490 to 0.17428, saving model to ./model/422-0.1743.hdf5\n",
            "Epoch 423/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.2092 - accuracy: 0.9800 - val_loss: 0.1737 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00423: val_loss improved from 0.17428 to 0.17370, saving model to ./model/423-0.1737.hdf5\n",
            "Epoch 424/3500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.2086 - accuracy: 0.9800 - val_loss: 0.1732 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00424: val_loss improved from 0.17370 to 0.17322, saving model to ./model/424-0.1732.hdf5\n",
            "Epoch 425/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.2081 - accuracy: 0.9800 - val_loss: 0.1726 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00425: val_loss improved from 0.17322 to 0.17257, saving model to ./model/425-0.1726.hdf5\n",
            "Epoch 426/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.2075 - accuracy: 0.9800 - val_loss: 0.1720 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00426: val_loss improved from 0.17257 to 0.17198, saving model to ./model/426-0.1720.hdf5\n",
            "Epoch 427/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2070 - accuracy: 0.9800 - val_loss: 0.1714 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00427: val_loss improved from 0.17198 to 0.17144, saving model to ./model/427-0.1714.hdf5\n",
            "Epoch 428/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.2065 - accuracy: 0.9800 - val_loss: 0.1712 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00428: val_loss improved from 0.17144 to 0.17115, saving model to ./model/428-0.1712.hdf5\n",
            "Epoch 429/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.2061 - accuracy: 0.9800 - val_loss: 0.1709 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00429: val_loss improved from 0.17115 to 0.17090, saving model to ./model/429-0.1709.hdf5\n",
            "Epoch 430/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.2054 - accuracy: 0.9800 - val_loss: 0.1705 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00430: val_loss improved from 0.17090 to 0.17045, saving model to ./model/430-0.1705.hdf5\n",
            "Epoch 431/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.2049 - accuracy: 0.9800 - val_loss: 0.1701 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00431: val_loss improved from 0.17045 to 0.17005, saving model to ./model/431-0.1701.hdf5\n",
            "Epoch 432/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.2044 - accuracy: 0.9800 - val_loss: 0.1692 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00432: val_loss improved from 0.17005 to 0.16923, saving model to ./model/432-0.1692.hdf5\n",
            "Epoch 433/3500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.2037 - accuracy: 0.9800 - val_loss: 0.1688 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00433: val_loss improved from 0.16923 to 0.16879, saving model to ./model/433-0.1688.hdf5\n",
            "Epoch 434/3500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.2032 - accuracy: 0.9800 - val_loss: 0.1683 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00434: val_loss improved from 0.16879 to 0.16830, saving model to ./model/434-0.1683.hdf5\n",
            "Epoch 435/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.2027 - accuracy: 0.9800 - val_loss: 0.1680 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00435: val_loss improved from 0.16830 to 0.16800, saving model to ./model/435-0.1680.hdf5\n",
            "Epoch 436/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.2024 - accuracy: 0.9800 - val_loss: 0.1672 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00436: val_loss improved from 0.16800 to 0.16719, saving model to ./model/436-0.1672.hdf5\n",
            "Epoch 437/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.2016 - accuracy: 0.9800 - val_loss: 0.1668 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00437: val_loss improved from 0.16719 to 0.16683, saving model to ./model/437-0.1668.hdf5\n",
            "Epoch 438/3500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.2011 - accuracy: 0.9800 - val_loss: 0.1665 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00438: val_loss improved from 0.16683 to 0.16647, saving model to ./model/438-0.1665.hdf5\n",
            "Epoch 439/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.2006 - accuracy: 0.9800 - val_loss: 0.1662 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00439: val_loss improved from 0.16647 to 0.16617, saving model to ./model/439-0.1662.hdf5\n",
            "Epoch 440/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.2000 - accuracy: 0.9800 - val_loss: 0.1657 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00440: val_loss improved from 0.16617 to 0.16570, saving model to ./model/440-0.1657.hdf5\n",
            "Epoch 441/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1994 - accuracy: 0.9800 - val_loss: 0.1653 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00441: val_loss improved from 0.16570 to 0.16530, saving model to ./model/441-0.1653.hdf5\n",
            "Epoch 442/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1990 - accuracy: 0.9800 - val_loss: 0.1650 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00442: val_loss improved from 0.16530 to 0.16499, saving model to ./model/442-0.1650.hdf5\n",
            "Epoch 443/3500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1985 - accuracy: 0.9800 - val_loss: 0.1644 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00443: val_loss improved from 0.16499 to 0.16440, saving model to ./model/443-0.1644.hdf5\n",
            "Epoch 444/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1979 - accuracy: 0.9800 - val_loss: 0.1640 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00444: val_loss improved from 0.16440 to 0.16403, saving model to ./model/444-0.1640.hdf5\n",
            "Epoch 445/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1976 - accuracy: 0.9800 - val_loss: 0.1639 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00445: val_loss improved from 0.16403 to 0.16386, saving model to ./model/445-0.1639.hdf5\n",
            "Epoch 446/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.1969 - accuracy: 0.9800 - val_loss: 0.1633 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00446: val_loss improved from 0.16386 to 0.16332, saving model to ./model/446-0.1633.hdf5\n",
            "Epoch 447/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1964 - accuracy: 0.9800 - val_loss: 0.1627 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00447: val_loss improved from 0.16332 to 0.16265, saving model to ./model/447-0.1627.hdf5\n",
            "Epoch 448/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.1958 - accuracy: 0.9800 - val_loss: 0.1621 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00448: val_loss improved from 0.16265 to 0.16212, saving model to ./model/448-0.1621.hdf5\n",
            "Epoch 449/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1953 - accuracy: 0.9800 - val_loss: 0.1617 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00449: val_loss improved from 0.16212 to 0.16165, saving model to ./model/449-0.1617.hdf5\n",
            "Epoch 450/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1948 - accuracy: 0.9800 - val_loss: 0.1612 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00450: val_loss improved from 0.16165 to 0.16121, saving model to ./model/450-0.1612.hdf5\n",
            "Epoch 451/3500\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1943 - accuracy: 0.9800 - val_loss: 0.1607 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00451: val_loss improved from 0.16121 to 0.16074, saving model to ./model/451-0.1607.hdf5\n",
            "Epoch 452/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1939 - accuracy: 0.9800 - val_loss: 0.1604 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00452: val_loss improved from 0.16074 to 0.16043, saving model to ./model/452-0.1604.hdf5\n",
            "Epoch 453/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1934 - accuracy: 0.9800 - val_loss: 0.1599 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00453: val_loss improved from 0.16043 to 0.15988, saving model to ./model/453-0.1599.hdf5\n",
            "Epoch 454/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.1928 - accuracy: 0.9800 - val_loss: 0.1596 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00454: val_loss improved from 0.15988 to 0.15965, saving model to ./model/454-0.1596.hdf5\n",
            "Epoch 455/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1924 - accuracy: 0.9800 - val_loss: 0.1591 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00455: val_loss improved from 0.15965 to 0.15911, saving model to ./model/455-0.1591.hdf5\n",
            "Epoch 456/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1921 - accuracy: 0.9800 - val_loss: 0.1585 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00456: val_loss improved from 0.15911 to 0.15849, saving model to ./model/456-0.1585.hdf5\n",
            "Epoch 457/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1914 - accuracy: 0.9800 - val_loss: 0.1581 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00457: val_loss improved from 0.15849 to 0.15806, saving model to ./model/457-0.1581.hdf5\n",
            "Epoch 458/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1909 - accuracy: 0.9800 - val_loss: 0.1579 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00458: val_loss improved from 0.15806 to 0.15791, saving model to ./model/458-0.1579.hdf5\n",
            "Epoch 459/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1904 - accuracy: 0.9800 - val_loss: 0.1577 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00459: val_loss improved from 0.15791 to 0.15774, saving model to ./model/459-0.1577.hdf5\n",
            "Epoch 460/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1900 - accuracy: 0.9800 - val_loss: 0.1577 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00460: val_loss improved from 0.15774 to 0.15765, saving model to ./model/460-0.1577.hdf5\n",
            "Epoch 461/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1894 - accuracy: 0.9800 - val_loss: 0.1574 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00461: val_loss improved from 0.15765 to 0.15737, saving model to ./model/461-0.1574.hdf5\n",
            "Epoch 462/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1890 - accuracy: 0.9800 - val_loss: 0.1568 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00462: val_loss improved from 0.15737 to 0.15679, saving model to ./model/462-0.1568.hdf5\n",
            "Epoch 463/3500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.1884 - accuracy: 0.9800 - val_loss: 0.1563 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00463: val_loss improved from 0.15679 to 0.15634, saving model to ./model/463-0.1563.hdf5\n",
            "Epoch 464/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1880 - accuracy: 0.9800 - val_loss: 0.1559 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00464: val_loss improved from 0.15634 to 0.15586, saving model to ./model/464-0.1559.hdf5\n",
            "Epoch 465/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1875 - accuracy: 0.9800 - val_loss: 0.1554 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00465: val_loss improved from 0.15586 to 0.15538, saving model to ./model/465-0.1554.hdf5\n",
            "Epoch 466/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1871 - accuracy: 0.9800 - val_loss: 0.1547 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00466: val_loss improved from 0.15538 to 0.15471, saving model to ./model/466-0.1547.hdf5\n",
            "Epoch 467/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1867 - accuracy: 0.9800 - val_loss: 0.1541 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00467: val_loss improved from 0.15471 to 0.15407, saving model to ./model/467-0.1541.hdf5\n",
            "Epoch 468/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1862 - accuracy: 0.9800 - val_loss: 0.1539 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00468: val_loss improved from 0.15407 to 0.15393, saving model to ./model/468-0.1539.hdf5\n",
            "Epoch 469/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1857 - accuracy: 0.9800 - val_loss: 0.1538 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00469: val_loss improved from 0.15393 to 0.15375, saving model to ./model/469-0.1538.hdf5\n",
            "Epoch 470/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1852 - accuracy: 0.9800 - val_loss: 0.1531 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00470: val_loss improved from 0.15375 to 0.15313, saving model to ./model/470-0.1531.hdf5\n",
            "Epoch 471/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1848 - accuracy: 0.9800 - val_loss: 0.1530 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00471: val_loss improved from 0.15313 to 0.15301, saving model to ./model/471-0.1530.hdf5\n",
            "Epoch 472/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1842 - accuracy: 0.9800 - val_loss: 0.1526 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00472: val_loss improved from 0.15301 to 0.15258, saving model to ./model/472-0.1526.hdf5\n",
            "Epoch 473/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.1837 - accuracy: 0.9800 - val_loss: 0.1522 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00473: val_loss improved from 0.15258 to 0.15215, saving model to ./model/473-0.1522.hdf5\n",
            "Epoch 474/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1834 - accuracy: 0.9800 - val_loss: 0.1515 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00474: val_loss improved from 0.15215 to 0.15151, saving model to ./model/474-0.1515.hdf5\n",
            "Epoch 475/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1829 - accuracy: 0.9800 - val_loss: 0.1510 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00475: val_loss improved from 0.15151 to 0.15095, saving model to ./model/475-0.1510.hdf5\n",
            "Epoch 476/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1823 - accuracy: 0.9800 - val_loss: 0.1506 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00476: val_loss improved from 0.15095 to 0.15060, saving model to ./model/476-0.1506.hdf5\n",
            "Epoch 477/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1823 - accuracy: 0.9800 - val_loss: 0.1507 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00477: val_loss did not improve from 0.15060\n",
            "Epoch 478/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1814 - accuracy: 0.9800 - val_loss: 0.1504 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00478: val_loss improved from 0.15060 to 0.15041, saving model to ./model/478-0.1504.hdf5\n",
            "Epoch 479/3500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1810 - accuracy: 0.9800 - val_loss: 0.1500 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00479: val_loss improved from 0.15041 to 0.15004, saving model to ./model/479-0.1500.hdf5\n",
            "Epoch 480/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1806 - accuracy: 0.9800 - val_loss: 0.1498 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00480: val_loss improved from 0.15004 to 0.14976, saving model to ./model/480-0.1498.hdf5\n",
            "Epoch 481/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1801 - accuracy: 0.9800 - val_loss: 0.1492 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00481: val_loss improved from 0.14976 to 0.14921, saving model to ./model/481-0.1492.hdf5\n",
            "Epoch 482/3500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.1796 - accuracy: 0.9800 - val_loss: 0.1489 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00482: val_loss improved from 0.14921 to 0.14890, saving model to ./model/482-0.1489.hdf5\n",
            "Epoch 483/3500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1793 - accuracy: 0.9800 - val_loss: 0.1486 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00483: val_loss improved from 0.14890 to 0.14862, saving model to ./model/483-0.1486.hdf5\n",
            "Epoch 484/3500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.1788 - accuracy: 0.9800 - val_loss: 0.1480 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00484: val_loss improved from 0.14862 to 0.14798, saving model to ./model/484-0.1480.hdf5\n",
            "Epoch 485/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1784 - accuracy: 0.9800 - val_loss: 0.1474 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00485: val_loss improved from 0.14798 to 0.14739, saving model to ./model/485-0.1474.hdf5\n",
            "Epoch 486/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1780 - accuracy: 0.9800 - val_loss: 0.1468 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00486: val_loss improved from 0.14739 to 0.14677, saving model to ./model/486-0.1468.hdf5\n",
            "Epoch 487/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1774 - accuracy: 0.9800 - val_loss: 0.1465 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00487: val_loss improved from 0.14677 to 0.14649, saving model to ./model/487-0.1465.hdf5\n",
            "Epoch 488/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.1770 - accuracy: 0.9800 - val_loss: 0.1461 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00488: val_loss improved from 0.14649 to 0.14613, saving model to ./model/488-0.1461.hdf5\n",
            "Epoch 489/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.1766 - accuracy: 0.9800 - val_loss: 0.1458 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00489: val_loss improved from 0.14613 to 0.14583, saving model to ./model/489-0.1458.hdf5\n",
            "Epoch 490/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1762 - accuracy: 0.9800 - val_loss: 0.1455 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00490: val_loss improved from 0.14583 to 0.14554, saving model to ./model/490-0.1455.hdf5\n",
            "Epoch 491/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1759 - accuracy: 0.9800 - val_loss: 0.1457 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00491: val_loss did not improve from 0.14554\n",
            "Epoch 492/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1754 - accuracy: 0.9800 - val_loss: 0.1457 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00492: val_loss did not improve from 0.14554\n",
            "Epoch 493/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1748 - accuracy: 0.9800 - val_loss: 0.1453 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00493: val_loss improved from 0.14554 to 0.14525, saving model to ./model/493-0.1453.hdf5\n",
            "Epoch 494/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1745 - accuracy: 0.9800 - val_loss: 0.1450 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00494: val_loss improved from 0.14525 to 0.14505, saving model to ./model/494-0.1450.hdf5\n",
            "Epoch 495/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1740 - accuracy: 0.9800 - val_loss: 0.1444 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00495: val_loss improved from 0.14505 to 0.14441, saving model to ./model/495-0.1444.hdf5\n",
            "Epoch 496/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1737 - accuracy: 0.9800 - val_loss: 0.1438 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00496: val_loss improved from 0.14441 to 0.14377, saving model to ./model/496-0.1438.hdf5\n",
            "Epoch 497/3500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.1731 - accuracy: 0.9800 - val_loss: 0.1435 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00497: val_loss improved from 0.14377 to 0.14346, saving model to ./model/497-0.1435.hdf5\n",
            "Epoch 498/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1728 - accuracy: 0.9800 - val_loss: 0.1429 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00498: val_loss improved from 0.14346 to 0.14288, saving model to ./model/498-0.1429.hdf5\n",
            "Epoch 499/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1723 - accuracy: 0.9800 - val_loss: 0.1425 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00499: val_loss improved from 0.14288 to 0.14246, saving model to ./model/499-0.1425.hdf5\n",
            "Epoch 500/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1721 - accuracy: 0.9800 - val_loss: 0.1419 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00500: val_loss improved from 0.14246 to 0.14189, saving model to ./model/500-0.1419.hdf5\n",
            "Epoch 501/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1715 - accuracy: 0.9800 - val_loss: 0.1416 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00501: val_loss improved from 0.14189 to 0.14164, saving model to ./model/501-0.1416.hdf5\n",
            "Epoch 502/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1710 - accuracy: 0.9800 - val_loss: 0.1415 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00502: val_loss improved from 0.14164 to 0.14147, saving model to ./model/502-0.1415.hdf5\n",
            "Epoch 503/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1707 - accuracy: 0.9800 - val_loss: 0.1414 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00503: val_loss improved from 0.14147 to 0.14141, saving model to ./model/503-0.1414.hdf5\n",
            "Epoch 504/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1703 - accuracy: 0.9800 - val_loss: 0.1414 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00504: val_loss improved from 0.14141 to 0.14138, saving model to ./model/504-0.1414.hdf5\n",
            "Epoch 505/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1698 - accuracy: 0.9800 - val_loss: 0.1410 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00505: val_loss improved from 0.14138 to 0.14105, saving model to ./model/505-0.1410.hdf5\n",
            "Epoch 506/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1697 - accuracy: 0.9800 - val_loss: 0.1410 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00506: val_loss improved from 0.14105 to 0.14103, saving model to ./model/506-0.1410.hdf5\n",
            "Epoch 507/3500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1691 - accuracy: 0.9800 - val_loss: 0.1407 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00507: val_loss improved from 0.14103 to 0.14070, saving model to ./model/507-0.1407.hdf5\n",
            "Epoch 508/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1686 - accuracy: 0.9800 - val_loss: 0.1401 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00508: val_loss improved from 0.14070 to 0.14008, saving model to ./model/508-0.1401.hdf5\n",
            "Epoch 509/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1682 - accuracy: 0.9800 - val_loss: 0.1395 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00509: val_loss improved from 0.14008 to 0.13949, saving model to ./model/509-0.1395.hdf5\n",
            "Epoch 510/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1679 - accuracy: 0.9800 - val_loss: 0.1389 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00510: val_loss improved from 0.13949 to 0.13889, saving model to ./model/510-0.1389.hdf5\n",
            "Epoch 511/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1674 - accuracy: 0.9800 - val_loss: 0.1384 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00511: val_loss improved from 0.13889 to 0.13841, saving model to ./model/511-0.1384.hdf5\n",
            "Epoch 512/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1672 - accuracy: 0.9800 - val_loss: 0.1384 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00512: val_loss improved from 0.13841 to 0.13835, saving model to ./model/512-0.1384.hdf5\n",
            "Epoch 513/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1666 - accuracy: 0.9800 - val_loss: 0.1381 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00513: val_loss improved from 0.13835 to 0.13806, saving model to ./model/513-0.1381.hdf5\n",
            "Epoch 514/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1662 - accuracy: 0.9800 - val_loss: 0.1377 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00514: val_loss improved from 0.13806 to 0.13774, saving model to ./model/514-0.1377.hdf5\n",
            "Epoch 515/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1659 - accuracy: 0.9800 - val_loss: 0.1372 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00515: val_loss improved from 0.13774 to 0.13722, saving model to ./model/515-0.1372.hdf5\n",
            "Epoch 516/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1655 - accuracy: 0.9800 - val_loss: 0.1370 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00516: val_loss improved from 0.13722 to 0.13699, saving model to ./model/516-0.1370.hdf5\n",
            "Epoch 517/3500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.1651 - accuracy: 0.9800 - val_loss: 0.1367 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00517: val_loss improved from 0.13699 to 0.13667, saving model to ./model/517-0.1367.hdf5\n",
            "Epoch 518/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1647 - accuracy: 0.9800 - val_loss: 0.1365 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00518: val_loss improved from 0.13667 to 0.13651, saving model to ./model/518-0.1365.hdf5\n",
            "Epoch 519/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1643 - accuracy: 0.9800 - val_loss: 0.1363 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00519: val_loss improved from 0.13651 to 0.13627, saving model to ./model/519-0.1363.hdf5\n",
            "Epoch 520/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1640 - accuracy: 0.9800 - val_loss: 0.1362 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00520: val_loss improved from 0.13627 to 0.13623, saving model to ./model/520-0.1362.hdf5\n",
            "Epoch 521/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1635 - accuracy: 0.9800 - val_loss: 0.1358 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00521: val_loss improved from 0.13623 to 0.13579, saving model to ./model/521-0.1358.hdf5\n",
            "Epoch 522/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1632 - accuracy: 0.9800 - val_loss: 0.1353 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00522: val_loss improved from 0.13579 to 0.13532, saving model to ./model/522-0.1353.hdf5\n",
            "Epoch 523/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1628 - accuracy: 0.9800 - val_loss: 0.1352 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00523: val_loss improved from 0.13532 to 0.13517, saving model to ./model/523-0.1352.hdf5\n",
            "Epoch 524/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1625 - accuracy: 0.9800 - val_loss: 0.1347 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00524: val_loss improved from 0.13517 to 0.13465, saving model to ./model/524-0.1347.hdf5\n",
            "Epoch 525/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1620 - accuracy: 0.9800 - val_loss: 0.1344 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00525: val_loss improved from 0.13465 to 0.13443, saving model to ./model/525-0.1344.hdf5\n",
            "Epoch 526/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1617 - accuracy: 0.9800 - val_loss: 0.1340 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00526: val_loss improved from 0.13443 to 0.13402, saving model to ./model/526-0.1340.hdf5\n",
            "Epoch 527/3500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.1613 - accuracy: 0.9800 - val_loss: 0.1338 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00527: val_loss improved from 0.13402 to 0.13380, saving model to ./model/527-0.1338.hdf5\n",
            "Epoch 528/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1609 - accuracy: 0.9800 - val_loss: 0.1335 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00528: val_loss improved from 0.13380 to 0.13349, saving model to ./model/528-0.1335.hdf5\n",
            "Epoch 529/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.1608 - accuracy: 0.9800 - val_loss: 0.1330 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00529: val_loss improved from 0.13349 to 0.13296, saving model to ./model/529-0.1330.hdf5\n",
            "Epoch 530/3500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1601 - accuracy: 0.9800 - val_loss: 0.1328 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00530: val_loss improved from 0.13296 to 0.13285, saving model to ./model/530-0.1328.hdf5\n",
            "Epoch 531/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1599 - accuracy: 0.9800 - val_loss: 0.1325 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00531: val_loss improved from 0.13285 to 0.13247, saving model to ./model/531-0.1325.hdf5\n",
            "Epoch 532/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1594 - accuracy: 0.9800 - val_loss: 0.1323 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00532: val_loss improved from 0.13247 to 0.13235, saving model to ./model/532-0.1323.hdf5\n",
            "Epoch 533/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1590 - accuracy: 0.9800 - val_loss: 0.1322 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00533: val_loss improved from 0.13235 to 0.13220, saving model to ./model/533-0.1322.hdf5\n",
            "Epoch 534/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1590 - accuracy: 0.9800 - val_loss: 0.1324 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00534: val_loss did not improve from 0.13220\n",
            "Epoch 535/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1583 - accuracy: 0.9800 - val_loss: 0.1322 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00535: val_loss improved from 0.13220 to 0.13218, saving model to ./model/535-0.1322.hdf5\n",
            "Epoch 536/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1580 - accuracy: 0.9800 - val_loss: 0.1317 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00536: val_loss improved from 0.13218 to 0.13171, saving model to ./model/536-0.1317.hdf5\n",
            "Epoch 537/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1576 - accuracy: 0.9800 - val_loss: 0.1313 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00537: val_loss improved from 0.13171 to 0.13128, saving model to ./model/537-0.1313.hdf5\n",
            "Epoch 538/3500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1572 - accuracy: 0.9800 - val_loss: 0.1310 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00538: val_loss improved from 0.13128 to 0.13096, saving model to ./model/538-0.1310.hdf5\n",
            "Epoch 539/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1569 - accuracy: 0.9800 - val_loss: 0.1305 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00539: val_loss improved from 0.13096 to 0.13052, saving model to ./model/539-0.1305.hdf5\n",
            "Epoch 540/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1565 - accuracy: 0.9800 - val_loss: 0.1300 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00540: val_loss improved from 0.13052 to 0.12998, saving model to ./model/540-0.1300.hdf5\n",
            "Epoch 541/3500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1562 - accuracy: 0.9800 - val_loss: 0.1297 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00541: val_loss improved from 0.12998 to 0.12971, saving model to ./model/541-0.1297.hdf5\n",
            "Epoch 542/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1558 - accuracy: 0.9800 - val_loss: 0.1295 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00542: val_loss improved from 0.12971 to 0.12947, saving model to ./model/542-0.1295.hdf5\n",
            "Epoch 543/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1556 - accuracy: 0.9800 - val_loss: 0.1289 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00543: val_loss improved from 0.12947 to 0.12892, saving model to ./model/543-0.1289.hdf5\n",
            "Epoch 544/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1551 - accuracy: 0.9800 - val_loss: 0.1287 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00544: val_loss improved from 0.12892 to 0.12873, saving model to ./model/544-0.1287.hdf5\n",
            "Epoch 545/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1547 - accuracy: 0.9800 - val_loss: 0.1285 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00545: val_loss improved from 0.12873 to 0.12845, saving model to ./model/545-0.1285.hdf5\n",
            "Epoch 546/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1545 - accuracy: 0.9800 - val_loss: 0.1280 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00546: val_loss improved from 0.12845 to 0.12802, saving model to ./model/546-0.1280.hdf5\n",
            "Epoch 547/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1541 - accuracy: 0.9800 - val_loss: 0.1279 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00547: val_loss improved from 0.12802 to 0.12787, saving model to ./model/547-0.1279.hdf5\n",
            "Epoch 548/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1538 - accuracy: 0.9800 - val_loss: 0.1276 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00548: val_loss improved from 0.12787 to 0.12759, saving model to ./model/548-0.1276.hdf5\n",
            "Epoch 549/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1534 - accuracy: 0.9800 - val_loss: 0.1276 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00549: val_loss did not improve from 0.12759\n",
            "Epoch 550/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1532 - accuracy: 0.9800 - val_loss: 0.1273 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00550: val_loss improved from 0.12759 to 0.12726, saving model to ./model/550-0.1273.hdf5\n",
            "Epoch 551/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1527 - accuracy: 0.9800 - val_loss: 0.1273 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00551: val_loss improved from 0.12726 to 0.12726, saving model to ./model/551-0.1273.hdf5\n",
            "Epoch 552/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1525 - accuracy: 0.9800 - val_loss: 0.1269 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00552: val_loss improved from 0.12726 to 0.12689, saving model to ./model/552-0.1269.hdf5\n",
            "Epoch 553/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.1520 - accuracy: 0.9800 - val_loss: 0.1267 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00553: val_loss improved from 0.12689 to 0.12667, saving model to ./model/553-0.1267.hdf5\n",
            "Epoch 554/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1517 - accuracy: 0.9800 - val_loss: 0.1264 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00554: val_loss improved from 0.12667 to 0.12644, saving model to ./model/554-0.1264.hdf5\n",
            "Epoch 555/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1516 - accuracy: 0.9800 - val_loss: 0.1260 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00555: val_loss improved from 0.12644 to 0.12596, saving model to ./model/555-0.1260.hdf5\n",
            "Epoch 556/3500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1510 - accuracy: 0.9800 - val_loss: 0.1259 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00556: val_loss improved from 0.12596 to 0.12587, saving model to ./model/556-0.1259.hdf5\n",
            "Epoch 557/3500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.1507 - accuracy: 0.9800 - val_loss: 0.1258 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00557: val_loss improved from 0.12587 to 0.12584, saving model to ./model/557-0.1258.hdf5\n",
            "Epoch 558/3500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.1504 - accuracy: 0.9800 - val_loss: 0.1256 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00558: val_loss improved from 0.12584 to 0.12564, saving model to ./model/558-0.1256.hdf5\n",
            "Epoch 559/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.1501 - accuracy: 0.9800 - val_loss: 0.1252 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00559: val_loss improved from 0.12564 to 0.12519, saving model to ./model/559-0.1252.hdf5\n",
            "Epoch 560/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.1498 - accuracy: 0.9800 - val_loss: 0.1251 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00560: val_loss improved from 0.12519 to 0.12514, saving model to ./model/560-0.1251.hdf5\n",
            "Epoch 561/3500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1494 - accuracy: 0.9800 - val_loss: 0.1248 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00561: val_loss improved from 0.12514 to 0.12483, saving model to ./model/561-0.1248.hdf5\n",
            "Epoch 562/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1492 - accuracy: 0.9800 - val_loss: 0.1242 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00562: val_loss improved from 0.12483 to 0.12421, saving model to ./model/562-0.1242.hdf5\n",
            "Epoch 563/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1487 - accuracy: 0.9800 - val_loss: 0.1239 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00563: val_loss improved from 0.12421 to 0.12394, saving model to ./model/563-0.1239.hdf5\n",
            "Epoch 564/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1485 - accuracy: 0.9800 - val_loss: 0.1239 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00564: val_loss improved from 0.12394 to 0.12389, saving model to ./model/564-0.1239.hdf5\n",
            "Epoch 565/3500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1481 - accuracy: 0.9800 - val_loss: 0.1235 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00565: val_loss improved from 0.12389 to 0.12346, saving model to ./model/565-0.1235.hdf5\n",
            "Epoch 566/3500\n",
            "2/2 [==============================] - 0s 34ms/step - loss: 0.1478 - accuracy: 0.9800 - val_loss: 0.1232 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00566: val_loss improved from 0.12346 to 0.12324, saving model to ./model/566-0.1232.hdf5\n",
            "Epoch 567/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1476 - accuracy: 0.9800 - val_loss: 0.1228 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00567: val_loss improved from 0.12324 to 0.12275, saving model to ./model/567-0.1228.hdf5\n",
            "Epoch 568/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1472 - accuracy: 0.9800 - val_loss: 0.1224 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00568: val_loss improved from 0.12275 to 0.12237, saving model to ./model/568-0.1224.hdf5\n",
            "Epoch 569/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1470 - accuracy: 0.9800 - val_loss: 0.1225 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00569: val_loss did not improve from 0.12237\n",
            "Epoch 570/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1465 - accuracy: 0.9800 - val_loss: 0.1224 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00570: val_loss did not improve from 0.12237\n",
            "Epoch 571/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1462 - accuracy: 0.9800 - val_loss: 0.1222 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00571: val_loss improved from 0.12237 to 0.12222, saving model to ./model/571-0.1222.hdf5\n",
            "Epoch 572/3500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.1459 - accuracy: 0.9800 - val_loss: 0.1219 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00572: val_loss improved from 0.12222 to 0.12191, saving model to ./model/572-0.1219.hdf5\n",
            "Epoch 573/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1456 - accuracy: 0.9800 - val_loss: 0.1217 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00573: val_loss improved from 0.12191 to 0.12169, saving model to ./model/573-0.1217.hdf5\n",
            "Epoch 574/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1452 - accuracy: 0.9800 - val_loss: 0.1214 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00574: val_loss improved from 0.12169 to 0.12141, saving model to ./model/574-0.1214.hdf5\n",
            "Epoch 575/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1450 - accuracy: 0.9800 - val_loss: 0.1212 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00575: val_loss improved from 0.12141 to 0.12118, saving model to ./model/575-0.1212.hdf5\n",
            "Epoch 576/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1447 - accuracy: 0.9800 - val_loss: 0.1208 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00576: val_loss improved from 0.12118 to 0.12075, saving model to ./model/576-0.1208.hdf5\n",
            "Epoch 577/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1444 - accuracy: 0.9800 - val_loss: 0.1203 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00577: val_loss improved from 0.12075 to 0.12028, saving model to ./model/577-0.1203.hdf5\n",
            "Epoch 578/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1441 - accuracy: 0.9800 - val_loss: 0.1203 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00578: val_loss improved from 0.12028 to 0.12026, saving model to ./model/578-0.1203.hdf5\n",
            "Epoch 579/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1437 - accuracy: 0.9800 - val_loss: 0.1200 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00579: val_loss improved from 0.12026 to 0.12005, saving model to ./model/579-0.1200.hdf5\n",
            "Epoch 580/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1435 - accuracy: 0.9800 - val_loss: 0.1197 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00580: val_loss improved from 0.12005 to 0.11966, saving model to ./model/580-0.1197.hdf5\n",
            "Epoch 581/3500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.1431 - accuracy: 0.9800 - val_loss: 0.1195 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00581: val_loss improved from 0.11966 to 0.11951, saving model to ./model/581-0.1195.hdf5\n",
            "Epoch 582/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1428 - accuracy: 0.9800 - val_loss: 0.1194 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00582: val_loss improved from 0.11951 to 0.11936, saving model to ./model/582-0.1194.hdf5\n",
            "Epoch 583/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.1425 - accuracy: 0.9800 - val_loss: 0.1191 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00583: val_loss improved from 0.11936 to 0.11912, saving model to ./model/583-0.1191.hdf5\n",
            "Epoch 584/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1422 - accuracy: 0.9800 - val_loss: 0.1190 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00584: val_loss improved from 0.11912 to 0.11904, saving model to ./model/584-0.1190.hdf5\n",
            "Epoch 585/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1421 - accuracy: 0.9800 - val_loss: 0.1191 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00585: val_loss did not improve from 0.11904\n",
            "Epoch 586/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1422 - accuracy: 0.9800 - val_loss: 0.1184 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00586: val_loss improved from 0.11904 to 0.11844, saving model to ./model/586-0.1184.hdf5\n",
            "Epoch 587/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1413 - accuracy: 0.9800 - val_loss: 0.1183 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00587: val_loss improved from 0.11844 to 0.11826, saving model to ./model/587-0.1183.hdf5\n",
            "Epoch 588/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1412 - accuracy: 0.9800 - val_loss: 0.1184 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00588: val_loss did not improve from 0.11826\n",
            "Epoch 589/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1412 - accuracy: 0.9800 - val_loss: 0.1186 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00589: val_loss did not improve from 0.11826\n",
            "Epoch 590/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1406 - accuracy: 0.9800 - val_loss: 0.1183 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00590: val_loss did not improve from 0.11826\n",
            "Epoch 591/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1403 - accuracy: 0.9800 - val_loss: 0.1176 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00591: val_loss improved from 0.11826 to 0.11762, saving model to ./model/591-0.1176.hdf5\n",
            "Epoch 592/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1401 - accuracy: 0.9800 - val_loss: 0.1170 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00592: val_loss improved from 0.11762 to 0.11696, saving model to ./model/592-0.1170.hdf5\n",
            "Epoch 593/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1397 - accuracy: 0.9800 - val_loss: 0.1168 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00593: val_loss improved from 0.11696 to 0.11680, saving model to ./model/593-0.1168.hdf5\n",
            "Epoch 594/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.1394 - accuracy: 0.9800 - val_loss: 0.1164 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00594: val_loss improved from 0.11680 to 0.11641, saving model to ./model/594-0.1164.hdf5\n",
            "Epoch 595/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1392 - accuracy: 0.9800 - val_loss: 0.1165 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00595: val_loss did not improve from 0.11641\n",
            "Epoch 596/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1389 - accuracy: 0.9800 - val_loss: 0.1160 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00596: val_loss improved from 0.11641 to 0.11604, saving model to ./model/596-0.1160.hdf5\n",
            "Epoch 597/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1385 - accuracy: 0.9800 - val_loss: 0.1159 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00597: val_loss improved from 0.11604 to 0.11592, saving model to ./model/597-0.1159.hdf5\n",
            "Epoch 598/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1382 - accuracy: 0.9800 - val_loss: 0.1157 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00598: val_loss improved from 0.11592 to 0.11574, saving model to ./model/598-0.1157.hdf5\n",
            "Epoch 599/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1380 - accuracy: 0.9800 - val_loss: 0.1155 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00599: val_loss improved from 0.11574 to 0.11551, saving model to ./model/599-0.1155.hdf5\n",
            "Epoch 600/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1377 - accuracy: 0.9800 - val_loss: 0.1155 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00600: val_loss improved from 0.11551 to 0.11548, saving model to ./model/600-0.1155.hdf5\n",
            "Epoch 601/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1374 - accuracy: 0.9800 - val_loss: 0.1152 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00601: val_loss improved from 0.11548 to 0.11518, saving model to ./model/601-0.1152.hdf5\n",
            "Epoch 602/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1371 - accuracy: 0.9800 - val_loss: 0.1151 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00602: val_loss improved from 0.11518 to 0.11511, saving model to ./model/602-0.1151.hdf5\n",
            "Epoch 603/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1372 - accuracy: 0.9800 - val_loss: 0.1153 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00603: val_loss did not improve from 0.11511\n",
            "Epoch 604/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1366 - accuracy: 0.9800 - val_loss: 0.1149 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00604: val_loss improved from 0.11511 to 0.11490, saving model to ./model/604-0.1149.hdf5\n",
            "Epoch 605/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1363 - accuracy: 0.9800 - val_loss: 0.1146 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00605: val_loss improved from 0.11490 to 0.11461, saving model to ./model/605-0.1146.hdf5\n",
            "Epoch 606/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.1361 - accuracy: 0.9800 - val_loss: 0.1141 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00606: val_loss improved from 0.11461 to 0.11413, saving model to ./model/606-0.1141.hdf5\n",
            "Epoch 607/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1358 - accuracy: 0.9800 - val_loss: 0.1138 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00607: val_loss improved from 0.11413 to 0.11381, saving model to ./model/607-0.1138.hdf5\n",
            "Epoch 608/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1356 - accuracy: 0.9800 - val_loss: 0.1139 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00608: val_loss did not improve from 0.11381\n",
            "Epoch 609/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1354 - accuracy: 0.9800 - val_loss: 0.1140 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00609: val_loss did not improve from 0.11381\n",
            "Epoch 610/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1350 - accuracy: 0.9800 - val_loss: 0.1138 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00610: val_loss did not improve from 0.11381\n",
            "Epoch 611/3500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.1348 - accuracy: 0.9800 - val_loss: 0.1137 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00611: val_loss improved from 0.11381 to 0.11371, saving model to ./model/611-0.1137.hdf5\n",
            "Epoch 612/3500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.1344 - accuracy: 0.9800 - val_loss: 0.1134 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00612: val_loss improved from 0.11371 to 0.11335, saving model to ./model/612-0.1134.hdf5\n",
            "Epoch 613/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1344 - accuracy: 0.9800 - val_loss: 0.1127 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00613: val_loss improved from 0.11335 to 0.11265, saving model to ./model/613-0.1127.hdf5\n",
            "Epoch 614/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1339 - accuracy: 0.9800 - val_loss: 0.1124 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00614: val_loss improved from 0.11265 to 0.11243, saving model to ./model/614-0.1124.hdf5\n",
            "Epoch 615/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1337 - accuracy: 0.9800 - val_loss: 0.1120 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00615: val_loss improved from 0.11243 to 0.11200, saving model to ./model/615-0.1120.hdf5\n",
            "Epoch 616/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1334 - accuracy: 0.9800 - val_loss: 0.1119 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00616: val_loss improved from 0.11200 to 0.11187, saving model to ./model/616-0.1119.hdf5\n",
            "Epoch 617/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1332 - accuracy: 0.9800 - val_loss: 0.1116 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00617: val_loss improved from 0.11187 to 0.11164, saving model to ./model/617-0.1116.hdf5\n",
            "Epoch 618/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1329 - accuracy: 0.9800 - val_loss: 0.1116 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00618: val_loss improved from 0.11164 to 0.11155, saving model to ./model/618-0.1116.hdf5\n",
            "Epoch 619/3500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.1326 - accuracy: 0.9800 - val_loss: 0.1115 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00619: val_loss improved from 0.11155 to 0.11152, saving model to ./model/619-0.1115.hdf5\n",
            "Epoch 620/3500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1325 - accuracy: 0.9800 - val_loss: 0.1112 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00620: val_loss improved from 0.11152 to 0.11116, saving model to ./model/620-0.1112.hdf5\n",
            "Epoch 621/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.1326 - accuracy: 0.9800 - val_loss: 0.1116 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00621: val_loss did not improve from 0.11116\n",
            "Epoch 622/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1323 - accuracy: 0.9800 - val_loss: 0.1119 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00622: val_loss did not improve from 0.11116\n",
            "Epoch 623/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1317 - accuracy: 0.9800 - val_loss: 0.1115 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00623: val_loss did not improve from 0.11116\n",
            "Epoch 624/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.1314 - accuracy: 0.9800 - val_loss: 0.1112 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00624: val_loss did not improve from 0.11116\n",
            "Epoch 625/3500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1312 - accuracy: 0.9800 - val_loss: 0.1106 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00625: val_loss improved from 0.11116 to 0.11064, saving model to ./model/625-0.1106.hdf5\n",
            "Epoch 626/3500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.1310 - accuracy: 0.9800 - val_loss: 0.1105 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00626: val_loss improved from 0.11064 to 0.11053, saving model to ./model/626-0.1105.hdf5\n",
            "Epoch 627/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1307 - accuracy: 0.9800 - val_loss: 0.1100 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00627: val_loss improved from 0.11053 to 0.10996, saving model to ./model/627-0.1100.hdf5\n",
            "Epoch 628/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.1304 - accuracy: 0.9800 - val_loss: 0.1098 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00628: val_loss improved from 0.10996 to 0.10980, saving model to ./model/628-0.1098.hdf5\n",
            "Epoch 629/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1302 - accuracy: 0.9800 - val_loss: 0.1093 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00629: val_loss improved from 0.10980 to 0.10934, saving model to ./model/629-0.1093.hdf5\n",
            "Epoch 630/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1303 - accuracy: 0.9800 - val_loss: 0.1088 - val_accuracy: 0.9800\n",
            "\n",
            "Epoch 00630: val_loss improved from 0.10934 to 0.10880, saving model to ./model/630-0.1088.hdf5\n",
            "Epoch 631/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1297 - accuracy: 0.9800 - val_loss: 0.1089 - val_accuracy: 0.9800\n",
            "\n",
            "Epoch 00631: val_loss did not improve from 0.10880\n",
            "Epoch 632/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1294 - accuracy: 0.9800 - val_loss: 0.1088 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00632: val_loss did not improve from 0.10880\n",
            "Epoch 633/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1292 - accuracy: 0.9800 - val_loss: 0.1090 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00633: val_loss did not improve from 0.10880\n",
            "Epoch 634/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1290 - accuracy: 0.9800 - val_loss: 0.1092 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00634: val_loss did not improve from 0.10880\n",
            "Epoch 635/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1287 - accuracy: 0.9800 - val_loss: 0.1090 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00635: val_loss did not improve from 0.10880\n",
            "Epoch 636/3500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1285 - accuracy: 0.9800 - val_loss: 0.1090 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00636: val_loss did not improve from 0.10880\n",
            "Epoch 637/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1283 - accuracy: 0.9800 - val_loss: 0.1089 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00637: val_loss did not improve from 0.10880\n",
            "Epoch 638/3500\n",
            "2/2 [==============================] - 0s 32ms/step - loss: 0.1280 - accuracy: 0.9800 - val_loss: 0.1087 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00638: val_loss improved from 0.10880 to 0.10867, saving model to ./model/638-0.1087.hdf5\n",
            "Epoch 639/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1278 - accuracy: 0.9800 - val_loss: 0.1082 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00639: val_loss improved from 0.10867 to 0.10822, saving model to ./model/639-0.1082.hdf5\n",
            "Epoch 640/3500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1280 - accuracy: 0.9800 - val_loss: 0.1075 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00640: val_loss improved from 0.10822 to 0.10749, saving model to ./model/640-0.1075.hdf5\n",
            "Epoch 641/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1273 - accuracy: 0.9800 - val_loss: 0.1075 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00641: val_loss improved from 0.10749 to 0.10749, saving model to ./model/641-0.1075.hdf5\n",
            "Epoch 642/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1270 - accuracy: 0.9800 - val_loss: 0.1074 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00642: val_loss improved from 0.10749 to 0.10738, saving model to ./model/642-0.1074.hdf5\n",
            "Epoch 643/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1269 - accuracy: 0.9800 - val_loss: 0.1074 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00643: val_loss did not improve from 0.10738\n",
            "Epoch 644/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1266 - accuracy: 0.9800 - val_loss: 0.1072 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00644: val_loss improved from 0.10738 to 0.10724, saving model to ./model/644-0.1072.hdf5\n",
            "Epoch 645/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1264 - accuracy: 0.9800 - val_loss: 0.1070 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00645: val_loss improved from 0.10724 to 0.10696, saving model to ./model/645-0.1070.hdf5\n",
            "Epoch 646/3500\n",
            "2/2 [==============================] - 0s 33ms/step - loss: 0.1262 - accuracy: 0.9800 - val_loss: 0.1066 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00646: val_loss improved from 0.10696 to 0.10658, saving model to ./model/646-0.1066.hdf5\n",
            "Epoch 647/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1259 - accuracy: 0.9800 - val_loss: 0.1064 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00647: val_loss improved from 0.10658 to 0.10643, saving model to ./model/647-0.1064.hdf5\n",
            "Epoch 648/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1257 - accuracy: 0.9800 - val_loss: 0.1062 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00648: val_loss improved from 0.10643 to 0.10625, saving model to ./model/648-0.1062.hdf5\n",
            "Epoch 649/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1256 - accuracy: 0.9800 - val_loss: 0.1059 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00649: val_loss improved from 0.10625 to 0.10590, saving model to ./model/649-0.1059.hdf5\n",
            "Epoch 650/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1253 - accuracy: 0.9800 - val_loss: 0.1061 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00650: val_loss did not improve from 0.10590\n",
            "Epoch 651/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1251 - accuracy: 0.9800 - val_loss: 0.1059 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00651: val_loss improved from 0.10590 to 0.10586, saving model to ./model/651-0.1059.hdf5\n",
            "Epoch 652/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1248 - accuracy: 0.9800 - val_loss: 0.1059 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00652: val_loss did not improve from 0.10586\n",
            "Epoch 653/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1246 - accuracy: 0.9800 - val_loss: 0.1059 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00653: val_loss did not improve from 0.10586\n",
            "Epoch 654/3500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.1244 - accuracy: 0.9800 - val_loss: 0.1058 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00654: val_loss improved from 0.10586 to 0.10585, saving model to ./model/654-0.1058.hdf5\n",
            "Epoch 655/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1241 - accuracy: 0.9800 - val_loss: 0.1057 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00655: val_loss improved from 0.10585 to 0.10573, saving model to ./model/655-0.1057.hdf5\n",
            "Epoch 656/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1242 - accuracy: 0.9800 - val_loss: 0.1059 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00656: val_loss did not improve from 0.10573\n",
            "Epoch 657/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1240 - accuracy: 0.9800 - val_loss: 0.1059 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00657: val_loss did not improve from 0.10573\n",
            "Epoch 658/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1235 - accuracy: 0.9800 - val_loss: 0.1055 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00658: val_loss improved from 0.10573 to 0.10548, saving model to ./model/658-0.1055.hdf5\n",
            "Epoch 659/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1233 - accuracy: 0.9800 - val_loss: 0.1051 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00659: val_loss improved from 0.10548 to 0.10506, saving model to ./model/659-0.1051.hdf5\n",
            "Epoch 660/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1234 - accuracy: 0.9800 - val_loss: 0.1041 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00660: val_loss improved from 0.10506 to 0.10409, saving model to ./model/660-0.1041.hdf5\n",
            "Epoch 661/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1229 - accuracy: 0.9800 - val_loss: 0.1038 - val_accuracy: 0.9800\n",
            "\n",
            "Epoch 00661: val_loss improved from 0.10409 to 0.10384, saving model to ./model/661-0.1038.hdf5\n",
            "Epoch 662/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1226 - accuracy: 0.9800 - val_loss: 0.1036 - val_accuracy: 0.9800\n",
            "\n",
            "Epoch 00662: val_loss improved from 0.10384 to 0.10361, saving model to ./model/662-0.1036.hdf5\n",
            "Epoch 663/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1224 - accuracy: 0.9800 - val_loss: 0.1034 - val_accuracy: 0.9800\n",
            "\n",
            "Epoch 00663: val_loss improved from 0.10361 to 0.10340, saving model to ./model/663-0.1034.hdf5\n",
            "Epoch 664/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1225 - accuracy: 0.9800 - val_loss: 0.1029 - val_accuracy: 0.9800\n",
            "\n",
            "Epoch 00664: val_loss improved from 0.10340 to 0.10294, saving model to ./model/664-0.1029.hdf5\n",
            "Epoch 665/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1221 - accuracy: 0.9800 - val_loss: 0.1028 - val_accuracy: 0.9800\n",
            "\n",
            "Epoch 00665: val_loss improved from 0.10294 to 0.10284, saving model to ./model/665-0.1028.hdf5\n",
            "Epoch 666/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1221 - accuracy: 0.9800 - val_loss: 0.1033 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00666: val_loss did not improve from 0.10284\n",
            "Epoch 667/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1216 - accuracy: 0.9800 - val_loss: 0.1034 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00667: val_loss did not improve from 0.10284\n",
            "Epoch 668/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1214 - accuracy: 0.9800 - val_loss: 0.1036 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00668: val_loss did not improve from 0.10284\n",
            "Epoch 669/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1216 - accuracy: 0.9800 - val_loss: 0.1040 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00669: val_loss did not improve from 0.10284\n",
            "Epoch 670/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1210 - accuracy: 0.9800 - val_loss: 0.1037 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00670: val_loss did not improve from 0.10284\n",
            "Epoch 671/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1208 - accuracy: 0.9800 - val_loss: 0.1032 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00671: val_loss did not improve from 0.10284\n",
            "Epoch 672/3500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.1205 - accuracy: 0.9800 - val_loss: 0.1029 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00672: val_loss did not improve from 0.10284\n",
            "Epoch 673/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.1204 - accuracy: 0.9800 - val_loss: 0.1027 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00673: val_loss improved from 0.10284 to 0.10270, saving model to ./model/673-0.1027.hdf5\n",
            "Epoch 674/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1201 - accuracy: 0.9800 - val_loss: 0.1024 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00674: val_loss improved from 0.10270 to 0.10236, saving model to ./model/674-0.1024.hdf5\n",
            "Epoch 675/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1200 - accuracy: 0.9800 - val_loss: 0.1023 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00675: val_loss improved from 0.10236 to 0.10226, saving model to ./model/675-0.1023.hdf5\n",
            "Epoch 676/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1197 - accuracy: 0.9800 - val_loss: 0.1018 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00676: val_loss improved from 0.10226 to 0.10184, saving model to ./model/676-0.1018.hdf5\n",
            "Epoch 677/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1195 - accuracy: 0.9800 - val_loss: 0.1015 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00677: val_loss improved from 0.10184 to 0.10149, saving model to ./model/677-0.1015.hdf5\n",
            "Epoch 678/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1193 - accuracy: 0.9800 - val_loss: 0.1012 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00678: val_loss improved from 0.10149 to 0.10124, saving model to ./model/678-0.1012.hdf5\n",
            "Epoch 679/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1192 - accuracy: 0.9800 - val_loss: 0.1012 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00679: val_loss improved from 0.10124 to 0.10121, saving model to ./model/679-0.1012.hdf5\n",
            "Epoch 680/3500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.1189 - accuracy: 0.9800 - val_loss: 0.1012 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00680: val_loss improved from 0.10121 to 0.10119, saving model to ./model/680-0.1012.hdf5\n",
            "Epoch 681/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1187 - accuracy: 0.9800 - val_loss: 0.1011 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00681: val_loss improved from 0.10119 to 0.10109, saving model to ./model/681-0.1011.hdf5\n",
            "Epoch 682/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1186 - accuracy: 0.9800 - val_loss: 0.1012 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00682: val_loss did not improve from 0.10109\n",
            "Epoch 683/3500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1185 - accuracy: 0.9800 - val_loss: 0.1014 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00683: val_loss did not improve from 0.10109\n",
            "Epoch 684/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1182 - accuracy: 0.9800 - val_loss: 0.1011 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00684: val_loss did not improve from 0.10109\n",
            "Epoch 685/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1180 - accuracy: 0.9800 - val_loss: 0.1010 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00685: val_loss improved from 0.10109 to 0.10103, saving model to ./model/685-0.1010.hdf5\n",
            "Epoch 686/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1180 - accuracy: 0.9800 - val_loss: 0.1005 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00686: val_loss improved from 0.10103 to 0.10046, saving model to ./model/686-0.1005.hdf5\n",
            "Epoch 687/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1180 - accuracy: 0.9800 - val_loss: 0.0999 - val_accuracy: 0.9800\n",
            "\n",
            "Epoch 00687: val_loss improved from 0.10046 to 0.09988, saving model to ./model/687-0.0999.hdf5\n",
            "Epoch 688/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1174 - accuracy: 0.9800 - val_loss: 0.0998 - val_accuracy: 0.9800\n",
            "\n",
            "Epoch 00688: val_loss improved from 0.09988 to 0.09975, saving model to ./model/688-0.0998.hdf5\n",
            "Epoch 689/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1173 - accuracy: 0.9800 - val_loss: 0.1000 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00689: val_loss did not improve from 0.09975\n",
            "Epoch 690/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1170 - accuracy: 0.9800 - val_loss: 0.0999 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00690: val_loss did not improve from 0.09975\n",
            "Epoch 691/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.1170 - accuracy: 0.9800 - val_loss: 0.1003 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00691: val_loss did not improve from 0.09975\n",
            "Epoch 692/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.1168 - accuracy: 0.9800 - val_loss: 0.1005 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00692: val_loss did not improve from 0.09975\n",
            "Epoch 693/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1165 - accuracy: 0.9800 - val_loss: 0.1001 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00693: val_loss did not improve from 0.09975\n",
            "Epoch 694/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1163 - accuracy: 0.9800 - val_loss: 0.0999 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00694: val_loss did not improve from 0.09975\n",
            "Epoch 695/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1161 - accuracy: 0.9800 - val_loss: 0.0996 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00695: val_loss improved from 0.09975 to 0.09958, saving model to ./model/695-0.0996.hdf5\n",
            "Epoch 696/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1159 - accuracy: 0.9800 - val_loss: 0.0995 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00696: val_loss improved from 0.09958 to 0.09948, saving model to ./model/696-0.0995.hdf5\n",
            "Epoch 697/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1157 - accuracy: 0.9800 - val_loss: 0.0993 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00697: val_loss improved from 0.09948 to 0.09928, saving model to ./model/697-0.0993.hdf5\n",
            "Epoch 698/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1155 - accuracy: 0.9800 - val_loss: 0.0988 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00698: val_loss improved from 0.09928 to 0.09881, saving model to ./model/698-0.0988.hdf5\n",
            "Epoch 699/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1154 - accuracy: 0.9800 - val_loss: 0.0987 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00699: val_loss improved from 0.09881 to 0.09872, saving model to ./model/699-0.0987.hdf5\n",
            "Epoch 700/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1153 - accuracy: 0.9800 - val_loss: 0.0987 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00700: val_loss improved from 0.09872 to 0.09871, saving model to ./model/700-0.0987.hdf5\n",
            "Epoch 701/3500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.1150 - accuracy: 0.9800 - val_loss: 0.0983 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00701: val_loss improved from 0.09871 to 0.09830, saving model to ./model/701-0.0983.hdf5\n",
            "Epoch 702/3500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.1148 - accuracy: 0.9800 - val_loss: 0.0982 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00702: val_loss improved from 0.09830 to 0.09820, saving model to ./model/702-0.0982.hdf5\n",
            "Epoch 703/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1146 - accuracy: 0.9800 - val_loss: 0.0980 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00703: val_loss improved from 0.09820 to 0.09805, saving model to ./model/703-0.0980.hdf5\n",
            "Epoch 704/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1148 - accuracy: 0.9800 - val_loss: 0.0983 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00704: val_loss did not improve from 0.09805\n",
            "Epoch 705/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1143 - accuracy: 0.9800 - val_loss: 0.0980 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00705: val_loss improved from 0.09805 to 0.09795, saving model to ./model/705-0.0980.hdf5\n",
            "Epoch 706/3500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1141 - accuracy: 0.9800 - val_loss: 0.0977 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00706: val_loss improved from 0.09795 to 0.09769, saving model to ./model/706-0.0977.hdf5\n",
            "Epoch 707/3500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.1139 - accuracy: 0.9800 - val_loss: 0.0977 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00707: val_loss did not improve from 0.09769\n",
            "Epoch 708/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1138 - accuracy: 0.9800 - val_loss: 0.0973 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00708: val_loss improved from 0.09769 to 0.09732, saving model to ./model/708-0.0973.hdf5\n",
            "Epoch 709/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1136 - accuracy: 0.9800 - val_loss: 0.0974 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00709: val_loss did not improve from 0.09732\n",
            "Epoch 710/3500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.1135 - accuracy: 0.9800 - val_loss: 0.0970 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00710: val_loss improved from 0.09732 to 0.09698, saving model to ./model/710-0.0970.hdf5\n",
            "Epoch 711/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1133 - accuracy: 0.9800 - val_loss: 0.0967 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00711: val_loss improved from 0.09698 to 0.09674, saving model to ./model/711-0.0967.hdf5\n",
            "Epoch 712/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1133 - accuracy: 0.9800 - val_loss: 0.0972 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00712: val_loss did not improve from 0.09674\n",
            "Epoch 713/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1129 - accuracy: 0.9800 - val_loss: 0.0973 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00713: val_loss did not improve from 0.09674\n",
            "Epoch 714/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1127 - accuracy: 0.9800 - val_loss: 0.0971 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00714: val_loss did not improve from 0.09674\n",
            "Epoch 715/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1125 - accuracy: 0.9800 - val_loss: 0.0969 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00715: val_loss did not improve from 0.09674\n",
            "Epoch 716/3500\n",
            "2/2 [==============================] - 0s 26ms/step - loss: 0.1124 - accuracy: 0.9800 - val_loss: 0.0969 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00716: val_loss did not improve from 0.09674\n",
            "Epoch 717/3500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.1122 - accuracy: 0.9800 - val_loss: 0.0968 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00717: val_loss did not improve from 0.09674\n",
            "Epoch 718/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1120 - accuracy: 0.9800 - val_loss: 0.0965 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00718: val_loss improved from 0.09674 to 0.09654, saving model to ./model/718-0.0965.hdf5\n",
            "Epoch 719/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.1118 - accuracy: 0.9800 - val_loss: 0.0962 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00719: val_loss improved from 0.09654 to 0.09622, saving model to ./model/719-0.0962.hdf5\n",
            "Epoch 720/3500\n",
            "2/2 [==============================] - 0s 30ms/step - loss: 0.1117 - accuracy: 0.9800 - val_loss: 0.0959 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00720: val_loss improved from 0.09622 to 0.09589, saving model to ./model/720-0.0959.hdf5\n",
            "Epoch 721/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1115 - accuracy: 0.9800 - val_loss: 0.0959 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00721: val_loss improved from 0.09589 to 0.09589, saving model to ./model/721-0.0959.hdf5\n",
            "Epoch 722/3500\n",
            "2/2 [==============================] - 0s 27ms/step - loss: 0.1113 - accuracy: 0.9800 - val_loss: 0.0959 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00722: val_loss improved from 0.09589 to 0.09588, saving model to ./model/722-0.0959.hdf5\n",
            "Epoch 723/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1112 - accuracy: 0.9800 - val_loss: 0.0959 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00723: val_loss did not improve from 0.09588\n",
            "Epoch 724/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1111 - accuracy: 0.9800 - val_loss: 0.0955 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00724: val_loss improved from 0.09588 to 0.09548, saving model to ./model/724-0.0955.hdf5\n",
            "Epoch 725/3500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1109 - accuracy: 0.9800 - val_loss: 0.0952 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00725: val_loss improved from 0.09548 to 0.09518, saving model to ./model/725-0.0952.hdf5\n",
            "Epoch 726/3500\n",
            "2/2 [==============================] - 0s 25ms/step - loss: 0.1107 - accuracy: 0.9800 - val_loss: 0.0949 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00726: val_loss improved from 0.09518 to 0.09494, saving model to ./model/726-0.0949.hdf5\n",
            "Epoch 727/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1106 - accuracy: 0.9800 - val_loss: 0.0952 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00727: val_loss did not improve from 0.09494\n",
            "Epoch 728/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1103 - accuracy: 0.9800 - val_loss: 0.0951 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00728: val_loss did not improve from 0.09494\n",
            "Epoch 729/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1102 - accuracy: 0.9800 - val_loss: 0.0950 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00729: val_loss did not improve from 0.09494\n",
            "Epoch 730/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1102 - accuracy: 0.9800 - val_loss: 0.0953 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00730: val_loss did not improve from 0.09494\n",
            "Epoch 731/3500\n",
            "2/2 [==============================] - 0s 28ms/step - loss: 0.1098 - accuracy: 0.9800 - val_loss: 0.0952 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00731: val_loss did not improve from 0.09494\n",
            "Epoch 732/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1097 - accuracy: 0.9800 - val_loss: 0.0952 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00732: val_loss did not improve from 0.09494\n",
            "Epoch 733/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1095 - accuracy: 0.9800 - val_loss: 0.0949 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00733: val_loss did not improve from 0.09494\n",
            "Epoch 734/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1094 - accuracy: 0.9800 - val_loss: 0.0948 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00734: val_loss improved from 0.09494 to 0.09478, saving model to ./model/734-0.0948.hdf5\n",
            "Epoch 735/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1092 - accuracy: 0.9800 - val_loss: 0.0947 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00735: val_loss improved from 0.09478 to 0.09466, saving model to ./model/735-0.0947.hdf5\n",
            "Epoch 736/3500\n",
            "2/2 [==============================] - 0s 31ms/step - loss: 0.1092 - accuracy: 0.9800 - val_loss: 0.0946 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00736: val_loss improved from 0.09466 to 0.09461, saving model to ./model/736-0.0946.hdf5\n",
            "Epoch 737/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1091 - accuracy: 0.9800 - val_loss: 0.0945 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00737: val_loss improved from 0.09461 to 0.09452, saving model to ./model/737-0.0945.hdf5\n",
            "Epoch 738/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1088 - accuracy: 0.9800 - val_loss: 0.0939 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00738: val_loss improved from 0.09452 to 0.09385, saving model to ./model/738-0.0939.hdf5\n",
            "Epoch 739/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1087 - accuracy: 0.9800 - val_loss: 0.0932 - val_accuracy: 0.9800\n",
            "\n",
            "Epoch 00739: val_loss improved from 0.09385 to 0.09322, saving model to ./model/739-0.0932.hdf5\n",
            "Epoch 740/3500\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 0.1085 - accuracy: 0.9800 - val_loss: 0.0932 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00740: val_loss improved from 0.09322 to 0.09321, saving model to ./model/740-0.0932.hdf5\n",
            "Epoch 741/3500\n",
            "2/2 [==============================] - 0s 29ms/step - loss: 0.1084 - accuracy: 0.9800 - val_loss: 0.0928 - val_accuracy: 0.9800\n",
            "\n",
            "Epoch 00741: val_loss improved from 0.09321 to 0.09285, saving model to ./model/741-0.0928.hdf5\n",
            "Epoch 742/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1082 - accuracy: 0.9800 - val_loss: 0.0931 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00742: val_loss did not improve from 0.09285\n",
            "Epoch 743/3500\n",
            "2/2 [==============================] - 0s 21ms/step - loss: 0.1080 - accuracy: 0.9800 - val_loss: 0.0932 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00743: val_loss did not improve from 0.09285\n",
            "Epoch 744/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1078 - accuracy: 0.9800 - val_loss: 0.0930 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00744: val_loss did not improve from 0.09285\n",
            "Epoch 745/3500\n",
            "2/2 [==============================] - 0s 20ms/step - loss: 0.1076 - accuracy: 0.9800 - val_loss: 0.0930 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00745: val_loss did not improve from 0.09285\n",
            "Epoch 746/3500\n",
            "2/2 [==============================] - 0s 23ms/step - loss: 0.1075 - accuracy: 0.9800 - val_loss: 0.0931 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00746: val_loss did not improve from 0.09285\n",
            "Epoch 747/3500\n",
            "2/2 [==============================] - 0s 22ms/step - loss: 0.1075 - accuracy: 0.9800 - val_loss: 0.0934 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00747: val_loss did not improve from 0.09285\n",
            "Epoch 748/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1072 - accuracy: 0.9800 - val_loss: 0.0933 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00748: val_loss did not improve from 0.09285\n",
            "Epoch 749/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1072 - accuracy: 0.9800 - val_loss: 0.0935 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00749: val_loss did not improve from 0.09285\n",
            "Epoch 750/3500\n",
            "2/2 [==============================] - 0s 19ms/step - loss: 0.1069 - accuracy: 0.9800 - val_loss: 0.0933 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00750: val_loss did not improve from 0.09285\n",
            "Epoch 751/3500\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1068 - accuracy: 0.9800 - val_loss: 0.0931 - val_accuracy: 0.9600\n",
            "\n",
            "Epoch 00751: val_loss did not improve from 0.09285\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmvw9ebWfOE9"
      },
      "source": [
        "# 보스턴 집값 예측하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vhzNjbqefbf",
        "outputId": "ce67f6b8-38a0-4c1b-d6b3-201c404a2197"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "#seed값 설정\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "#데이터 입력\n",
        "df = pd.read_csv(\"/housing.csv\", delim_whitespace=True, header=None)\n",
        "\n",
        "#데이터 분류\n",
        "dataset = df.values\n",
        "X = dataset[:, 0:13]\n",
        "Y = dataset[:, 13]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=seed)\n",
        "\n",
        "#모델 설정\n",
        "model = Sequential()\n",
        "model.add(Dense(30, input_dim=13, activation='relu'))\n",
        "model.add(Dense(6, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "#모델 컴파일\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "#mean_squared_error : 평균 제곱 오차\n",
        "\n",
        "#모델 실행\n",
        "model.fit(X_train, Y_train, epochs=200, batch_size=10)\n",
        "\n",
        "#예측 값과 실제 값의 비교\n",
        "Y_prediction = model.predict(X_test).flatten()#flatten : 일차원배열로 만들어줌(안하면 이차원배열이라 밑에 계산 안됨)\n",
        "for i in range(10):\n",
        "    label = Y_test[i]\n",
        "    prediction = Y_prediction[i]\n",
        "    print(\"실제가격 : {:.3f}, 예상가격 : {:.3f}\".format(label, prediction))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 8438.1172\n",
            "Epoch 2/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 732.8683\n",
            "Epoch 3/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 512.5950\n",
            "Epoch 4/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 388.6990\n",
            "Epoch 5/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 256.9753\n",
            "Epoch 6/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 170.7661\n",
            "Epoch 7/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 135.6643\n",
            "Epoch 8/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 123.0021\n",
            "Epoch 9/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 92.7171\n",
            "Epoch 10/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 80.1417\n",
            "Epoch 11/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 72.3035\n",
            "Epoch 12/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 69.8260\n",
            "Epoch 13/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 67.6638\n",
            "Epoch 14/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 65.8864\n",
            "Epoch 15/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 65.1428\n",
            "Epoch 16/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 63.5601\n",
            "Epoch 17/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 64.5949\n",
            "Epoch 18/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 61.6633\n",
            "Epoch 19/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 62.5243\n",
            "Epoch 20/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 59.6989\n",
            "Epoch 21/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 59.3723\n",
            "Epoch 22/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 58.5467\n",
            "Epoch 23/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 58.7318\n",
            "Epoch 24/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 56.2302\n",
            "Epoch 25/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 56.2373\n",
            "Epoch 26/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 56.2391\n",
            "Epoch 27/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 54.9049\n",
            "Epoch 28/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 54.9681\n",
            "Epoch 29/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 54.0103\n",
            "Epoch 30/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 53.4721\n",
            "Epoch 31/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 52.6120\n",
            "Epoch 32/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 52.3308\n",
            "Epoch 33/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 51.6922\n",
            "Epoch 34/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 51.4115\n",
            "Epoch 35/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 50.9594\n",
            "Epoch 36/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 50.0806\n",
            "Epoch 37/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 49.6587\n",
            "Epoch 38/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 50.1437\n",
            "Epoch 39/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 48.7939\n",
            "Epoch 40/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 48.2098\n",
            "Epoch 41/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 48.1594\n",
            "Epoch 42/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 47.6336\n",
            "Epoch 43/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 46.4014\n",
            "Epoch 44/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 46.0603\n",
            "Epoch 45/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 46.2956\n",
            "Epoch 46/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 46.1978\n",
            "Epoch 47/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 44.8460\n",
            "Epoch 48/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 43.1158\n",
            "Epoch 49/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 42.7315\n",
            "Epoch 50/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 42.7363\n",
            "Epoch 51/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 41.1165\n",
            "Epoch 52/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 41.3375\n",
            "Epoch 53/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 40.9050\n",
            "Epoch 54/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 39.9034\n",
            "Epoch 55/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 38.7777\n",
            "Epoch 56/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 39.4455\n",
            "Epoch 57/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 39.0700\n",
            "Epoch 58/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 37.7630\n",
            "Epoch 59/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 36.5026\n",
            "Epoch 60/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 36.5739\n",
            "Epoch 61/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 38.2261\n",
            "Epoch 62/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 36.1457\n",
            "Epoch 63/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 36.0968\n",
            "Epoch 64/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 34.8201\n",
            "Epoch 65/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 33.8550\n",
            "Epoch 66/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 35.0673\n",
            "Epoch 67/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 33.6298\n",
            "Epoch 68/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 33.4776\n",
            "Epoch 69/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 37.0617\n",
            "Epoch 70/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 33.4909\n",
            "Epoch 71/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 32.8610\n",
            "Epoch 72/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 33.0652\n",
            "Epoch 73/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 31.9464\n",
            "Epoch 74/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 30.9932\n",
            "Epoch 75/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 32.2534\n",
            "Epoch 76/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 31.4631\n",
            "Epoch 77/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 31.7118\n",
            "Epoch 78/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 30.5142\n",
            "Epoch 79/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 30.4484\n",
            "Epoch 80/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 29.6032\n",
            "Epoch 81/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 29.3145\n",
            "Epoch 82/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 30.3669\n",
            "Epoch 83/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 31.6188\n",
            "Epoch 84/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 29.0275\n",
            "Epoch 85/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 28.3375\n",
            "Epoch 86/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 28.4044\n",
            "Epoch 87/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 29.4635\n",
            "Epoch 88/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 29.5894\n",
            "Epoch 89/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 28.4563\n",
            "Epoch 90/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 27.0863\n",
            "Epoch 91/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 28.2004\n",
            "Epoch 92/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 26.7010\n",
            "Epoch 93/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 27.8506\n",
            "Epoch 94/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 30.4518\n",
            "Epoch 95/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 26.2899\n",
            "Epoch 96/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 25.6983\n",
            "Epoch 97/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 25.7705\n",
            "Epoch 98/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 25.6901\n",
            "Epoch 99/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 25.3404\n",
            "Epoch 100/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 25.3621\n",
            "Epoch 101/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 25.5198\n",
            "Epoch 102/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 26.4034\n",
            "Epoch 103/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 27.0355\n",
            "Epoch 104/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 29.2855\n",
            "Epoch 105/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 25.3013\n",
            "Epoch 106/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 25.3194\n",
            "Epoch 107/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 24.9012\n",
            "Epoch 108/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 24.4835\n",
            "Epoch 109/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 24.7045\n",
            "Epoch 110/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 25.2438\n",
            "Epoch 111/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 26.0588\n",
            "Epoch 112/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 26.9572\n",
            "Epoch 113/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 24.1499\n",
            "Epoch 114/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 25.3550\n",
            "Epoch 115/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 23.2317\n",
            "Epoch 116/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 23.9471\n",
            "Epoch 117/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 24.0546\n",
            "Epoch 118/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 23.1469\n",
            "Epoch 119/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 23.7542\n",
            "Epoch 120/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 22.8985\n",
            "Epoch 121/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 24.4217\n",
            "Epoch 122/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 23.0718\n",
            "Epoch 123/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 22.9580\n",
            "Epoch 124/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 24.8591\n",
            "Epoch 125/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 23.1668\n",
            "Epoch 126/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 22.6643\n",
            "Epoch 127/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 24.3838\n",
            "Epoch 128/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 22.6999\n",
            "Epoch 129/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 23.6269\n",
            "Epoch 130/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 21.9588\n",
            "Epoch 131/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 23.2078\n",
            "Epoch 132/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 22.1276\n",
            "Epoch 133/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 23.4127\n",
            "Epoch 134/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 24.1749\n",
            "Epoch 135/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 23.8193\n",
            "Epoch 136/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 23.3802\n",
            "Epoch 137/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 21.4158\n",
            "Epoch 138/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 23.3578\n",
            "Epoch 139/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 20.7983\n",
            "Epoch 140/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 23.1516\n",
            "Epoch 141/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 22.0328\n",
            "Epoch 142/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 20.3153\n",
            "Epoch 143/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 23.2594\n",
            "Epoch 144/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 23.0867\n",
            "Epoch 145/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 27.0086\n",
            "Epoch 146/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 21.7518\n",
            "Epoch 147/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 22.0327\n",
            "Epoch 148/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 22.8959\n",
            "Epoch 149/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 22.4905\n",
            "Epoch 150/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 21.5998\n",
            "Epoch 151/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 23.4205\n",
            "Epoch 152/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 21.1253\n",
            "Epoch 153/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 20.1864\n",
            "Epoch 154/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 22.7077\n",
            "Epoch 155/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 20.3380\n",
            "Epoch 156/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 22.0297\n",
            "Epoch 157/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 20.7166\n",
            "Epoch 158/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 21.2586\n",
            "Epoch 159/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 20.4158\n",
            "Epoch 160/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 21.2197\n",
            "Epoch 161/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 20.8700\n",
            "Epoch 162/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 20.1265\n",
            "Epoch 163/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 20.3223\n",
            "Epoch 164/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 21.2626\n",
            "Epoch 165/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 19.6495\n",
            "Epoch 166/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 19.0726\n",
            "Epoch 167/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 20.4881\n",
            "Epoch 168/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 19.1696\n",
            "Epoch 169/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 19.7511\n",
            "Epoch 170/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 18.2152\n",
            "Epoch 171/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 18.2944\n",
            "Epoch 172/200\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 18.2965\n",
            "Epoch 173/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 19.2690\n",
            "Epoch 174/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 18.5533\n",
            "Epoch 175/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 18.9418\n",
            "Epoch 176/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 18.7512\n",
            "Epoch 177/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 18.7615\n",
            "Epoch 178/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 19.5743\n",
            "Epoch 179/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 17.7814\n",
            "Epoch 180/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 17.7651\n",
            "Epoch 181/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 17.0862\n",
            "Epoch 182/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 18.2538\n",
            "Epoch 183/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 17.8485\n",
            "Epoch 184/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 20.4784\n",
            "Epoch 185/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 19.8855\n",
            "Epoch 186/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 17.0514\n",
            "Epoch 187/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 17.9898\n",
            "Epoch 188/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 17.8454\n",
            "Epoch 189/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 17.3030\n",
            "Epoch 190/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 16.9978\n",
            "Epoch 191/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 17.2636\n",
            "Epoch 192/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 17.8245\n",
            "Epoch 193/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 17.4317\n",
            "Epoch 194/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 18.5794\n",
            "Epoch 195/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 16.7098\n",
            "Epoch 196/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 17.5683\n",
            "Epoch 197/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 17.0497\n",
            "Epoch 198/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 17.3721\n",
            "Epoch 199/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 19.3602\n",
            "Epoch 200/200\n",
            "36/36 [==============================] - 0s 1ms/step - loss: 17.9043\n",
            "실제가격 : 22.600, 예상가격 : 23.494\n",
            "실제가격 : 50.000, 예상가격 : 25.601\n",
            "실제가격 : 23.000, 예상가격 : 24.425\n",
            "실제가격 : 8.300, 예상가격 : 12.533\n",
            "실제가격 : 21.200, 예상가격 : 18.124\n",
            "실제가격 : 19.900, 예상가격 : 20.766\n",
            "실제가격 : 20.600, 예상가격 : 21.137\n",
            "실제가격 : 18.700, 예상가격 : 22.038\n",
            "실제가격 : 16.100, 예상가격 : 16.557\n",
            "실제가격 : 18.600, 예상가격 : 7.678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnZ8kTmrfjW2"
      },
      "source": [
        "선형회귀는 로지스트회귀처럼 1과0으로 이루어진게 아닌 자연수의 값이라 accuracy가 없다  \n",
        "1인지 0인지에서는 맞는지 틀린지를 알 수 있지만  \n",
        "수치상 5.0%와 5.1%는 맞는지 틀린지 정하기 애매하다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DB7ePojGfRP3",
        "outputId": "c8662089-a904-4a9a-b837-0f11e931fd38"
      },
      "source": [
        "#보스턴 집값 예측 자동 중단 및 그래프 적용\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#seed값 설정\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "#데이터 입력\n",
        "df_pre = pd.read_csv(\"/housing.csv\", delim_whitespace=True, header=None)\n",
        "df = df_pre.sample(frac=1)\n",
        "\n",
        "#데이터 분류\n",
        "dataset = df.values\n",
        "X = dataset[:, 0:13]\n",
        "Y = dataset[:, 13]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=seed)\n",
        "\n",
        "#모델 설정\n",
        "model = Sequential()\n",
        "model.add(Dense(30, input_dim=13, activation='relu'))\n",
        "model.add(Dense(6, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "#모델 컴파일\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "#모델 실행\n",
        "history = model.fit(X_train, Y_train, validation_split=0.33, epochs=5000, batch_size=10, callbacks=[early_stopping_callback, checkpointer])\n",
        "\n",
        "hist = pd.DataFrame(history.history)\n",
        "print(hist.tail())\n",
        "\n",
        "#val값에 테스트셋으로 실험 결과의 오차 값을 저장\n",
        "y_vloss = history.history['val_loss']\n",
        "\n",
        "#원래 값에 학습셋으로 측정한 정확도의 값을 저장\n",
        "y_loss = history.history['loss']\n",
        "\n",
        "#x값을 지정하고 정확도를 파란색으로, 오차를 빨간색으로 표시\n",
        "x_len = np.arange(len(y_loss))\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3, label='val_loss')\n",
        "plt.plot(x_len, y_loss, \"o\", c=\"blue\", markersize=3, label='loss')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#예측 값과 실제 값의 비교\n",
        "Y_prediction = model.predict(X_test).flatten()\n",
        "for i in range(10):\n",
        "    label = Y_test[i]\n",
        "    prediction = Y_prediction[i]\n",
        "    print(\"실제가격 : {:.3f}, 예상가격 : {:.3f}\".format(label, prediction))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5000\n",
            "24/24 [==============================] - 1s 6ms/step - loss: 10934.6426 - val_loss: 3399.1145\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.09285\n",
            "Epoch 2/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 1448.8398 - val_loss: 613.5666\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.09285\n",
            "Epoch 3/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 584.2853 - val_loss: 500.0798\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.09285\n",
            "Epoch 4/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 496.2946 - val_loss: 431.5092\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.09285\n",
            "Epoch 5/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 412.0949 - val_loss: 354.8476\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.09285\n",
            "Epoch 6/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 326.3025 - val_loss: 274.1810\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.09285\n",
            "Epoch 7/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 245.6190 - val_loss: 202.8194\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.09285\n",
            "Epoch 8/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 183.0386 - val_loss: 156.6184\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.09285\n",
            "Epoch 9/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 147.2050 - val_loss: 133.7574\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.09285\n",
            "Epoch 10/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 128.8246 - val_loss: 123.9070\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.09285\n",
            "Epoch 11/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 119.2253 - val_loss: 116.7239\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.09285\n",
            "Epoch 12/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 112.5392 - val_loss: 111.2741\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.09285\n",
            "Epoch 13/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 107.3723 - val_loss: 106.9673\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.09285\n",
            "Epoch 14/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 103.4488 - val_loss: 102.8017\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.09285\n",
            "Epoch 15/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 99.1420 - val_loss: 92.0496\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.09285\n",
            "Epoch 16/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 86.4269 - val_loss: 80.8284\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.09285\n",
            "Epoch 17/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 77.7124 - val_loss: 74.1138\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.09285\n",
            "Epoch 18/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 73.4467 - val_loss: 71.2346\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.09285\n",
            "Epoch 19/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 69.7020 - val_loss: 69.0837\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.09285\n",
            "Epoch 20/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 66.3982 - val_loss: 66.5767\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.09285\n",
            "Epoch 21/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 68.1003 - val_loss: 68.3335\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.09285\n",
            "Epoch 22/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 64.2564 - val_loss: 61.7584\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.09285\n",
            "Epoch 23/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 62.4062 - val_loss: 61.3973\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.09285\n",
            "Epoch 24/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 61.7255 - val_loss: 60.0470\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.09285\n",
            "Epoch 25/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 61.2557 - val_loss: 59.1393\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.09285\n",
            "Epoch 26/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 59.8056 - val_loss: 57.6034\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.09285\n",
            "Epoch 27/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 59.3128 - val_loss: 56.7713\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.09285\n",
            "Epoch 28/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 58.3432 - val_loss: 56.6571\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.09285\n",
            "Epoch 29/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 59.3305 - val_loss: 55.3556\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.09285\n",
            "Epoch 30/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 57.6283 - val_loss: 54.9831\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.09285\n",
            "Epoch 31/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 57.1190 - val_loss: 54.0340\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.09285\n",
            "Epoch 32/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 57.5524 - val_loss: 53.5774\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.09285\n",
            "Epoch 33/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 58.0074 - val_loss: 51.4058\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.09285\n",
            "Epoch 34/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 56.8607 - val_loss: 52.0888\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.09285\n",
            "Epoch 35/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 55.3811 - val_loss: 50.3789\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.09285\n",
            "Epoch 36/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 55.1811 - val_loss: 49.6012\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.09285\n",
            "Epoch 37/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 53.9122 - val_loss: 48.8256\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.09285\n",
            "Epoch 38/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 53.8875 - val_loss: 48.3844\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.09285\n",
            "Epoch 39/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 55.0041 - val_loss: 50.1080\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.09285\n",
            "Epoch 40/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 53.3933 - val_loss: 48.0644\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.09285\n",
            "Epoch 41/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 52.3909 - val_loss: 47.5738\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.09285\n",
            "Epoch 42/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 53.6154 - val_loss: 47.8545\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.09285\n",
            "Epoch 43/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 51.7566 - val_loss: 46.8056\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.09285\n",
            "Epoch 44/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 51.9921 - val_loss: 48.0632\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.09285\n",
            "Epoch 45/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 51.3038 - val_loss: 47.5484\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.09285\n",
            "Epoch 46/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 51.8905 - val_loss: 46.2976\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.09285\n",
            "Epoch 47/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 51.4797 - val_loss: 48.5748\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.09285\n",
            "Epoch 48/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 52.5578 - val_loss: 45.6381\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.09285\n",
            "Epoch 49/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 50.9698 - val_loss: 45.2410\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.09285\n",
            "Epoch 50/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 49.8330 - val_loss: 44.9208\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.09285\n",
            "Epoch 51/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 49.6356 - val_loss: 44.4869\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.09285\n",
            "Epoch 52/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 49.7403 - val_loss: 45.7991\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.09285\n",
            "Epoch 53/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 48.3052 - val_loss: 45.2215\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.09285\n",
            "Epoch 54/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 48.5026 - val_loss: 44.0174\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.09285\n",
            "Epoch 55/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 47.5977 - val_loss: 44.0988\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.09285\n",
            "Epoch 56/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 47.7069 - val_loss: 43.5449\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.09285\n",
            "Epoch 57/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 47.5188 - val_loss: 46.1451\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.09285\n",
            "Epoch 58/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 47.3506 - val_loss: 43.4735\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.09285\n",
            "Epoch 59/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 47.5892 - val_loss: 42.5724\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.09285\n",
            "Epoch 60/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 46.0838 - val_loss: 41.9759\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.09285\n",
            "Epoch 61/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 45.3257 - val_loss: 41.9832\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.09285\n",
            "Epoch 62/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 45.0241 - val_loss: 42.7609\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.09285\n",
            "Epoch 63/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 45.3277 - val_loss: 43.1473\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.09285\n",
            "Epoch 64/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 45.3158 - val_loss: 41.0125\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.09285\n",
            "Epoch 65/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 44.5384 - val_loss: 43.7124\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.09285\n",
            "Epoch 66/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 43.9551 - val_loss: 40.3878\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.09285\n",
            "Epoch 67/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 43.3283 - val_loss: 42.5698\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.09285\n",
            "Epoch 68/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 45.0084 - val_loss: 39.8797\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.09285\n",
            "Epoch 69/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 42.1796 - val_loss: 39.2197\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.09285\n",
            "Epoch 70/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 43.0000 - val_loss: 38.8402\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.09285\n",
            "Epoch 71/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 43.3090 - val_loss: 39.2335\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.09285\n",
            "Epoch 72/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 42.7822 - val_loss: 38.4811\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.09285\n",
            "Epoch 73/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 41.0861 - val_loss: 38.7986\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.09285\n",
            "Epoch 74/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 41.6473 - val_loss: 37.6571\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.09285\n",
            "Epoch 75/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 41.7144 - val_loss: 37.9880\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.09285\n",
            "Epoch 76/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 41.9119 - val_loss: 42.0353\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.09285\n",
            "Epoch 77/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 42.4716 - val_loss: 39.0783\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.09285\n",
            "Epoch 78/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 40.0693 - val_loss: 37.0763\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.09285\n",
            "Epoch 79/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 39.0448 - val_loss: 36.1742\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.09285\n",
            "Epoch 80/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 39.2925 - val_loss: 36.4040\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.09285\n",
            "Epoch 81/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 39.7263 - val_loss: 35.8362\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.09285\n",
            "Epoch 82/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 39.8983 - val_loss: 39.7647\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.09285\n",
            "Epoch 83/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 38.9272 - val_loss: 36.0902\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.09285\n",
            "Epoch 84/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 39.2182 - val_loss: 36.8814\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.09285\n",
            "Epoch 85/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 37.3410 - val_loss: 35.4132\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.09285\n",
            "Epoch 86/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 37.6408 - val_loss: 34.5514\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.09285\n",
            "Epoch 87/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 38.8824 - val_loss: 34.2139\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.09285\n",
            "Epoch 88/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 36.8947 - val_loss: 34.0785\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.09285\n",
            "Epoch 89/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 37.3211 - val_loss: 35.5223\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.09285\n",
            "Epoch 90/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 36.9055 - val_loss: 34.2110\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.09285\n",
            "Epoch 91/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 36.6891 - val_loss: 34.6340\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.09285\n",
            "Epoch 92/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 35.8237 - val_loss: 33.2467\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.09285\n",
            "Epoch 93/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 36.4588 - val_loss: 32.7275\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.09285\n",
            "Epoch 94/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 36.3078 - val_loss: 32.7090\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.09285\n",
            "Epoch 95/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 38.9868 - val_loss: 38.9689\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.09285\n",
            "Epoch 96/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 38.7625 - val_loss: 32.2705\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.09285\n",
            "Epoch 97/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 34.7089 - val_loss: 31.8762\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.09285\n",
            "Epoch 98/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 34.3007 - val_loss: 32.9530\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.09285\n",
            "Epoch 99/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 34.7788 - val_loss: 33.6757\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.09285\n",
            "Epoch 100/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 38.7964 - val_loss: 37.9010\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.09285\n",
            "Epoch 101/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 34.0167 - val_loss: 31.4112\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.09285\n",
            "Epoch 102/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 33.7341 - val_loss: 31.2412\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 0.09285\n",
            "Epoch 103/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 34.6482 - val_loss: 30.9955\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 0.09285\n",
            "Epoch 104/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 33.3244 - val_loss: 31.9086\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.09285\n",
            "Epoch 105/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 35.0457 - val_loss: 34.4387\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 0.09285\n",
            "Epoch 106/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 34.0524 - val_loss: 32.2052\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.09285\n",
            "Epoch 107/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 34.9024 - val_loss: 30.5007\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.09285\n",
            "Epoch 108/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 32.8432 - val_loss: 30.3144\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.09285\n",
            "Epoch 109/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 33.0427 - val_loss: 29.8358\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.09285\n",
            "Epoch 110/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 34.4515 - val_loss: 30.4008\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.09285\n",
            "Epoch 111/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 32.4357 - val_loss: 30.5822\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.09285\n",
            "Epoch 112/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 32.6739 - val_loss: 28.9014\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.09285\n",
            "Epoch 113/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 32.0073 - val_loss: 29.1655\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.09285\n",
            "Epoch 114/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 32.3877 - val_loss: 29.4832\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.09285\n",
            "Epoch 115/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 33.0649 - val_loss: 34.3071\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.09285\n",
            "Epoch 116/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 32.3920 - val_loss: 29.7867\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.09285\n",
            "Epoch 117/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 32.6369 - val_loss: 30.2027\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.09285\n",
            "Epoch 118/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 31.1794 - val_loss: 28.3703\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.09285\n",
            "Epoch 119/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 34.2405 - val_loss: 28.1243\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 0.09285\n",
            "Epoch 120/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 33.2196 - val_loss: 29.0833\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.09285\n",
            "Epoch 121/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 31.2372 - val_loss: 27.5800\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.09285\n",
            "Epoch 122/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 32.4620 - val_loss: 33.7994\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.09285\n",
            "Epoch 123/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 31.8135 - val_loss: 32.0720\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 0.09285\n",
            "Epoch 124/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 31.9241 - val_loss: 27.5193\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.09285\n",
            "Epoch 125/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 33.6741 - val_loss: 28.6562\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.09285\n",
            "Epoch 126/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 32.7811 - val_loss: 29.5269\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.09285\n",
            "Epoch 127/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 32.1809 - val_loss: 27.4968\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.09285\n",
            "Epoch 128/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 30.9118 - val_loss: 28.2934\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.09285\n",
            "Epoch 129/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 30.3584 - val_loss: 27.8233\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.09285\n",
            "Epoch 130/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 30.0062 - val_loss: 26.9437\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.09285\n",
            "Epoch 131/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 30.4381 - val_loss: 28.1739\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.09285\n",
            "Epoch 132/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 30.8317 - val_loss: 26.7493\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 0.09285\n",
            "Epoch 133/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 29.5992 - val_loss: 27.0229\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.09285\n",
            "Epoch 134/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 29.8962 - val_loss: 27.3712\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.09285\n",
            "Epoch 135/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 30.2944 - val_loss: 28.7533\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.09285\n",
            "Epoch 136/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 29.9259 - val_loss: 27.5332\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.09285\n",
            "Epoch 137/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 30.3130 - val_loss: 26.7626\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.09285\n",
            "Epoch 138/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 29.4732 - val_loss: 29.6554\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.09285\n",
            "Epoch 139/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 31.7798 - val_loss: 26.1935\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.09285\n",
            "Epoch 140/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 29.2830 - val_loss: 29.1147\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.09285\n",
            "Epoch 141/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 30.0782 - val_loss: 26.7915\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.09285\n",
            "Epoch 142/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 29.8857 - val_loss: 26.9932\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.09285\n",
            "Epoch 143/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 29.5122 - val_loss: 25.4980\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.09285\n",
            "Epoch 144/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 29.3856 - val_loss: 25.7567\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.09285\n",
            "Epoch 145/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 31.0985 - val_loss: 24.7472\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.09285\n",
            "Epoch 146/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 28.4948 - val_loss: 25.9352\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.09285\n",
            "Epoch 147/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 28.8254 - val_loss: 25.9911\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.09285\n",
            "Epoch 148/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 27.6063 - val_loss: 34.7368\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 0.09285\n",
            "Epoch 149/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 30.3771 - val_loss: 29.5341\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 0.09285\n",
            "Epoch 150/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 27.9875 - val_loss: 24.9836\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.09285\n",
            "Epoch 151/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 28.8478 - val_loss: 25.0266\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.09285\n",
            "Epoch 152/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 29.8166 - val_loss: 27.5540\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.09285\n",
            "Epoch 153/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 27.7022 - val_loss: 24.9004\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 0.09285\n",
            "Epoch 154/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 27.4871 - val_loss: 25.8772\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.09285\n",
            "Epoch 155/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 29.9661 - val_loss: 28.5602\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.09285\n",
            "          loss   val_loss\n",
            "150  28.847822  25.026646\n",
            "151  29.816582  27.553970\n",
            "152  27.702183  24.900425\n",
            "153  27.487135  25.877171\n",
            "154  29.966087  28.560232\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "실제가격 : 19.400, 예상가격 : 23.431\n",
            "실제가격 : 10.900, 예상가격 : 16.942\n",
            "실제가격 : 34.700, 예상가격 : 31.906\n",
            "실제가격 : 15.600, 예상가격 : 15.846\n",
            "실제가격 : 22.600, 예상가격 : 26.616\n",
            "실제가격 : 29.000, 예상가격 : 28.338\n",
            "실제가격 : 23.800, 예상가격 : 26.239\n",
            "실제가격 : 45.400, 예상가격 : 41.711\n",
            "실제가격 : 50.000, 예상가격 : 33.624\n",
            "실제가격 : 26.700, 예상가격 : 29.739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMFRRFtDf7g7"
      },
      "source": [
        "보스턴 집값 예측 정규화 적용\n",
        "- X_train과 X_test 정규화 하기\n",
        "- 정규화 방법은 Z_Score Normaliztion을 적용\n",
        "- 동일 결과를 StandardScaler()를 사용해 보기\n",
        "- 실제 data와 예측 data의 차를 평균을 통해 정규화 전/후 비교해보기\n",
        "- 공식 : (X-평균) / 표준편차  \n",
        "mean = X_train.mean(axis=0)  \n",
        "X_train -= mean  \n",
        "std = X_train.std(axis=0)  \n",
        "X_train /= std"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Gt5yuEq1fwRx",
        "outputId": "f48b907b-d2ef-4c01-ddb2-07ca460da473"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#seed값 설정\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "#데이터 입력\n",
        "df_pre = pd.read_csv(\"/housing.csv\", delim_whitespace=True, header=None)\n",
        "df = df_pre.sample(frac=1)\n",
        "\n",
        "#데이터 분류\n",
        "dataset = df.values\n",
        "X = dataset[:, 0:13]\n",
        "Y = dataset[:, 13]\n",
        "\n",
        "#pandas의 plot box를 사용해 data 확인해보기\n",
        "df.plot.box(figsize=(10,10))\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=seed)\n",
        "\n",
        "#X_train만 boxplot으로 시각화 확인\n",
        "plt.boxplot(X_train)\n",
        "plt.show()\n",
        "\n",
        "#정규화\n",
        "mean = X_train.mean(axis=0)\n",
        "X_train -= mean\n",
        "std = X_train.std(axis=0)\n",
        "X_train /= std\n",
        "X_test -= mean\n",
        "X_test /= std\n",
        "\n",
        "#X_train만 boxplot으로 정규화 이후 시각화 확인\n",
        "plt.boxplot(X_train)\n",
        "plt.show()\n",
        "\n",
        "#모델 설정\n",
        "model = Sequential()\n",
        "model.add(Dense(30, input_dim=13, activation='relu'))\n",
        "model.add(Dense(6, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "#모델 컴파일\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "#자동 중단 설정\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=50)\n",
        "\n",
        "#모델 저장 조건 설정\n",
        "modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "\n",
        "#모델 실행\n",
        "history = model.fit(X_train, Y_train, validation_split=0.33, epochs=5000, batch_size=10, callbacks=[early_stopping_callback, checkpointer])\n",
        "\n",
        "hist = pd.DataFrame(history.history)\n",
        "print(hist.tail())\n",
        "\n",
        "#val값에 테스트셋으로 실험 결과의 오차 값을 저장\n",
        "y_vloss = history.history['val_loss']\n",
        "\n",
        "#원래 값에 학습셋으로 측정한 정확도의 값을 저장\n",
        "y_loss = history.history['loss']\n",
        "\n",
        "#x값을 지정하고 정확도를 파란색으로, 오차를 빨간색으로 표시\n",
        "x_len = np.arange(len(y_loss))\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(x_len, y_vloss, \"o\", c=\"red\", markersize=3, label='val_loss')\n",
        "plt.plot(x_len, y_loss, \"o\", c=\"blue\", markersize=3, label='loss')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#예측 값과 실제 값의 비교\n",
        "Y_prediction = model.predict(X_test).flatten()\n",
        "for i in range(10):\n",
        "    label = Y_test[i]\n",
        "    prediction = Y_prediction[i]\n",
        "    print(\"실제가격 : {:.3f}, 예상가격 : {:.3f}\".format(label, prediction))\n",
        "\n",
        "#예측 값과 실제값 그래프로 비교\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(Y_prediction, c='red')\n",
        "plt.plot(Y_test, c=\"blue\")\n",
        "\n",
        "#예측값과 실제값 오차 평균을 측정\n",
        "avr = abs(Y_prediction - Y_test).mean()\n",
        "print(avr)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5000\n",
            "24/24 [==============================] - 0s 6ms/step - loss: 598.5685 - val_loss: 583.3478\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 583.34778, saving model to ./model/01-583.3478.hdf5\n",
            "Epoch 2/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 576.6685 - val_loss: 565.3906\n",
            "\n",
            "Epoch 00002: val_loss improved from 583.34778 to 565.39056, saving model to ./model/02-565.3906.hdf5\n",
            "Epoch 3/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 557.5626 - val_loss: 543.7240\n",
            "\n",
            "Epoch 00003: val_loss improved from 565.39056 to 543.72400, saving model to ./model/03-543.7240.hdf5\n",
            "Epoch 4/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 530.7675 - val_loss: 511.1332\n",
            "\n",
            "Epoch 00004: val_loss improved from 543.72400 to 511.13318, saving model to ./model/04-511.1332.hdf5\n",
            "Epoch 5/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 493.5795 - val_loss: 466.9056\n",
            "\n",
            "Epoch 00005: val_loss improved from 511.13318 to 466.90564, saving model to ./model/05-466.9056.hdf5\n",
            "Epoch 6/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 443.1310 - val_loss: 409.0855\n",
            "\n",
            "Epoch 00006: val_loss improved from 466.90564 to 409.08554, saving model to ./model/06-409.0855.hdf5\n",
            "Epoch 7/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 381.9050 - val_loss: 340.2955\n",
            "\n",
            "Epoch 00007: val_loss improved from 409.08554 to 340.29553, saving model to ./model/07-340.2955.hdf5\n",
            "Epoch 8/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 312.8849 - val_loss: 265.8389\n",
            "\n",
            "Epoch 00008: val_loss improved from 340.29553 to 265.83887, saving model to ./model/08-265.8389.hdf5\n",
            "Epoch 9/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 241.8840 - val_loss: 194.1042\n",
            "\n",
            "Epoch 00009: val_loss improved from 265.83887 to 194.10422, saving model to ./model/09-194.1042.hdf5\n",
            "Epoch 10/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 176.9308 - val_loss: 131.8357\n",
            "\n",
            "Epoch 00010: val_loss improved from 194.10422 to 131.83566, saving model to ./model/10-131.8357.hdf5\n",
            "Epoch 11/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 124.7185 - val_loss: 85.7247\n",
            "\n",
            "Epoch 00011: val_loss improved from 131.83566 to 85.72467, saving model to ./model/11-85.7247.hdf5\n",
            "Epoch 12/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 88.1018 - val_loss: 58.5982\n",
            "\n",
            "Epoch 00012: val_loss improved from 85.72467 to 58.59823, saving model to ./model/12-58.5982.hdf5\n",
            "Epoch 13/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 67.3364 - val_loss: 43.7814\n",
            "\n",
            "Epoch 00013: val_loss improved from 58.59823 to 43.78138, saving model to ./model/13-43.7814.hdf5\n",
            "Epoch 14/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 54.8705 - val_loss: 36.1033\n",
            "\n",
            "Epoch 00014: val_loss improved from 43.78138 to 36.10329, saving model to ./model/14-36.1033.hdf5\n",
            "Epoch 15/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 47.3713 - val_loss: 30.8656\n",
            "\n",
            "Epoch 00015: val_loss improved from 36.10329 to 30.86565, saving model to ./model/15-30.8656.hdf5\n",
            "Epoch 16/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 41.2646 - val_loss: 27.4504\n",
            "\n",
            "Epoch 00016: val_loss improved from 30.86565 to 27.45044, saving model to ./model/16-27.4504.hdf5\n",
            "Epoch 17/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 36.7093 - val_loss: 24.9721\n",
            "\n",
            "Epoch 00017: val_loss improved from 27.45044 to 24.97214, saving model to ./model/17-24.9721.hdf5\n",
            "Epoch 18/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 33.4073 - val_loss: 22.9383\n",
            "\n",
            "Epoch 00018: val_loss improved from 24.97214 to 22.93833, saving model to ./model/18-22.9383.hdf5\n",
            "Epoch 19/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 30.6751 - val_loss: 21.5056\n",
            "\n",
            "Epoch 00019: val_loss improved from 22.93833 to 21.50559, saving model to ./model/19-21.5056.hdf5\n",
            "Epoch 20/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 28.3718 - val_loss: 20.4124\n",
            "\n",
            "Epoch 00020: val_loss improved from 21.50559 to 20.41244, saving model to ./model/20-20.4124.hdf5\n",
            "Epoch 21/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 26.6129 - val_loss: 19.5145\n",
            "\n",
            "Epoch 00021: val_loss improved from 20.41244 to 19.51449, saving model to ./model/21-19.5145.hdf5\n",
            "Epoch 22/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 25.1876 - val_loss: 18.5451\n",
            "\n",
            "Epoch 00022: val_loss improved from 19.51449 to 18.54507, saving model to ./model/22-18.5451.hdf5\n",
            "Epoch 23/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 23.9225 - val_loss: 17.8432\n",
            "\n",
            "Epoch 00023: val_loss improved from 18.54507 to 17.84315, saving model to ./model/23-17.8432.hdf5\n",
            "Epoch 24/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 22.9197 - val_loss: 17.2407\n",
            "\n",
            "Epoch 00024: val_loss improved from 17.84315 to 17.24068, saving model to ./model/24-17.2407.hdf5\n",
            "Epoch 25/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 22.0089 - val_loss: 16.7952\n",
            "\n",
            "Epoch 00025: val_loss improved from 17.24068 to 16.79524, saving model to ./model/25-16.7952.hdf5\n",
            "Epoch 26/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 21.2354 - val_loss: 16.3396\n",
            "\n",
            "Epoch 00026: val_loss improved from 16.79524 to 16.33962, saving model to ./model/26-16.3396.hdf5\n",
            "Epoch 27/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 20.5336 - val_loss: 15.8687\n",
            "\n",
            "Epoch 00027: val_loss improved from 16.33962 to 15.86870, saving model to ./model/27-15.8687.hdf5\n",
            "Epoch 28/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 19.8244 - val_loss: 15.4011\n",
            "\n",
            "Epoch 00028: val_loss improved from 15.86870 to 15.40114, saving model to ./model/28-15.4011.hdf5\n",
            "Epoch 29/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 19.2893 - val_loss: 15.0008\n",
            "\n",
            "Epoch 00029: val_loss improved from 15.40114 to 15.00084, saving model to ./model/29-15.0008.hdf5\n",
            "Epoch 30/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 18.6887 - val_loss: 14.5507\n",
            "\n",
            "Epoch 00030: val_loss improved from 15.00084 to 14.55065, saving model to ./model/30-14.5507.hdf5\n",
            "Epoch 31/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 18.1193 - val_loss: 14.3334\n",
            "\n",
            "Epoch 00031: val_loss improved from 14.55065 to 14.33337, saving model to ./model/31-14.3334.hdf5\n",
            "Epoch 32/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 17.7294 - val_loss: 14.0640\n",
            "\n",
            "Epoch 00032: val_loss improved from 14.33337 to 14.06399, saving model to ./model/32-14.0640.hdf5\n",
            "Epoch 33/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 17.3472 - val_loss: 13.5506\n",
            "\n",
            "Epoch 00033: val_loss improved from 14.06399 to 13.55058, saving model to ./model/33-13.5506.hdf5\n",
            "Epoch 34/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 16.7726 - val_loss: 13.3714\n",
            "\n",
            "Epoch 00034: val_loss improved from 13.55058 to 13.37136, saving model to ./model/34-13.3714.hdf5\n",
            "Epoch 35/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 16.4040 - val_loss: 12.9633\n",
            "\n",
            "Epoch 00035: val_loss improved from 13.37136 to 12.96334, saving model to ./model/35-12.9633.hdf5\n",
            "Epoch 36/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 15.9842 - val_loss: 12.6325\n",
            "\n",
            "Epoch 00036: val_loss improved from 12.96334 to 12.63252, saving model to ./model/36-12.6325.hdf5\n",
            "Epoch 37/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 15.6379 - val_loss: 12.4772\n",
            "\n",
            "Epoch 00037: val_loss improved from 12.63252 to 12.47721, saving model to ./model/37-12.4772.hdf5\n",
            "Epoch 38/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 15.3154 - val_loss: 12.1575\n",
            "\n",
            "Epoch 00038: val_loss improved from 12.47721 to 12.15749, saving model to ./model/38-12.1575.hdf5\n",
            "Epoch 39/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 15.0493 - val_loss: 12.1218\n",
            "\n",
            "Epoch 00039: val_loss improved from 12.15749 to 12.12175, saving model to ./model/39-12.1218.hdf5\n",
            "Epoch 40/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 14.5546 - val_loss: 11.7387\n",
            "\n",
            "Epoch 00040: val_loss improved from 12.12175 to 11.73875, saving model to ./model/40-11.7387.hdf5\n",
            "Epoch 41/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 14.2420 - val_loss: 11.4711\n",
            "\n",
            "Epoch 00041: val_loss improved from 11.73875 to 11.47110, saving model to ./model/41-11.4711.hdf5\n",
            "Epoch 42/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 13.9640 - val_loss: 11.2623\n",
            "\n",
            "Epoch 00042: val_loss improved from 11.47110 to 11.26226, saving model to ./model/42-11.2623.hdf5\n",
            "Epoch 43/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 13.7170 - val_loss: 11.0996\n",
            "\n",
            "Epoch 00043: val_loss improved from 11.26226 to 11.09956, saving model to ./model/43-11.0996.hdf5\n",
            "Epoch 44/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 13.3474 - val_loss: 10.8126\n",
            "\n",
            "Epoch 00044: val_loss improved from 11.09956 to 10.81258, saving model to ./model/44-10.8126.hdf5\n",
            "Epoch 45/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 13.0641 - val_loss: 10.7198\n",
            "\n",
            "Epoch 00045: val_loss improved from 10.81258 to 10.71980, saving model to ./model/45-10.7198.hdf5\n",
            "Epoch 46/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 12.7921 - val_loss: 10.5478\n",
            "\n",
            "Epoch 00046: val_loss improved from 10.71980 to 10.54780, saving model to ./model/46-10.5478.hdf5\n",
            "Epoch 47/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 12.5664 - val_loss: 10.4833\n",
            "\n",
            "Epoch 00047: val_loss improved from 10.54780 to 10.48332, saving model to ./model/47-10.4833.hdf5\n",
            "Epoch 48/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 12.2975 - val_loss: 10.2712\n",
            "\n",
            "Epoch 00048: val_loss improved from 10.48332 to 10.27120, saving model to ./model/48-10.2712.hdf5\n",
            "Epoch 49/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 12.0582 - val_loss: 10.1395\n",
            "\n",
            "Epoch 00049: val_loss improved from 10.27120 to 10.13947, saving model to ./model/49-10.1395.hdf5\n",
            "Epoch 50/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 11.8716 - val_loss: 10.0361\n",
            "\n",
            "Epoch 00050: val_loss improved from 10.13947 to 10.03610, saving model to ./model/50-10.0361.hdf5\n",
            "Epoch 51/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 11.6752 - val_loss: 9.8221\n",
            "\n",
            "Epoch 00051: val_loss improved from 10.03610 to 9.82210, saving model to ./model/51-9.8221.hdf5\n",
            "Epoch 52/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 11.4207 - val_loss: 9.7511\n",
            "\n",
            "Epoch 00052: val_loss improved from 9.82210 to 9.75110, saving model to ./model/52-9.7511.hdf5\n",
            "Epoch 53/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 11.4211 - val_loss: 9.7997\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 9.75110\n",
            "Epoch 54/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 11.1220 - val_loss: 9.4887\n",
            "\n",
            "Epoch 00054: val_loss improved from 9.75110 to 9.48866, saving model to ./model/54-9.4887.hdf5\n",
            "Epoch 55/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 10.8973 - val_loss: 9.4754\n",
            "\n",
            "Epoch 00055: val_loss improved from 9.48866 to 9.47542, saving model to ./model/55-9.4754.hdf5\n",
            "Epoch 56/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 10.8384 - val_loss: 9.2403\n",
            "\n",
            "Epoch 00056: val_loss improved from 9.47542 to 9.24028, saving model to ./model/56-9.2403.hdf5\n",
            "Epoch 57/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 10.5822 - val_loss: 9.4109\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 9.24028\n",
            "Epoch 58/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 10.4461 - val_loss: 9.1778\n",
            "\n",
            "Epoch 00058: val_loss improved from 9.24028 to 9.17783, saving model to ./model/58-9.1778.hdf5\n",
            "Epoch 59/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 10.2558 - val_loss: 9.2132\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 9.17783\n",
            "Epoch 60/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 10.1614 - val_loss: 8.9575\n",
            "\n",
            "Epoch 00060: val_loss improved from 9.17783 to 8.95746, saving model to ./model/60-8.9575.hdf5\n",
            "Epoch 61/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 9.9780 - val_loss: 9.0875\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 8.95746\n",
            "Epoch 62/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 9.8829 - val_loss: 9.0872\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 8.95746\n",
            "Epoch 63/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 9.7696 - val_loss: 8.7591\n",
            "\n",
            "Epoch 00063: val_loss improved from 8.95746 to 8.75914, saving model to ./model/63-8.7591.hdf5\n",
            "Epoch 64/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 9.5575 - val_loss: 9.0190\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 8.75914\n",
            "Epoch 65/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 9.5014 - val_loss: 8.8288\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 8.75914\n",
            "Epoch 66/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 9.3700 - val_loss: 8.6122\n",
            "\n",
            "Epoch 00066: val_loss improved from 8.75914 to 8.61222, saving model to ./model/66-8.6122.hdf5\n",
            "Epoch 67/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 9.2103 - val_loss: 8.7403\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 8.61222\n",
            "Epoch 68/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 9.2106 - val_loss: 8.7074\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 8.61222\n",
            "Epoch 69/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 9.0175 - val_loss: 8.8154\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 8.61222\n",
            "Epoch 70/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 9.1014 - val_loss: 8.5311\n",
            "\n",
            "Epoch 00070: val_loss improved from 8.61222 to 8.53112, saving model to ./model/70-8.5311.hdf5\n",
            "Epoch 71/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 8.9113 - val_loss: 8.5452\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 8.53112\n",
            "Epoch 72/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 8.7457 - val_loss: 8.7313\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 8.53112\n",
            "Epoch 73/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 8.7889 - val_loss: 8.5582\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 8.53112\n",
            "Epoch 74/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 8.5966 - val_loss: 8.4947\n",
            "\n",
            "Epoch 00074: val_loss improved from 8.53112 to 8.49474, saving model to ./model/74-8.4947.hdf5\n",
            "Epoch 75/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 8.5380 - val_loss: 8.4520\n",
            "\n",
            "Epoch 00075: val_loss improved from 8.49474 to 8.45202, saving model to ./model/75-8.4520.hdf5\n",
            "Epoch 76/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 8.4792 - val_loss: 8.3727\n",
            "\n",
            "Epoch 00076: val_loss improved from 8.45202 to 8.37272, saving model to ./model/76-8.3727.hdf5\n",
            "Epoch 77/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 8.3177 - val_loss: 8.5845\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 8.37272\n",
            "Epoch 78/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 8.2640 - val_loss: 8.3805\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 8.37272\n",
            "Epoch 79/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 8.2664 - val_loss: 8.2595\n",
            "\n",
            "Epoch 00079: val_loss improved from 8.37272 to 8.25946, saving model to ./model/79-8.2595.hdf5\n",
            "Epoch 80/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 8.2938 - val_loss: 8.4011\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 8.25946\n",
            "Epoch 81/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 8.1234 - val_loss: 8.2526\n",
            "\n",
            "Epoch 00081: val_loss improved from 8.25946 to 8.25261, saving model to ./model/81-8.2526.hdf5\n",
            "Epoch 82/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 7.9786 - val_loss: 8.4578\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 8.25261\n",
            "Epoch 83/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 7.9789 - val_loss: 8.2387\n",
            "\n",
            "Epoch 00083: val_loss improved from 8.25261 to 8.23867, saving model to ./model/83-8.2387.hdf5\n",
            "Epoch 84/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 7.9011 - val_loss: 8.3280\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 8.23867\n",
            "Epoch 85/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 7.8740 - val_loss: 8.2550\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 8.23867\n",
            "Epoch 86/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 7.8365 - val_loss: 8.1730\n",
            "\n",
            "Epoch 00086: val_loss improved from 8.23867 to 8.17299, saving model to ./model/86-8.1730.hdf5\n",
            "Epoch 87/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 8.0938 - val_loss: 8.3177\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 8.17299\n",
            "Epoch 88/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 7.6753 - val_loss: 8.1584\n",
            "\n",
            "Epoch 00088: val_loss improved from 8.17299 to 8.15844, saving model to ./model/88-8.1584.hdf5\n",
            "Epoch 89/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 7.6774 - val_loss: 8.2192\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 8.15844\n",
            "Epoch 90/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 7.5850 - val_loss: 8.1939\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 8.15844\n",
            "Epoch 91/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 7.4884 - val_loss: 8.2872\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 8.15844\n",
            "Epoch 92/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 7.5377 - val_loss: 8.1909\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 8.15844\n",
            "Epoch 93/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 7.4115 - val_loss: 8.2501\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 8.15844\n",
            "Epoch 94/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 7.5601 - val_loss: 8.1092\n",
            "\n",
            "Epoch 00094: val_loss improved from 8.15844 to 8.10917, saving model to ./model/94-8.1092.hdf5\n",
            "Epoch 95/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 7.3439 - val_loss: 8.2385\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 8.10917\n",
            "Epoch 96/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 7.3009 - val_loss: 8.1622\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 8.10917\n",
            "Epoch 97/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 7.2859 - val_loss: 8.1260\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 8.10917\n",
            "Epoch 98/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 7.2167 - val_loss: 8.2955\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 8.10917\n",
            "Epoch 99/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 7.1950 - val_loss: 8.1819\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 8.10917\n",
            "Epoch 100/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 7.1967 - val_loss: 8.2133\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 8.10917\n",
            "Epoch 101/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 7.1827 - val_loss: 8.1537\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 8.10917\n",
            "Epoch 102/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 7.0645 - val_loss: 8.1230\n",
            "\n",
            "Epoch 00102: val_loss did not improve from 8.10917\n",
            "Epoch 103/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 7.0162 - val_loss: 8.1294\n",
            "\n",
            "Epoch 00103: val_loss did not improve from 8.10917\n",
            "Epoch 104/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 6.9886 - val_loss: 8.1389\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 8.10917\n",
            "Epoch 105/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 6.9934 - val_loss: 8.2608\n",
            "\n",
            "Epoch 00105: val_loss did not improve from 8.10917\n",
            "Epoch 106/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 7.0033 - val_loss: 8.2123\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 8.10917\n",
            "Epoch 107/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 6.9108 - val_loss: 7.9893\n",
            "\n",
            "Epoch 00107: val_loss improved from 8.10917 to 7.98933, saving model to ./model/107-7.9893.hdf5\n",
            "Epoch 108/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 6.9277 - val_loss: 8.3055\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 7.98933\n",
            "Epoch 109/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 6.9332 - val_loss: 8.1649\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 7.98933\n",
            "Epoch 110/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 6.9145 - val_loss: 8.3363\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 7.98933\n",
            "Epoch 111/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 6.8396 - val_loss: 8.1306\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 7.98933\n",
            "Epoch 112/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 6.7519 - val_loss: 8.2086\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 7.98933\n",
            "Epoch 113/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 6.7029 - val_loss: 8.1722\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 7.98933\n",
            "Epoch 114/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 6.6771 - val_loss: 8.1986\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 7.98933\n",
            "Epoch 115/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 6.6603 - val_loss: 8.1936\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 7.98933\n",
            "Epoch 116/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 6.5975 - val_loss: 8.1807\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 7.98933\n",
            "Epoch 117/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 6.5958 - val_loss: 8.1770\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 7.98933\n",
            "Epoch 118/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 6.5893 - val_loss: 8.3696\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 7.98933\n",
            "Epoch 119/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 6.5500 - val_loss: 8.0636\n",
            "\n",
            "Epoch 00119: val_loss did not improve from 7.98933\n",
            "Epoch 120/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 6.4699 - val_loss: 8.2862\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 7.98933\n",
            "Epoch 121/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 6.4407 - val_loss: 8.2473\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 7.98933\n",
            "Epoch 122/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 6.3893 - val_loss: 8.2217\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 7.98933\n",
            "Epoch 123/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 6.4246 - val_loss: 8.1464\n",
            "\n",
            "Epoch 00123: val_loss did not improve from 7.98933\n",
            "Epoch 124/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 6.3542 - val_loss: 8.3764\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 7.98933\n",
            "Epoch 125/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 6.3568 - val_loss: 8.2589\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 7.98933\n",
            "Epoch 126/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 6.3330 - val_loss: 8.3401\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 7.98933\n",
            "Epoch 127/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 6.3054 - val_loss: 8.2744\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 7.98933\n",
            "Epoch 128/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 6.3497 - val_loss: 8.1596\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 7.98933\n",
            "Epoch 129/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 6.2233 - val_loss: 8.4390\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 7.98933\n",
            "Epoch 130/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 6.2286 - val_loss: 8.3104\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 7.98933\n",
            "Epoch 131/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 6.1765 - val_loss: 8.2872\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 7.98933\n",
            "Epoch 132/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 6.1716 - val_loss: 8.2187\n",
            "\n",
            "Epoch 00132: val_loss did not improve from 7.98933\n",
            "Epoch 133/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 6.1080 - val_loss: 8.4093\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 7.98933\n",
            "Epoch 134/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 6.0729 - val_loss: 8.2606\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 7.98933\n",
            "Epoch 135/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 6.0405 - val_loss: 8.3838\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 7.98933\n",
            "Epoch 136/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 5.9951 - val_loss: 8.3788\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 7.98933\n",
            "Epoch 137/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 5.9964 - val_loss: 8.4411\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 7.98933\n",
            "Epoch 138/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 5.9724 - val_loss: 8.4504\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 7.98933\n",
            "Epoch 139/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 5.9370 - val_loss: 8.3267\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 7.98933\n",
            "Epoch 140/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 6.0061 - val_loss: 8.4550\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 7.98933\n",
            "Epoch 141/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 5.8635 - val_loss: 8.2776\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 7.98933\n",
            "Epoch 142/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 5.8611 - val_loss: 8.6593\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 7.98933\n",
            "Epoch 143/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 5.8264 - val_loss: 8.5781\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 7.98933\n",
            "Epoch 144/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 5.8030 - val_loss: 8.5242\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 7.98933\n",
            "Epoch 145/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 5.7941 - val_loss: 8.4807\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 7.98933\n",
            "Epoch 146/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 5.7751 - val_loss: 8.3656\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 7.98933\n",
            "Epoch 147/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 5.7744 - val_loss: 8.4931\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 7.98933\n",
            "Epoch 148/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 5.7032 - val_loss: 8.4695\n",
            "\n",
            "Epoch 00148: val_loss did not improve from 7.98933\n",
            "Epoch 149/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 5.6619 - val_loss: 8.4892\n",
            "\n",
            "Epoch 00149: val_loss did not improve from 7.98933\n",
            "Epoch 150/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 5.6293 - val_loss: 8.4172\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 7.98933\n",
            "Epoch 151/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 5.6256 - val_loss: 8.6060\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 7.98933\n",
            "Epoch 152/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 5.6260 - val_loss: 8.5219\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 7.98933\n",
            "Epoch 153/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 5.5683 - val_loss: 8.5257\n",
            "\n",
            "Epoch 00153: val_loss did not improve from 7.98933\n",
            "Epoch 154/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 5.6256 - val_loss: 8.6399\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 7.98933\n",
            "Epoch 155/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 5.6577 - val_loss: 8.4562\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 7.98933\n",
            "Epoch 156/5000\n",
            "24/24 [==============================] - 0s 2ms/step - loss: 5.5639 - val_loss: 8.4790\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 7.98933\n",
            "Epoch 157/5000\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 5.5031 - val_loss: 8.6275\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 7.98933\n",
            "         loss  val_loss\n",
            "152  5.568348  8.525730\n",
            "153  5.625607  8.639906\n",
            "154  5.657723  8.456211\n",
            "155  5.563896  8.478953\n",
            "156  5.503072  8.627545\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "실제가격 : 19.400, 예상가격 : 18.025\n",
            "실제가격 : 10.900, 예상가격 : 12.650\n",
            "실제가격 : 34.700, 예상가격 : 31.101\n",
            "실제가격 : 15.600, 예상가격 : 15.147\n",
            "실제가격 : 22.600, 예상가격 : 24.207\n",
            "실제가격 : 29.000, 예상가격 : 32.969\n",
            "실제가격 : 23.800, 예상가격 : 21.323\n",
            "실제가격 : 45.400, 예상가격 : 42.453\n",
            "실제가격 : 50.000, 예상가격 : 47.442\n",
            "실제가격 : 26.700, 예상가격 : 31.217\n",
            "2.566477078513095\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}