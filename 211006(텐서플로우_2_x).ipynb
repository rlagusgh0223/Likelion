{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "211006(텐서플로우 2.x)",
      "provenance": [],
      "authorship_tag": "ABX9TyNQ+HUAj4B0ROqir32sYlRO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRHJM0wu2jTq",
        "outputId": "7fec1470-c250-4bc9-e086-24dbae203b02"
      },
      "source": [
        "import tensorflow as tf\n",
        "from datetime import datetime    #텐서보드 위해\n",
        "#코랩으로 텐서보드 하려면 아래 코드 실행해야된다는데 그냥 되는것 같다\n",
        "#아래 코드는 일단 참고만\n",
        "#    %load_ext tensorboard\n",
        "#    %tensorboard --logdir=logs/mylogs\n",
        "#원래는 이걸 해야 파일에 mylogs가 생기는거 같은데 그냥 생겨있다\n",
        "\n",
        "#x, y의 데이터 값\n",
        "data = [[2,81], [4,93], [6,91], [8,97]]\n",
        "x_train = [x_row[0] for x_row in data]\n",
        "y_train = [y_row[1] for y_row in data]\n",
        "w = tf.Variable(tf.random.uniform([1], 0, 10, dtype=tf.float64, seed=0))\n",
        "b = tf.Variable(tf.random.uniform([1], 0, 100, dtype=tf.float64, seed=0))\n",
        "\n",
        "#2.x에서는 즉시실행을 하니까 함수형태로 만든다\n",
        "#기울기와 절편을 통해 계산되는 예상 y값\n",
        "def hypothesis(v, b):    #가설\n",
        "  return x_train * w + b\n",
        "\n",
        "@tf.function    #텐서보드 위해\n",
        "def costFunc():    #minimize에서 사용 손실(비용) 함수. 학습하는 함수\n",
        "  return tf.sqrt(tf.reduce_mean(tf.square(hypothesis(w,b) - y_train)))\n",
        "\n",
        "def cost(w, b):    #손실을 계산하는 함수, 실제 평균제곱근 나타내는 함수\n",
        "  return tf.sqrt(tf.reduce_mean(tf.square(hypothesis(w,b) - y_train)))\n",
        "\n",
        "#==텐서보드 그래프\n",
        "stamp = datetime.now().strftime(\"%Y%m%d - %H%M%S\")\n",
        "logdir = 'logs/mylogs/%s' % stamp\n",
        "writer = tf.summary.create_file_writer(logdir)\n",
        "tf.summary.trace_on(graph=True, profiler=True)\n",
        "costFunc()\n",
        "with writer.as_default():    #텐서보드(그래프추가)\n",
        "  tf.summary.trace_export(name='graph_t1', step=0, profiler_outdir=logdir)\n",
        "#===\n",
        "\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.1) #경사하강법이 가능하도록 SGD불러들임\n",
        "for i in range(2001):    #steps\n",
        "  opt.minimize(costFunc, var_list=[w,b])#1.x의 session처럼 돌리는 부분\n",
        "  if i%100 == 0:\n",
        "    print(i, f'{cost(w,b)}, {w.numpy()}, {b.numpy()}')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1298: start (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.start` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1348: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1348: save (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "`tf.python.eager.profiler` has deprecated, use `tf.profiler` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/profiler.py:151: maybe_create_event_file (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "`tf.python.eager.profiler` has deprecated, use `tf.profiler` instead.\n",
            "0 28.054120362994606, [7.5236665], [78.22530992]\n",
            "100 2.907335450703233, [2.46033278], [78.04320254]\n",
            "200 2.8895786038278084, [2.39146795], [78.4541584]\n",
            "300 2.8837641982203985, [2.35207199], [78.68925662]\n",
            "400 2.881876024628414, [2.32962379], [78.82321789]\n",
            "500 2.8812645253139695, [2.31684923], [78.89945103]\n",
            "600 2.8810666618004617, [2.3095827], [78.94281455]\n",
            "700 2.8810026572332452, [2.30544986], [78.96747755]\n",
            "800 2.8809819550604914, [2.30309942], [78.98150401]\n",
            "900 2.880975259177448, [2.30176268], [78.98948108]\n",
            "1000 2.8809730934910194, [2.30100246], [78.99401776]\n",
            "1100 2.880972393033297, [2.30057011], [78.99659782]\n",
            "1200 2.8809721664813255, [2.30032423], [78.99806514]\n",
            "1300 2.8809720932067027, [2.30018439], [78.99889962]\n",
            "1400 2.880972069507192, [2.30010487], [78.9993742]\n",
            "1500 2.8809720618419647, [2.30005964], [78.9996441]\n",
            "1600 2.880972059362775, [2.30003392], [78.9997976]\n",
            "1700 2.880972058560916, [2.30001929], [78.99988489]\n",
            "1800 2.8809720583015657, [2.30001097], [78.99993454]\n",
            "1900 2.880972058217689, [2.30000624], [78.99996277]\n",
            "2000 2.8809720581905562, [2.30000355], [78.99997883]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPNtgK1O4Udt",
        "outputId": "d70c1687-ef4e-4e31-faa7-5ecded159391"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#x, y의 데이터 값\n",
        "data = [[0.3, 12.27], [-0.78, 14.44], [1.26, 11.87], [0.03, 18.75], [1.11, 17.52], [15.17, 9.29],\n",
        "        [0.24, 16.37], [-0.24, 19.78], [-0.47, 19.51], [-0.77, 12.65], [-0.37, 14.74], [-0.85, 10.72],\n",
        "        [-0.41, 21.94], [-0.27, 12.83], [0.02, 15.51], [-0.76, 17.14], [2.66, 14.42]]\n",
        "\n",
        "x_data = [i[0] for i in data]\n",
        "y_data = [i[1] for i in data]\n",
        "del x_data[5]\n",
        "del y_data[5]\n",
        "w = tf.Variable(tf.random.uniform([1], 0, 10, dtype=tf.float64, seed=0))\n",
        "b = tf.Variable(tf.random.uniform([1], 0, 100, dtype=tf.float64, seed=0))\n",
        "\n",
        "def hypothesis(v, b):    #가설\n",
        "  return x_data * w + b\n",
        "\n",
        "def costFunc():    #minimize에서 사용 손실(비용) 함수. 학습하는 함수\n",
        "  return tf.sqrt(tf.reduce_mean(tf.square(hypothesis(w,b) - y_data)))\n",
        "\n",
        "def cost(w, b):    #손실을 계산하는 함수, 실제 평균제곱근 나타내는 함수\n",
        "  return tf.sqrt(tf.reduce_mean(tf.square(hypothesis(w,b) - y_data)))\n",
        "\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.1) #경사하강법이 가능하도록 SGD불러들임\n",
        "for i in range(2001):    #steps\n",
        "  opt.minimize(costFunc, var_list=[w,b])#1.x의 session처럼 돌리는 부분\n",
        "  if i%100 == 0:\n",
        "    print(i, f'{cost(w,b)}, {w.numpy()}, {b.numpy()}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 65.51133641202694, [0.7264622], [81.05124295]\n",
            "100 55.50987483959369, [0.18060539], [71.06541644]\n",
            "200 45.525500827197746, [-0.30235797], [61.08490489]\n",
            "300 35.5697469195525, [-0.70552657], [51.11518871]\n",
            "400 25.670405272659124, [-1.00123799], [41.17000985]\n",
            "500 15.918552352174903, [-1.13724667], [31.2957093]\n",
            "600 6.86883258971933, [-0.98998798], [21.7854939]\n",
            "700 3.1714009161187082, [-0.50753665], [16.18392719]\n",
            "800 3.127525039444982, [-0.37037567], [15.6908378]\n",
            "900 3.127427795738897, [-0.35700916], [15.67027318]\n",
            "1000 3.127427484700745, [-0.35592315], [15.66936418]\n",
            "1100 3.1274274833753006, [-0.35584069], [15.66932024]\n",
            "1200 3.1274274833689124, [-0.35583462], [15.66931789]\n",
            "1300 3.1274274833688804, [-0.35583418], [15.66931775]\n",
            "1400 3.127427483368881, [-0.35583415], [15.66931774]\n",
            "1500 3.127427483368881, [-0.35583415], [15.66931774]\n",
            "1600 3.1274274833688804, [-0.35583415], [15.66931774]\n",
            "1700 3.1274274833688804, [-0.35583415], [15.66931774]\n",
            "1800 3.1274274833688804, [-0.35583415], [15.66931774]\n",
            "1900 3.127427483368881, [-0.35583415], [15.66931774]\n",
            "2000 3.127427483368881, [-0.35583415], [15.66931774]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqJgWa_e7OPp",
        "outputId": "5a6ad2b0-39ac-438b-fa30-ca8abb1a3459"
      },
      "source": [
        "#다중선형회귀 1.x -> 2.x로 변환\n",
        "import tensorflow as tf\n",
        "\n",
        "data = [[2, 0, 81], [4, 4, 93], [6, 2, 91], [8, 3, 97]]\n",
        "x1 = [x_row1[0] for x_row1 in data]\n",
        "x2 = [x_row2[1] for x_row2 in data]\n",
        "y_data = [y_row[2] for y_row in data]\n",
        "\n",
        "a1 = tf.Variable(tf.random.uniform([1], 0, 10, dtype=tf.float64, seed=0))\n",
        "b = tf.Variable(tf.random.uniform([1], 0, 100, dtype=tf.float64, seed=0))\n",
        "a2 = tf.Variable(tf.random.uniform([1], 0, 10, dtype=tf.float64, seed=0))\n",
        "\n",
        "#기울기와 절편을 통해 계산되는 예상 Y값\n",
        "def hypothesis(a1, a2, b): #가설\n",
        "    return a1 * x1 + a2 * x2 + b\n",
        "\n",
        "def costFunc():\n",
        "    return tf.sqrt(tf.reduce_mean(tf.square(hypothesis(a1, a2, b) - y_data)))\n",
        "\n",
        "def cost(a1, a2, b):    #손실을 계산하는 함수. 실제 평균제곱근 나타내는 함수\n",
        "    return tf.sqrt(tf.reduce_mean(tf.square(hypothesis(a1, a2, b) - y_data)))\n",
        "\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
        "for i in range(2001): #steps\n",
        "    opt.minimize(costFunc, var_list=[a1, a2, b])\n",
        "    if i %100 == 0:\n",
        "        print(i, f'{cost(a1, a2, b)}, {a1.numpy()}, {a2.numpy()}, {b.numpy()}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 18.378958804659174, [7.36325529], [6.86395071], [33.13850621]\n",
            "100 16.50526794829839, [6.9970681], [5.33615235], [37.01070498]\n",
            "200 14.882511189674203, [6.68519788], [4.56112496], [40.94923014]\n",
            "300 13.289271084742209, [6.22933374], [4.10354792], [44.88759807]\n",
            "400 11.702465228733516, [5.7040438], [3.79956371], [48.82444649]\n",
            "500 10.116995487526816, [5.14824201], [3.56325793], [52.76015287]\n",
            "600 8.532035191367738, [4.58053517], [3.35349906], [56.69503574]\n",
            "700 6.947688631321025, [4.00891353], [3.15269452], [60.62904257]\n",
            "800 5.364469869710447, [3.43640102], [2.95438606], [64.56161556]\n",
            "900 3.7837878603837214, [2.86412783], [2.75672047], [68.49103655]\n",
            "1000 2.2110495150358824, [2.29326296], [2.55961007], [72.41060242]\n",
            "1100 1.835244527285039, [1.52833254], [2.26892656], [75.93838933]\n",
            "1200 1.8367547018624004, [1.34913032], [2.20481973], [77.02392772]\n",
            "1300 1.8369628430176135, [1.27907618], [2.18025662], [77.48058425]\n",
            "1400 1.8369984590167985, [1.2504962], [2.17032295], [77.67255358]\n",
            "1500 1.8370047110994359, [1.23863749], [2.16621683], [77.75322453]\n",
            "1600 1.8370058134752012, [1.23368161], [2.16450363], [77.78711912]\n",
            "1700 1.8370060079993076, [1.2316042], [2.16378599], [77.80135918]\n",
            "1800 1.8370060423295436, [1.23073228], [2.16348488], [77.80734164]\n",
            "1900 1.8370060483883974, [1.23036613], [2.16335844], [77.80985493]\n",
            "2000 1.837006049457726, [1.23021233], [2.16330533], [77.81091078]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PUDmGE17bnH",
        "outputId": "eae927be-3405-4e22-bf2f-221289c7385f"
      },
      "source": [
        "#다중 선형 회귀 - 다순 선형 회귀와 결과 비교\n",
        "import tensorflow as tf\n",
        "\n",
        "data = [[2, 0, 81], [4, 4, 93], [6, 2, 91], [8, 3, 97]]\n",
        "x1 = [x_row1[0] for x_row1 in data]\n",
        "x2 = [x_row2[1] for x_row2 in data]    #새로 추가되는 값\n",
        "y_data = [y_row[2] for y_row in data]\n",
        "\n",
        "def mul(a1, a2, b):\n",
        "    y = []\n",
        "    for i in range(len(data)):\n",
        "        y.append(a1 * x1[i] + a2*x2[i] + b)\n",
        "    print(y)\n",
        "    avr1 = sum(y)/len(data)\n",
        "    print(\"다중 선형회귀의 점수 평균 :\", avr1)\n",
        "    \n",
        "    diff_y = []\n",
        "    for i in range(len(data)):\n",
        "        diff_y.append(abs(y_data[i] - y[i]))\n",
        "    avr2 = sum(diff_y) / len(data)\n",
        "    print(\"다중 선형회귀의 오차 평균 :\", avr2)\n",
        "\n",
        "def sim(a, b):\n",
        "    y = []\n",
        "    for i in range(len(data)):\n",
        "        y.append(a*x1[i] + b)\n",
        "    print(y)\n",
        "    avr1 = sum(y)/len(data)\n",
        "    print(\"단순 선형회귀의 점수 평균 :\", avr1)\n",
        "    \n",
        "    diff_y = []\n",
        "    for i in range(len(data)):\n",
        "        diff_y.append(abs(y_data[i] - y[i]))\n",
        "    avr2 = sum(diff_y) / len(data)\n",
        "    print(\"단순 선형회귀의 오차 평균 :\", avr2)\n",
        "\n",
        "mul(1.2301, 2.1633, 77.8117)\n",
        "sim(2.3, 79)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[80.2719, 91.3853, 89.5189, 94.14240000000001]\n",
            "다중 선형회귀의 점수 평균 : 88.82962500000001\n",
            "다중 선형회귀의 오차 평균 : 1.6703749999999964\n",
            "[83.6, 88.2, 92.8, 97.4]\n",
            "단순 선형회귀의 점수 평균 : 90.5\n",
            "단순 선형회귀의 오차 평균 : 2.3999999999999986\n"
          ]
        }
      ]
    }
  ]
}