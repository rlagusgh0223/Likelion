{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "211012(텐서플로우 2.x)",
      "provenance": [],
      "authorship_tag": "ABX9TyNp+IWhQTGrRKIVlgUu8Bd2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrqx3QIRzC69",
        "outputId": "4418c427-f827-4c92-9745-352c9b697cc6"
      },
      "source": [
        "#Hidden Layer 적용하여 XOR 해결\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "learning_rate = 0.1\n",
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
        "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
        "\n",
        "W1 = tf.Variable(tf.random.uniform([2,2]), name='weight1')\n",
        "b1 = tf.Variable(tf.random.uniform([2]), name='bias1')\n",
        "W2 = tf.Variable(tf.random.uniform([2,1]), name='weight2')\n",
        "b2 = tf.Variable(tf.random.uniform([1]), name='bias2')\n",
        "\n",
        "#활성화 함수(hyp:가설)\n",
        "def hypothesis():\n",
        "    layer1 = tf.sigmoid(tf.matmul(x_data, W1) + b1)\n",
        "    cost = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
        "    return cost\n",
        "def costFunc():\n",
        "    return -tf.reduce_mean(y_data * tf.math.log(hypothesis()) + (1 - y_data) * tf.math.log(1 - hypothesis()))\n",
        "\n",
        "train = tf.keras.optimizers.SGD(learning_rate)\n",
        "for step in range(10001):\n",
        "    train.minimize(costFunc, var_list=[W1, b1, W2, b2])\n",
        "    predicted = tf.cast(hypothesis()> 0.5, dtype=tf.float64)\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y_data), dtype=tf.float64))\n",
        "    if step%500 == 0:\n",
        "        print(f'epochs={step}, cost={costFunc()}, accuracy={accuracy}')\n",
        "print(\"\\nHypothesis :\\n\",hypothesis().numpy(), \"\\nCorrect:\\n\",predicted.numpy(), \"\\nAccuracy\\n\",accuracy.numpy())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epochs=0, cost=0.7622430920600891, accuracy=0.5\n",
            "epochs=500, cost=0.6926710605621338, accuracy=0.5\n",
            "epochs=1000, cost=0.6919280290603638, accuracy=0.5\n",
            "epochs=1500, cost=0.6899502873420715, accuracy=0.75\n",
            "epochs=2000, cost=0.6837698817253113, accuracy=0.75\n",
            "epochs=2500, cost=0.6655658483505249, accuracy=0.75\n",
            "epochs=3000, cost=0.6232362389564514, accuracy=0.75\n",
            "epochs=3500, cost=0.5638496279716492, accuracy=0.75\n",
            "epochs=4000, cost=0.5077230930328369, accuracy=0.75\n",
            "epochs=4500, cost=0.43535512685775757, accuracy=0.75\n",
            "epochs=5000, cost=0.2884193956851959, accuracy=1.0\n",
            "epochs=5500, cost=0.16295042634010315, accuracy=1.0\n",
            "epochs=6000, cost=0.10156022012233734, accuracy=1.0\n",
            "epochs=6500, cost=0.07115891575813293, accuracy=1.0\n",
            "epochs=7000, cost=0.053996190428733826, accuracy=1.0\n",
            "epochs=7500, cost=0.04320624843239784, accuracy=1.0\n",
            "epochs=8000, cost=0.03587156534194946, accuracy=1.0\n",
            "epochs=8500, cost=0.030592018738389015, accuracy=1.0\n",
            "epochs=9000, cost=0.02662411890923977, accuracy=1.0\n",
            "epochs=9500, cost=0.02354055643081665, accuracy=1.0\n",
            "epochs=10000, cost=0.02107948623597622, accuracy=1.0\n",
            "\n",
            "Hypothesis :\n",
            " [[0.02371585]\n",
            " [0.9809433 ]\n",
            " [0.98086035]\n",
            " [0.02151573]] \n",
            "Correct:\n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]] \n",
            "Accuracy\\ㅜ 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_63pfsh0vqk",
        "outputId": "35fe5288-55b8-410a-b5f7-2a79529f4501"
      },
      "source": [
        "#위 코드에서 그래프 추가하기\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from datetime import datetime    #텐서보드 위해\n",
        "\n",
        "learning_rate = 0.1\n",
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
        "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
        "\n",
        "W1 = tf.Variable(tf.random.uniform([2,2]), name='weight1')\n",
        "b1 = tf.Variable(tf.random.uniform([2]), name='bias1')\n",
        "W2 = tf.Variable(tf.random.uniform([2,1]), name='weight2')\n",
        "b2 = tf.Variable(tf.random.uniform([1]), name='bias2')\n",
        "\n",
        "#활성화 함수(hyp:가설)\n",
        "def hypothesis():\n",
        "    layer1 = tf.sigmoid(tf.matmul(x_data, W1) + b1)\n",
        "    cost = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
        "    return cost\n",
        "@tf.function    #텐서보드 위해\n",
        "def costFunc():\n",
        "    return -tf.reduce_mean(y_data * tf.math.log(hypothesis()) + (1 - y_data) * tf.math.log(1 - hypothesis()))\n",
        "\n",
        "#=========================================텐서보드 그래프========================================\n",
        "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "logdir = 'logs/mylogs/%s' % stamp\n",
        "writer = tf.summary.create_file_writer(logdir)\n",
        "tf.summary.trace_on(graph=True, profiler=True)\n",
        "costFunc()\n",
        "with writer.as_default():    #텐서 보드(그래프 추가)\n",
        "    tf.summary.trace_export(name='graph_t1', step=0, profiler_outdir=logdir)\n",
        "#================================================================================================\n",
        "\n",
        "train = tf.keras.optimizers.SGD(learning_rate)\n",
        "for step in range(10001):\n",
        "    train.minimize(costFunc, var_list=[W1, b1, W2, b2])\n",
        "    predicted = tf.cast(hypothesis()> 0.5, dtype=tf.float64)\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y_data), dtype=tf.float64))\n",
        "    if step%500 == 0:\n",
        "        print(f'epochs={step}, cost={costFunc()}, accuracy={accuracy}')\n",
        "print(\"\\nHypothesis :\\n\",hypothesis().numpy(), \"\\nCorrect:\\n\",predicted.numpy(), \"\\nAccuracy\\n\",accuracy.numpy())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epochs=0, cost=0.7622430920600891, accuracy=0.5\n",
            "epochs=500, cost=0.6926710605621338, accuracy=0.5\n",
            "epochs=1000, cost=0.6919280290603638, accuracy=0.5\n",
            "epochs=1500, cost=0.6899502873420715, accuracy=0.75\n",
            "epochs=2000, cost=0.6837698817253113, accuracy=0.75\n",
            "epochs=2500, cost=0.6655658483505249, accuracy=0.75\n",
            "epochs=3000, cost=0.6232362389564514, accuracy=0.75\n",
            "epochs=3500, cost=0.5638496279716492, accuracy=0.75\n",
            "epochs=4000, cost=0.5077230930328369, accuracy=0.75\n",
            "epochs=4500, cost=0.43535512685775757, accuracy=0.75\n",
            "epochs=5000, cost=0.2884193956851959, accuracy=1.0\n",
            "epochs=5500, cost=0.16295042634010315, accuracy=1.0\n",
            "epochs=6000, cost=0.10156022012233734, accuracy=1.0\n",
            "epochs=6500, cost=0.07115891575813293, accuracy=1.0\n",
            "epochs=7000, cost=0.053996190428733826, accuracy=1.0\n",
            "epochs=7500, cost=0.04320624843239784, accuracy=1.0\n",
            "epochs=8000, cost=0.03587156534194946, accuracy=1.0\n",
            "epochs=8500, cost=0.030592018738389015, accuracy=1.0\n",
            "epochs=9000, cost=0.02662411890923977, accuracy=1.0\n",
            "epochs=9500, cost=0.02354055643081665, accuracy=1.0\n",
            "epochs=10000, cost=0.02107948623597622, accuracy=1.0\n",
            "\n",
            "Hypothesis :\n",
            " [[0.02371585]\n",
            " [0.9809433 ]\n",
            " [0.98086035]\n",
            " [0.02151573]] \n",
            "Correct:\n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]] \n",
            "Accuracy\n",
            " 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqjvZfE91lZl",
        "outputId": "439719c9-6390-4848-f4b4-61212ec06bbe"
      },
      "source": [
        "#레이어 6개로 XOR\n",
        "#1.0에서는 오류가 나지만 2.0은 동일한 코드를 사용하더라도\n",
        "#확률적 경사 하강법을 사용하므로 오류가 나지 않음\n",
        "#근데 뭐가 문제인지 이 코드로는 75%가 나옴\n",
        "#그냥 그런 개념이다 정도만 알아둘 것\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "learninig_rate = 0.1\n",
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
        "y_data = np.array([[0], [1], [1], [0]], dtype=np.float32)\n",
        "\n",
        "W1 = tf.Variable(tf.random.uniform([2, 5]), name='weight1')\n",
        "b1 = tf.Variable(tf.random.uniform([5]), name='bias1')\n",
        "W2 = tf.Variable(tf.random.uniform([5, 5]), name='weight2')\n",
        "b2 = tf.Variable(tf.random.uniform([5]), name='bias2')\n",
        "W3 = tf.Variable(tf.random.uniform([5, 5]), name='weight3')\n",
        "b3 = tf.Variable(tf.random.uniform([5]), name='bias3')\n",
        "W4 = tf.Variable(tf.random.uniform([5, 5]), name='weight4')\n",
        "b4 = tf.Variable(tf.random.uniform([5]), name='bias4')\n",
        "W5 = tf.Variable(tf.random.uniform([5, 5]), name='weight5')\n",
        "b5 = tf.Variable(tf.random.uniform([5]), name='bias5')\n",
        "W6 = tf.Variable(tf.random.uniform([5, 1]), name='weight6')\n",
        "b6 = tf.Variable(tf.random.uniform([1]), name='bias6')\n",
        "\n",
        "#활성화함수\n",
        "def hypothesis():\n",
        "    layer1 = tf.sigmoid(tf.matmul(x_data, W1) + b1)\n",
        "    layer2 = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
        "    layer3 = tf.sigmoid(tf.matmul(layer2, W3) + b3)\n",
        "    layer4 = tf.sigmoid(tf.matmul(layer3, W4) + b4)\n",
        "    layer5 = tf.sigmoid(tf.matmul(layer4, W5) + b5)\n",
        "    cost = tf.sigmoid(tf.matmul(layer5, W6) + b6)\n",
        "    return cost\n",
        "\n",
        "@tf.function\n",
        "def costFunc():\n",
        "    return -tf.reduce_mean(y_data * tf.math.log(hypothesis()) + (1 - y_data) * tf.math.log(1 - hypothesis()))\n",
        "\n",
        "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "logdir = 'logs/mylogs/%s' % stamp\n",
        "writer = tf.summary.create_file_writer(logdir)\n",
        "tf.summary.trace_on(graph=True, profiler=True)\n",
        "costFunc()\n",
        "with writer.as_default():    #텐서 보드(그래프 추가)\n",
        "    tf.summary.trace_export(name='graph_t1', step=0, profiler_outdir=logdir)\n",
        "\n",
        "train = tf.keras.optimizers.SGD(learning_rate)\n",
        "for step in range(10001):\n",
        "    train.minimize(costFunc, var_list=[W1, b1, W2, b2, W3, b3, W4, b4, W5, b5, W6, b6])\n",
        "    predicted = tf.cast(hypothesis()> 0.5, dtype=tf.float32)\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, y_data), dtype=tf.float32))\n",
        "    if step%500 == 0:\n",
        "        print(f'epochs={step}, cost={costFunc()}, accuracy={accuracy}')\n",
        "print(\"\\nHypothesis :\\n\",hypothesis().numpy(), \"\\nCorrect:\\n\",predicted.numpy(), \"\\nAccuracy\\n\",accuracy.numpy())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Trace already enabled\n",
            "epochs=0, cost=1.4586420059204102, accuracy=0.5\n",
            "epochs=500, cost=0.6931456327438354, accuracy=0.75\n",
            "epochs=1000, cost=0.6931456327438354, accuracy=0.75\n",
            "epochs=1500, cost=0.6931455731391907, accuracy=0.75\n",
            "epochs=2000, cost=0.6931455731391907, accuracy=0.75\n",
            "epochs=2500, cost=0.6931455731391907, accuracy=0.75\n",
            "epochs=3000, cost=0.6931455731391907, accuracy=0.75\n",
            "epochs=3500, cost=0.6931456327438354, accuracy=0.75\n",
            "epochs=4000, cost=0.6931455731391907, accuracy=0.75\n",
            "epochs=4500, cost=0.6931456327438354, accuracy=0.75\n",
            "epochs=5000, cost=0.6931456327438354, accuracy=0.75\n",
            "epochs=5500, cost=0.6931456327438354, accuracy=0.75\n",
            "epochs=6000, cost=0.6931456327438354, accuracy=0.75\n",
            "epochs=6500, cost=0.6931456327438354, accuracy=0.75\n",
            "epochs=7000, cost=0.6931456327438354, accuracy=0.75\n",
            "epochs=7500, cost=0.6931456327438354, accuracy=0.75\n",
            "epochs=8000, cost=0.6931456327438354, accuracy=0.75\n",
            "epochs=8500, cost=0.6931456327438354, accuracy=0.75\n",
            "epochs=9000, cost=0.6931456327438354, accuracy=0.75\n",
            "epochs=9500, cost=0.6931456327438354, accuracy=0.75\n",
            "epochs=10000, cost=0.6931456327438354, accuracy=0.75\n",
            "\n",
            "Hypothesis :\n",
            " [[0.4999945 ]\n",
            " [0.50000536]\n",
            " [0.5000021 ]\n",
            " [0.5000098 ]] \n",
            "Correct:\n",
            " [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] \n",
            "Accuracy\n",
            " 0.75\n"
          ]
        }
      ]
    }
  ]
}