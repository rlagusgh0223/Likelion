{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "211008(텐서플로우 1.x)",
      "provenance": [],
      "authorship_tag": "ABX9TyODtcDIUPhJH2sTv4jQWgLE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1d2k-C-TsBk",
        "outputId": "f72fa8db-41e1-473f-e4f4-95897745f856"
      },
      "source": [
        "## 여러 입력 값을 갖는 로지스틱 회귀 실제 값 적용하기\n",
        "\n",
        "#7시간 공부하고 과외를 6번 받은 학생의 합격 가능성\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import numpy as np\n",
        "\n",
        "#실행할 때마다 같은 결과를 출력하기 위한 seed값 설정\n",
        "seed = 0\n",
        "np.random.seed(seed)#넘파이, 텐서플로우 seed값 초기화\n",
        "tf.set_random_seed(seed)\n",
        "\n",
        "#x, y의 데이터 값\n",
        "x_data = np.array([[2,3],[4,3],[6,4],[8,6],[10,7],[12,8],[14,19]])#[공부시간, 과외횟수]\n",
        "y_data = np.array([0,0,0,1,1,1,1]).reshape(7,1)#가로 7, 세로1로 만든다. 합격/불합격 결과\n",
        "\n",
        "#입력 값을 플레이스 홀더에 저장\n",
        "X = tf.placeholder(tf.float64, shape=[None, 2])#앞은 상관없고, 1차원 요소는 2개\n",
        "Y = tf.placeholder(tf.float64, shape=[None, 1])#앞은 상관없고, 1차원 요소는 1개\n",
        "\n",
        "#기울기 a와 바이어스 b의 값을 임의로 정함\n",
        "#a는 [2,1]이 형태를 가짐 a1, a2\n",
        "a = tf.Variable(tf.random_uniform([2,1], dtype=tf.float64))#기울기 2개니까 a1, a2 묶어서 [2,1](하나로 표현된 식이 2개 있다)\n",
        "#[2,1] 의미 : 들어오는 값은 2개, 나가는 값은 1개\n",
        "b = tf.Variable(tf.random_uniform([1], dtype=tf.float64))\n",
        "\n",
        "#y 시그모이드 함수의 방정식을 세움\n",
        "y = tf.sigmoid(tf.matmul(X, a) + b)    #예측치. () 안 부분은 -z식\n",
        "\n",
        "#오차를 구하는 함수\n",
        "loss = -tf.reduce_mean(Y * tf.log(y) + (1 - Y) * tf.log(1 - y))\n",
        "\n",
        "#학습률 값\n",
        "learning_rate = 0.1\n",
        "\n",
        "#오차를 최소로 하는 값 찾기\n",
        "gradient_decent = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
        "\n",
        "predicted = tf.cast(y > 0.5, dtype=tf.float64) #y가 0.5보다 크면 1, 아니면 0(텐서플로우의 cast연산자에 의해)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float64))#텐서플로우의 평균(predicted와 Y가 같으면 1, 아니면 0인 값들의 평균)\n",
        "\n",
        "#학습\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for i in range(3001):\n",
        "        a_, b_, loss_, _ = sess.run([a, b, loss, gradient_decent], feed_dict={X:x_data, Y:y_data})#플레이스홀더가 있으면 feed_dict로 값을 넣어준다\n",
        "        if (i+1) % 300 == 0:\n",
        "            print(\"step = %d, a1 = %.4f, a2 = %.4f, b = %.4f, loss = %.4f\" %(i+1, a_[0], a_[1], b_, loss_))\n",
        "    \n",
        "    \n",
        "    print()\n",
        "    #추가 코드(sessoin안에 있어야 함)\n",
        "    print(\"predicted = \", sess.run(predicted, feed_dict={X:x_data})) #\n",
        "    #다른 값 테스트\n",
        "    p_val, h_val = sess.run([predicted, y], feed_dict={X:[[1, 5], [10, 5], [4, 5]]})\n",
        "    print(\"check predicted = \", p_val)    #연산된 값을 bool로 변환한 값\n",
        "    print(\"check hypothesis = \", h_val)   #계산값\n",
        "    #정확도 측정\n",
        "    h, c, a = sess.run([y, predicted, accuracy], feed_dict={X:x_data, Y:y_data})\n",
        "    print(\"\\nHypothesis : \", h, \"\\nCorrect (Y) :\", c, \"\\nAccuracy : \",a)#예측치, 결과, 정확도 인듯....\n",
        "    \n",
        "    #===========================================여기부터 오늘 코드=============================================\n",
        "    new_x = np.array([7,6]).reshape(1,2) #7,6은 각각 공부한 시간과 과외수업횟수\n",
        "    new_y, new_y_result = sess.run([y, predicted], feed_dict={X:new_x})#새 합격 가능성, 그걸 predicted한게 y_result, 데이터를 플레이스 홀더에 넣어준다\n",
        "    \n",
        "    print(\"공부한 시간 : %d, 과외 수업 횟수 : %d\" %(new_x[:,0], new_x[:,1]))\n",
        "    print(\"합격 가능성 : %6.2f %%\" %(new_y*100))    #%하나만 쓰면 %글자 출력 안되니까 %%쓴거다\n",
        "    print(\"예측 결과 :\",new_y_result[0])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 300, a1 = 0.3977, a2 = 0.0820, b = -2.7195, loss = 0.2517\n",
            "step = 600, a1 = 0.5033, a2 = 0.2126, b = -4.2252, loss = 0.1733\n",
            "step = 900, a1 = 0.4990, a2 = 0.4149, b = -5.2534, loss = 0.1364\n",
            "step = 1200, a1 = 0.4515, a2 = 0.6366, b = -6.0584, loss = 0.1130\n",
            "step = 1500, a1 = 0.3914, a2 = 0.8503, b = -6.7260, loss = 0.0964\n",
            "step = 1800, a1 = 0.3300, a2 = 1.0476, b = -7.2984, loss = 0.0841\n",
            "step = 2100, a1 = 0.2715, a2 = 1.2274, b = -7.7999, loss = 0.0745\n",
            "step = 2400, a1 = 0.2172, a2 = 1.3908, b = -8.2467, loss = 0.0668\n",
            "step = 2700, a1 = 0.1673, a2 = 1.5395, b = -8.6496, loss = 0.0606\n",
            "step = 3000, a1 = 0.1217, a2 = 1.6754, b = -9.0167, loss = 0.0554\n",
            "\n",
            "predicted =  [[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n",
            "check predicted =  [[0.]\n",
            " [1.]\n",
            " [0.]]\n",
            "check hypothesis =  [[0.37349032]\n",
            " [0.64036528]\n",
            " [0.4619409 ]]\n",
            "\n",
            "Hypothesis :  [[0.02303809]\n",
            " [0.02919472]\n",
            " [0.17006392]\n",
            " [0.88180058]\n",
            " [0.98070748]\n",
            " [0.99712126]\n",
            " [1.        ]] \n",
            "Correct (Y) : [[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]] \n",
            "Accuracy :  1.0\n",
            "공부한 시간 : 7, 과외 수업 횟수 : 6\n",
            "합격 가능성 :  86.85 %\n",
            "예측 결과 : [1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcNnmuJ_Ui8p",
        "outputId": "c6a61cea-30d7-4e27-8f3e-fa73dc673eb3"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import numpy as np\n",
        "\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "tf.set_random_seed(seed)\n",
        "\n",
        "#data = np.loadtxt(\"C:/Users/Owner/Desktop/khh/Likelion/211008/data-03-diabetes.csv\", delimiter=\",\")\n",
        "#x_data = [[i[:-1]] for i in data] # 0 ~ 7번까지의 값이 x_data\n",
        "#y_data = [i[8] for i in data] #마지막 8번째 값이 y_data\n",
        "\n",
        "#배열 슬라이싱 응용\n",
        "xy = np.loadtxt(\"/content/data-03-diabetes.csv\", delimiter=\",\")\n",
        "x_data = xy[:, 0:-1]    #[전체줄, 각 줄 데이터 중 0~맨 끝에거 앞에까지]\n",
        "y_data = xy[:, [-1]]    #[전체줄, 각 줄 데이터 중 맨 끝에거]\n",
        "\n",
        "#Placeholders : Shape주의! 총 8개의 x_data와 1개의 y_data\n",
        "X = tf.placeholder(tf.float32, shape=[None,8])#\n",
        "Y = tf.placeholder(tf.float32, shape=[None,1])#\n",
        "\n",
        "W = tf.Variable(tf.random_normal([8,1]), name='weight')#기울기 8개? x값이 8개라 우선 8로 잡아봄\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "#random_normal은 어느정도 예측할 수 있을때 그 값을 중심으로 하지만\n",
        "#대부분은 예측할 수 없으미까 uniform을 쓰는게 좋다\n",
        "\n",
        "#Hypothesis예측값\n",
        "hyp = tf.sigmoid(tf.matmul(X, W) + b)\n",
        "\n",
        "#Cost/Loss function\n",
        "cost = -tf.reduce_mean(Y * tf.log(hyp) + (1 - Y) * tf.log(1-hyp))\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
        "\n",
        "#정확도 hyp > 0.5 else False\n",
        "predicted = tf.cast(hyp > 0.5, dtype=tf.float32)#\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))#\n",
        "\n",
        "#세션 시작\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    for step in range(10001):\n",
        "        cost_val, _ = sess.run([cost, train], feed_dict={X:x_data, Y:y_data})\n",
        "        if step % 200 == 0:\n",
        "            print(step, cost_val)\n",
        "            # 10000 0.480384\n",
        "        \n",
        "    #정확도 77%\n",
        "    _, _, a = sess.run([hyp, predicted, accuracy], feed_dict={X:x_data, Y:y_data})#acc앞은 연산을 위해 필요한거니까 출력 안해도 됨\n",
        "    #a = sess.run(accuracy, feed_dict={X:x_data, Y:y_data})로 해도 문제는 안됨\n",
        "    #graph가 구성되어 있으므로\n",
        "    print(\"Accuracy :\", a)\n",
        "    #Accuracy : 0.769433"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.9754207\n",
            "200 0.78652614\n",
            "400 0.73401636\n",
            "600 0.7038551\n",
            "800 0.6796619\n",
            "1000 0.6588307\n",
            "1200 0.6406826\n",
            "1400 0.6248361\n",
            "1600 0.6109787\n",
            "1800 0.59883696\n",
            "2000 0.58817154\n",
            "2200 0.57877535\n",
            "2400 0.57047045\n",
            "2600 0.5631049\n",
            "2800 0.5565494\n",
            "3000 0.5506938\n",
            "3200 0.54544497\n",
            "3400 0.5407234\n",
            "3600 0.53646153\n",
            "3800 0.53260183\n",
            "4000 0.5290952\n",
            "4200 0.5258994\n",
            "4400 0.5229783\n",
            "4600 0.5203007\n",
            "4800 0.5178397\n",
            "5000 0.51557213\n",
            "5200 0.51347744\n",
            "5400 0.51153815\n",
            "5600 0.5097386\n",
            "5800 0.50806534\n",
            "6000 0.5065064\n",
            "6200 0.5050512\n",
            "6400 0.50369036\n",
            "6600 0.5024156\n",
            "6800 0.5012195\n",
            "7000 0.50009567\n",
            "7200 0.49903786\n",
            "7400 0.4980409\n",
            "7600 0.49710017\n",
            "7800 0.4962113\n",
            "8000 0.49537027\n",
            "8200 0.49457365\n",
            "8400 0.4938183\n",
            "8600 0.4931012\n",
            "8800 0.4924198\n",
            "9000 0.49177158\n",
            "9200 0.4911545\n",
            "9400 0.49056628\n",
            "9600 0.49000522\n",
            "9800 0.48946962\n",
            "10000 0.48895785\n",
            "Accuracy : 0.76679844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A8m4DiSVNfv",
        "outputId": "87050cce-7e3d-415c-e1f3-f7594b6dc57f"
      },
      "source": [
        "# 퍼셉트론\n",
        "#AND, OR, NAND를 구현하는 로직연산\n",
        "#퍼셉트론은 XOR못한다\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
        "#y_data = np.array([[0],[0],[0],[1]], dtype=np.float32)#And를 구현하는 로직\n",
        "#y_data = np.array([[0],[1],[1],[1]], dtype=np.float32)#OR를 구현하는 로직\n",
        "y_data = np.array([[1],[1],[1],[0]], dtype=np.float32)#NAND를 구현하는 로직\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=[None,2])\n",
        "Y = tf.placeholder(tf.float32, shape=[None,1])\n",
        "\n",
        "W = tf.Variable(tf.random_normal([2,1]), name='weight')\n",
        "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
        "\n",
        "hyp = tf.sigmoid(tf.matmul(X, W) + b)\n",
        "\n",
        "cost = -tf.reduce_mean(Y * tf.log(hyp) + (1 - Y) * tf.log(1-hyp))   #오차\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
        "\n",
        "predicted = tf.cast(hyp > 0.5, dtype=tf.float32)\n",
        "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    \n",
        "    for step in range(10001):\n",
        "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
        "        if step % 1000 == 0:\n",
        "            print(\"step =\", step, \"cost =\", sess.run(cost, feed_dict={X:x_data, Y:y_data}))\n",
        "            print('W =',sess.run(W), \"b =\",sess.run(b))\n",
        "\n",
        "    h, p, a = sess.run([hyp, predicted, accuracy], feed_dict={X:x_data, Y:y_data})\n",
        "    print(\"\\nHypothesis :\",h,\"\\nCorrect\",p,\"\\nAccuracy :\", a)\n",
        "  \n",
        "    \n",
        "    #실제값 확인\n",
        "    print(\"\\n다른값 테스트\")\n",
        "    new_x = np.array([0,1]).reshape(1,2)\n",
        "    new_y = sess.run(hyp, feed_dict={X:new_x})\n",
        "    h, c = sess.run([hyp, predicted], feed_dict={X:new_x, Y:new_y})\n",
        "    print('Hyothesis :', h, \"\\nCorrect(Y) :\",c)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step = 0 cost = 0.9453583\n",
            "W = [[1.0201889]\n",
            " [0.5112581]] b = [-0.8465425]\n",
            "step = 1000 cost = 0.5874238\n",
            "W = [[ 0.15150224]\n",
            " [-0.1303716 ]] b = [0.6277868]\n",
            "step = 2000 cost = 0.4319353\n",
            "W = [[-0.5690266]\n",
            " [-0.7315243]] b = [1.4407197]\n",
            "step = 3000 cost = 0.34515724\n",
            "W = [[-1.0851076]\n",
            " [-1.1815641]] b = [2.0686817]\n",
            "step = 4000 cost = 0.28975335\n",
            "W = [[-1.4823263]\n",
            " [-1.541385 ]] b = [2.583518]\n",
            "step = 5000 cost = 0.2508015\n",
            "W = [[-1.8067298]\n",
            " [-1.8440031]] b = [3.0216131]\n",
            "step = 6000 cost = 0.22159007\n",
            "W = [[-2.082617 ]\n",
            " [-2.1068184]] b = [3.4044037]\n",
            "step = 7000 cost = 0.19869198\n",
            "W = [[-2.3238504]\n",
            " [-2.3399785]] b = [3.7452745]\n",
            "step = 8000 cost = 0.18016587\n",
            "W = [[-2.538957 ]\n",
            " [-2.5499647]] b = [4.0530934]\n",
            "step = 9000 cost = 0.16481918\n",
            "W = [[-2.7335358]\n",
            " [-2.7412126]] b = [4.3340473]\n",
            "step = 10000 cost = 0.15187196\n",
            "W = [[-2.9114633]\n",
            " [-2.9169228]] b = [4.5926466]\n",
            "\n",
            "Hypothesis : [[0.98997545]\n",
            " [0.8423375 ]\n",
            " [0.8430612 ]\n",
            " [0.22517842]] \n",
            "Correct [[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]] \n",
            "Accuracy : 1.0\n",
            "\n",
            "다른값 테스트\n",
            "Hyothesis : [[0.8423375]] \n",
            "Correct(Y) : [[1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6Jc0YY8VWuu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}